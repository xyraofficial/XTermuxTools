{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/functions-js/dist/module/types.js","sources":["file:///home/runner/workspace/node_modules/%40supabase/functions-js/src/types.ts"],"sourcesContent":["export type Fetch = typeof fetch\n\n/**\n * Response format\n */\nexport interface FunctionsResponseSuccess<T> {\n  data: T\n  error: null\n  response?: Response\n}\nexport interface FunctionsResponseFailure {\n  data: null\n  error: any\n  response?: Response\n}\nexport type FunctionsResponse<T> = FunctionsResponseSuccess<T> | FunctionsResponseFailure\n\n/**\n * Base error for Supabase Edge Function invocations.\n *\n * @example\n * ```ts\n * import { FunctionsError } from '@supabase/functions-js'\n *\n * throw new FunctionsError('Unexpected error invoking function', 'FunctionsError', {\n *   requestId: 'abc123',\n * })\n * ```\n */\nexport class FunctionsError extends Error {\n  context: any\n  constructor(message: string, name = 'FunctionsError', context?: any) {\n    super(message)\n    this.name = name\n    this.context = context\n  }\n}\n\n/**\n * Error thrown when the network request to an Edge Function fails.\n *\n * @example\n * ```ts\n * import { FunctionsFetchError } from '@supabase/functions-js'\n *\n * throw new FunctionsFetchError({ requestId: 'abc123' })\n * ```\n */\nexport class FunctionsFetchError extends FunctionsError {\n  constructor(context: any) {\n    super('Failed to send a request to the Edge Function', 'FunctionsFetchError', context)\n  }\n}\n\n/**\n * Error thrown when the Supabase relay cannot reach the Edge Function.\n *\n * @example\n * ```ts\n * import { FunctionsRelayError } from '@supabase/functions-js'\n *\n * throw new FunctionsRelayError({ region: 'us-east-1' })\n * ```\n */\nexport class FunctionsRelayError extends FunctionsError {\n  constructor(context: any) {\n    super('Relay Error invoking the Edge Function', 'FunctionsRelayError', context)\n  }\n}\n\n/**\n * Error thrown when the Edge Function returns a non-2xx status code.\n *\n * @example\n * ```ts\n * import { FunctionsHttpError } from '@supabase/functions-js'\n *\n * throw new FunctionsHttpError({ status: 500 })\n * ```\n */\nexport class FunctionsHttpError extends FunctionsError {\n  constructor(context: any) {\n    super('Edge Function returned a non-2xx status code', 'FunctionsHttpError', context)\n  }\n}\n// Define the enum for the 'region' property\nexport enum FunctionRegion {\n  Any = 'any',\n  ApNortheast1 = 'ap-northeast-1',\n  ApNortheast2 = 'ap-northeast-2',\n  ApSouth1 = 'ap-south-1',\n  ApSoutheast1 = 'ap-southeast-1',\n  ApSoutheast2 = 'ap-southeast-2',\n  CaCentral1 = 'ca-central-1',\n  EuCentral1 = 'eu-central-1',\n  EuWest1 = 'eu-west-1',\n  EuWest2 = 'eu-west-2',\n  EuWest3 = 'eu-west-3',\n  SaEast1 = 'sa-east-1',\n  UsEast1 = 'us-east-1',\n  UsWest1 = 'us-west-1',\n  UsWest2 = 'us-west-2',\n}\n\nexport type FunctionInvokeOptions = {\n  /**\n   * Object representing the headers to send with the request.\n   */\n  headers?: { [key: string]: string }\n  /**\n   * The HTTP verb of the request\n   */\n  method?: 'POST' | 'GET' | 'PUT' | 'PATCH' | 'DELETE'\n  /**\n   * The Region to invoke the function in.\n   */\n  region?: FunctionRegion\n  /**\n   * The body of the request.\n   */\n  body?:\n    | File\n    | Blob\n    | ArrayBuffer\n    | FormData\n    | ReadableStream<Uint8Array>\n    | Record<string, any>\n    | string\n  /**\n   * The AbortSignal to use for the request.\n   * */\n  signal?: AbortSignal\n  /**\n   * The timeout for the request in milliseconds.\n   * If the function takes longer than this, the request will be aborted.\n   * */\n  timeout?: number\n}\n"],"names":[],"mappings":"AAiBA;;;;;;;;;;;GAWG;;;;;;;;;;;;AACG,MAAO,cAAe,SAAQ,KAAK;IAEvC,YAAY,OAAe,EAAE,IAAI,GAAG,gBAAgB,EAAE,OAAa,CAAA;QACjE,KAAK,CAAC,OAAO,CAAC,CAAA;QACd,IAAI,CAAC,IAAI,GAAG,IAAI,CAAA;QAChB,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;IACxB,CAAC;CACF;AAYK,MAAO,mBAAoB,SAAQ,cAAc;IACrD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,+CAA+C,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAA;IACxF,CAAC;CACF;AAYK,MAAO,mBAAoB,SAAQ,cAAc;IACrD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,wCAAwC,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAA;IACjF,CAAC;CACF;AAYK,MAAO,kBAAmB,SAAQ,cAAc;IACpD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,8CAA8C,EAAE,oBAAoB,EAAE,OAAO,CAAC,CAAA;IACtF,CAAC;CACF;AAED,IAAY,cAgBX;AAhBD,CAAA,SAAY,cAAc;IACxB,cAAA,CAAA,MAAA,GAAA,KAAW,CAAA;IACX,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,WAAA,GAAA,YAAuB,CAAA;IACvB,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B,cAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;AACvB,CAAC,EAhBW,cAAc,IAAA,CAAd,cAAc,GAAA,CAAA,CAAA,GAgBzB"}},
    {"offset": {"line": 71, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/functions-js/dist/module/helper.js","sources":["file:///home/runner/workspace/node_modules/%40supabase/functions-js/src/helper.ts"],"sourcesContent":["import { Fetch } from './types'\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n"],"names":[],"mappings":";;;;AAEO,MAAM,YAAY,GAAG,CAAC,WAAmB,EAAS,EAAE;IACzD,IAAI,WAAW,EAAE,CAAC;QAChB,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,UAAY,CAAC,GAAG,IAAI,CAAC,CAAA;IAC1C,CAAC;IACD,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,IAAM,CAAC,GAAG,IAAI,CAAC,CAAA;AACpC,CAAC,CAAA"}},
    {"offset": {"line": 85, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/functions-js/dist/module/FunctionsClient.js","sources":["file:///home/runner/workspace/node_modules/%40supabase/functions-js/src/FunctionsClient.ts"],"sourcesContent":["import { resolveFetch } from './helper'\nimport {\n  Fetch,\n  FunctionInvokeOptions,\n  FunctionRegion,\n  FunctionsFetchError,\n  FunctionsHttpError,\n  FunctionsRelayError,\n  FunctionsResponse,\n} from './types'\n\n/**\n * Client for invoking Supabase Edge Functions.\n */\nexport class FunctionsClient {\n  protected url: string\n  protected headers: Record<string, string>\n  protected region: FunctionRegion\n  protected fetch: Fetch\n\n  /**\n   * Creates a new Functions client bound to an Edge Functions URL.\n   *\n   * @example\n   * ```ts\n   * import { FunctionsClient, FunctionRegion } from '@supabase/functions-js'\n   *\n   * const functions = new FunctionsClient('https://xyzcompany.supabase.co/functions/v1', {\n   *   headers: { apikey: 'public-anon-key' },\n   *   region: FunctionRegion.UsEast1,\n   * })\n   * ```\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      customFetch,\n      region = FunctionRegion.Any,\n    }: {\n      headers?: Record<string, string>\n      customFetch?: Fetch\n      region?: FunctionRegion\n    } = {}\n  ) {\n    this.url = url\n    this.headers = headers\n    this.region = region\n    this.fetch = resolveFetch(customFetch)\n  }\n\n  /**\n   * Updates the authorization header\n   * @param token - the new jwt token sent in the authorisation header\n   * @example\n   * ```ts\n   * functions.setAuth(session.access_token)\n   * ```\n   */\n  setAuth(token: string) {\n    this.headers.Authorization = `Bearer ${token}`\n  }\n\n  /**\n   * Invokes a function\n   * @param functionName - The name of the Function to invoke.\n   * @param options - Options for invoking the Function.\n   * @example\n   * ```ts\n   * const { data, error } = await functions.invoke('hello-world', {\n   *   body: { name: 'Ada' },\n   * })\n   * ```\n   */\n  async invoke<T = any>(\n    functionName: string,\n    options: FunctionInvokeOptions = {}\n  ): Promise<FunctionsResponse<T>> {\n    let timeoutId: ReturnType<typeof setTimeout> | undefined\n    let timeoutController: AbortController | undefined\n\n    try {\n      const { headers, method, body: functionArgs, signal, timeout } = options\n      let _headers: Record<string, string> = {}\n      let { region } = options\n      if (!region) {\n        region = this.region\n      }\n      // Add region as query parameter using URL API\n      const url = new URL(`${this.url}/${functionName}`)\n      if (region && region !== 'any') {\n        _headers['x-region'] = region\n        url.searchParams.set('forceFunctionRegion', region)\n      }\n      let body: any\n      if (\n        functionArgs &&\n        ((headers && !Object.prototype.hasOwnProperty.call(headers, 'Content-Type')) || !headers)\n      ) {\n        if (\n          (typeof Blob !== 'undefined' && functionArgs instanceof Blob) ||\n          functionArgs instanceof ArrayBuffer\n        ) {\n          // will work for File as File inherits Blob\n          // also works for ArrayBuffer as it is the same underlying structure as a Blob\n          _headers['Content-Type'] = 'application/octet-stream'\n          body = functionArgs\n        } else if (typeof functionArgs === 'string') {\n          // plain string\n          _headers['Content-Type'] = 'text/plain'\n          body = functionArgs\n        } else if (typeof FormData !== 'undefined' && functionArgs instanceof FormData) {\n          // don't set content-type headers\n          // Request will automatically add the right boundary value\n          body = functionArgs\n        } else {\n          // default, assume this is JSON\n          _headers['Content-Type'] = 'application/json'\n          body = JSON.stringify(functionArgs)\n        }\n      } else {\n        // if the Content-Type was supplied, simply set the body\n        body = functionArgs\n      }\n\n      // Handle timeout by creating an AbortController\n      let effectiveSignal = signal\n      if (timeout) {\n        timeoutController = new AbortController()\n        timeoutId = setTimeout(() => timeoutController!.abort(), timeout)\n\n        // If user provided their own signal, we need to respect both\n        if (signal) {\n          effectiveSignal = timeoutController.signal\n          // If the user's signal is aborted, abort our timeout controller too\n          signal.addEventListener('abort', () => timeoutController!.abort())\n        } else {\n          effectiveSignal = timeoutController.signal\n        }\n      }\n\n      const response = await this.fetch(url.toString(), {\n        method: method || 'POST',\n        // headers priority is (high to low):\n        // 1. invoke-level headers\n        // 2. client-level headers\n        // 3. default Content-Type header\n        headers: { ..._headers, ...this.headers, ...headers },\n        body,\n        signal: effectiveSignal,\n      }).catch((fetchError) => {\n        throw new FunctionsFetchError(fetchError)\n      })\n\n      const isRelayError = response.headers.get('x-relay-error')\n      if (isRelayError && isRelayError === 'true') {\n        throw new FunctionsRelayError(response)\n      }\n\n      if (!response.ok) {\n        throw new FunctionsHttpError(response)\n      }\n\n      let responseType = (response.headers.get('Content-Type') ?? 'text/plain').split(';')[0].trim()\n      let data: any\n      if (responseType === 'application/json') {\n        data = await response.json()\n      } else if (\n        responseType === 'application/octet-stream' ||\n        responseType === 'application/pdf'\n      ) {\n        data = await response.blob()\n      } else if (responseType === 'text/event-stream') {\n        data = response\n      } else if (responseType === 'multipart/form-data') {\n        data = await response.formData()\n      } else {\n        // default to text\n        data = await response.text()\n      }\n\n      return { data, error: null, response }\n    } catch (error) {\n      return {\n        data: null,\n        error,\n        response:\n          error instanceof FunctionsHttpError || error instanceof FunctionsRelayError\n            ? error.context\n            : undefined,\n      }\n    } finally {\n      // Clear the timeout if it was set\n      if (timeoutId) {\n        clearTimeout(timeoutId)\n      }\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,OAAO,EAAE,YAAY,EAAE,MAAM,UAAU,CAAA;AACvC,OAAO,EAGL,cAAc,EACd,mBAAmB,EACnB,kBAAkB,EAClB,mBAAmB,GAEpB,MAAM,SAAS,CAAA;;;;AAKV,MAAO,eAAe;IAM1B;;;;;;;;;;;;OAYG,CACH,YACE,GAAW,EACX,EACE,OAAO,GAAG,CAAA,CAAE,EACZ,WAAW,EACX,MAAM,GAAG,6LAAc,CAAC,GAAG,EAAA,GAKzB,CAAA,CAAE,CAAA;QAEN,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;QACd,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;QACtB,IAAI,CAAC,MAAM,GAAG,MAAM,CAAA;QACpB,IAAI,CAAC,KAAK,OAAG,4LAAY,EAAC,WAAW,CAAC,CAAA;IACxC,CAAC;IAED;;;;;;;OAOG,CACH,OAAO,CAAC,KAAa,EAAA;QACnB,IAAI,CAAC,OAAO,CAAC,aAAa,GAAG,CAAA,OAAA,EAAU,KAAK,EAAE,CAAA;IAChD,CAAC;IAED;;;;;;;;;;OAUG,CACG,MAAM,CAAA,cAAA,EAAA;8MACV,YAAoB,EACpB,UAAiC,CAAA,CAAE;;YAEnC,IAAI,SAAoD,CAAA;YACxD,IAAI,iBAA8C,CAAA;YAElD,IAAI,CAAC;gBACH,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,IAAI,EAAE,YAAY,EAAE,MAAM,EAAE,OAAO,EAAE,GAAG,OAAO,CAAA;gBACxE,IAAI,QAAQ,GAA2B,CAAA,CAAE,CAAA;gBACzC,IAAI,EAAE,MAAM,EAAE,GAAG,OAAO,CAAA;gBACxB,IAAI,CAAC,MAAM,EAAE,CAAC;oBACZ,MAAM,GAAG,IAAI,CAAC,MAAM,CAAA;gBACtB,CAAC;gBACD,8CAA8C;gBAC9C,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAA,CAAA,EAAI,YAAY,EAAE,CAAC,CAAA;gBAClD,IAAI,MAAM,IAAI,MAAM,KAAK,KAAK,EAAE,CAAC;oBAC/B,QAAQ,CAAC,UAAU,CAAC,GAAG,MAAM,CAAA;oBAC7B,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,qBAAqB,EAAE,MAAM,CAAC,CAAA;gBACrD,CAAC;gBACD,IAAI,IAAS,CAAA;gBACb,IACE,YAAY,IACZ,CAAC,AAAC,OAAO,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,OAAO,EAAE,cAAc,CAAC,CAAC,GAAI,CAAC,OAAO,CAAC,EACzF,CAAC;oBACD,IACE,AAAC,OAAO,IAAI,KAAK,WAAW,IAAI,YAAY,YAAY,IAAI,CAAC,GAC7D,YAAY,YAAY,WAAW,EACnC,CAAC;wBACD,2CAA2C;wBAC3C,8EAA8E;wBAC9E,QAAQ,CAAC,cAAc,CAAC,GAAG,0BAA0B,CAAA;wBACrD,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC,MAAM,IAAI,OAAO,YAAY,KAAK,QAAQ,EAAE,CAAC;wBAC5C,eAAe;wBACf,QAAQ,CAAC,cAAc,CAAC,GAAG,YAAY,CAAA;wBACvC,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC,MAAM,IAAI,OAAO,QAAQ,KAAK,WAAW,IAAI,YAAY,YAAY,QAAQ,EAAE,CAAC;wBAC/E,iCAAiC;wBACjC,0DAA0D;wBAC1D,IAAI,GAAG,YAAY,CAAA;oBACrB,CAAC,MAAM,CAAC;wBACN,+BAA+B;wBAC/B,QAAQ,CAAC,cAAc,CAAC,GAAG,kBAAkB,CAAA;wBAC7C,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAA;oBACrC,CAAC;gBACH,CAAC,MAAM,CAAC;oBACN,wDAAwD;oBACxD,IAAI,GAAG,YAAY,CAAA;gBACrB,CAAC;gBAED,gDAAgD;gBAChD,IAAI,eAAe,GAAG,MAAM,CAAA;gBAC5B,IAAI,OAAO,EAAE,CAAC;oBACZ,iBAAiB,GAAG,IAAI,eAAe,EAAE,CAAA;oBACzC,SAAS,GAAG,UAAU,CAAC,GAAG,CAAG,CAAD,gBAAmB,CAAC,KAAK,EAAE,EAAE,OAAO,CAAC,CAAA;oBAEjE,6DAA6D;oBAC7D,IAAI,MAAM,EAAE,CAAC;wBACX,eAAe,GAAG,iBAAiB,CAAC,MAAM,CAAA;wBAC1C,oEAAoE;wBACpE,MAAM,CAAC,gBAAgB,CAAC,OAAO,EAAE,GAAG,CAAG,CAAD,gBAAmB,CAAC,KAAK,EAAE,CAAC,CAAA;oBACpE,CAAC,MAAM,CAAC;wBACN,eAAe,GAAG,iBAAiB,CAAC,MAAM,CAAA;oBAC5C,CAAC;gBACH,CAAC;gBAED,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,QAAQ,EAAE,EAAE;oBAChD,MAAM,EAAE,MAAM,IAAI,MAAM;oBACxB,qCAAqC;oBACrC,0BAA0B;oBAC1B,0BAA0B;oBAC1B,iCAAiC;oBACjC,OAAO,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,QAAQ,GAAK,IAAI,CAAC,OAAO,GAAK,OAAO,CAAE;oBACrD,IAAI;oBACJ,MAAM,EAAE,eAAe;iBACxB,CAAC,CAAC,KAAK,CAAC,CAAC,UAAU,EAAE,EAAE;oBACtB,MAAM,IAAI,kMAAmB,CAAC,UAAU,CAAC,CAAA;gBAC3C,CAAC,CAAC,CAAA;gBAEF,MAAM,YAAY,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,eAAe,CAAC,CAAA;gBAC1D,IAAI,YAAY,IAAI,YAAY,KAAK,MAAM,EAAE,CAAC;oBAC5C,MAAM,IAAI,kMAAmB,CAAC,QAAQ,CAAC,CAAA;gBACzC,CAAC;gBAED,IAAI,CAAC,QAAQ,CAAC,EAAE,EAAE,CAAC;oBACjB,MAAM,IAAI,iMAAkB,CAAC,QAAQ,CAAC,CAAA;gBACxC,CAAC;gBAED,IAAI,YAAY,GAAG,CAAC,CAAA,KAAA,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,cAAc,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,YAAY,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAA;gBAC9F,IAAI,IAAS,CAAA;gBACb,IAAI,YAAY,KAAK,kBAAkB,EAAE,CAAC;oBACxC,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;gBAC9B,CAAC,MAAM,IACL,YAAY,KAAK,0BAA0B,IAC3C,YAAY,KAAK,iBAAiB,EAClC,CAAC;oBACD,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;gBAC9B,CAAC,MAAM,IAAI,YAAY,KAAK,mBAAmB,EAAE,CAAC;oBAChD,IAAI,GAAG,QAAQ,CAAA;gBACjB,CAAC,MAAM,IAAI,YAAY,KAAK,qBAAqB,EAAE,CAAC;oBAClD,IAAI,GAAG,MAAM,QAAQ,CAAC,QAAQ,EAAE,CAAA;gBAClC,CAAC,MAAM,CAAC;oBACN,kBAAkB;oBAClB,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;gBAC9B,CAAC;gBAED,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;oBAAE,QAAQ;gBAAA,CAAE,CAAA;YACxC,CAAC,CAAC,OAAO,KAAK,EAAE,CAAC;gBACf,OAAO;oBACL,IAAI,EAAE,IAAI;oBACV,KAAK;oBACL,QAAQ,EACN,KAAK,YAAY,iMAAkB,IAAI,KAAK,YAAY,kMAAmB,GACvE,KAAK,CAAC,OAAO,GACb,SAAS;iBAChB,CAAA;YACH,CAAC,QAAS,CAAC;gBACT,kCAAkC;gBAClC,IAAI,SAAS,EAAE,CAAC;oBACd,YAAY,CAAC,SAAS,CAAC,CAAA;gBACzB,CAAC;YACH,CAAC;QACH,CAAC;KAAA;CACF"}},
    {"offset": {"line": 247, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/index.mjs","sources":["file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/PostgrestError.ts","file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/PostgrestBuilder.ts","file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/PostgrestTransformBuilder.ts","file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/PostgrestFilterBuilder.ts","file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/PostgrestQueryBuilder.ts","file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/PostgrestClient.ts","file:///home/runner/workspace/node_modules/%40supabase/postgrest-js/src/index.ts"],"sourcesContent":["/**\n * Error format\n *\n * {@link https://postgrest.org/en/stable/api.html?highlight=options#errors-and-http-status-codes}\n */\nexport default class PostgrestError extends Error {\n  details: string\n  hint: string\n  code: string\n\n  /**\n   * @example\n   * ```ts\n   * import PostgrestError from '@supabase/postgrest-js'\n   *\n   * throw new PostgrestError({\n   *   message: 'Row level security prevented the request',\n   *   details: 'RLS denied the insert',\n   *   hint: 'Check your policies',\n   *   code: 'PGRST301',\n   * })\n   * ```\n   */\n  constructor(context: { message: string; details: string; hint: string; code: string }) {\n    super(context.message)\n    this.name = 'PostgrestError'\n    this.details = context.details\n    this.hint = context.hint\n    this.code = context.code\n  }\n}\n","import type {\n  PostgrestSingleResponse,\n  PostgrestResponseSuccess,\n  CheckMatchingArrayTypes,\n  MergePartialResult,\n  IsValidResultOverride,\n} from './types/types'\nimport { ClientServerOptions, Fetch } from './types/common/common'\nimport PostgrestError from './PostgrestError'\nimport { ContainsNull } from './select-query-parser/types'\n\nexport default abstract class PostgrestBuilder<\n  ClientOptions extends ClientServerOptions,\n  Result,\n  ThrowOnError extends boolean = false,\n> implements\n    PromiseLike<\n      ThrowOnError extends true ? PostgrestResponseSuccess<Result> : PostgrestSingleResponse<Result>\n    >\n{\n  protected method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n  protected url: URL\n  protected headers: Headers\n  protected schema?: string\n  protected body?: unknown\n  protected shouldThrowOnError = false\n  protected signal?: AbortSignal\n  protected fetch: Fetch\n  protected isMaybeSingle: boolean\n\n  /**\n   * Creates a builder configured for a specific PostgREST request.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const builder = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: new Headers({ apikey: 'public-anon-key' }) }\n   * )\n   * ```\n   */\n  constructor(builder: {\n    method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n    url: URL\n    headers: HeadersInit\n    schema?: string\n    body?: unknown\n    shouldThrowOnError?: boolean\n    signal?: AbortSignal\n    fetch?: Fetch\n    isMaybeSingle?: boolean\n  }) {\n    this.method = builder.method\n    this.url = builder.url\n    this.headers = new Headers(builder.headers)\n    this.schema = builder.schema\n    this.body = builder.body\n    this.shouldThrowOnError = builder.shouldThrowOnError ?? false\n    this.signal = builder.signal\n    this.isMaybeSingle = builder.isMaybeSingle ?? false\n\n    if (builder.fetch) {\n      this.fetch = builder.fetch\n    } else {\n      this.fetch = fetch\n    }\n  }\n\n  /**\n   * If there's an error with the query, throwOnError will reject the promise by\n   * throwing the error instead of returning it as part of a successful response.\n   *\n   * {@link https://github.com/supabase/supabase-js/issues/92}\n   */\n  throwOnError(): this & PostgrestBuilder<ClientOptions, Result, true> {\n    this.shouldThrowOnError = true\n    return this as this & PostgrestBuilder<ClientOptions, Result, true>\n  }\n\n  /**\n   * Set an HTTP header for the request.\n   */\n  setHeader(name: string, value: string): this {\n    this.headers = new Headers(this.headers)\n    this.headers.set(name, value)\n    return this\n  }\n\n  then<\n    TResult1 = ThrowOnError extends true\n      ? PostgrestResponseSuccess<Result>\n      : PostgrestSingleResponse<Result>,\n    TResult2 = never,\n  >(\n    onfulfilled?:\n      | ((\n          value: ThrowOnError extends true\n            ? PostgrestResponseSuccess<Result>\n            : PostgrestSingleResponse<Result>\n        ) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null\n  ): PromiseLike<TResult1 | TResult2> {\n    // https://postgrest.org/en/stable/api.html#switching-schemas\n    if (this.schema === undefined) {\n      // skip\n    } else if (['GET', 'HEAD'].includes(this.method)) {\n      this.headers.set('Accept-Profile', this.schema)\n    } else {\n      this.headers.set('Content-Profile', this.schema)\n    }\n    if (this.method !== 'GET' && this.method !== 'HEAD') {\n      this.headers.set('Content-Type', 'application/json')\n    }\n\n    // NOTE: Invoke w/o `this` to avoid illegal invocation error.\n    // https://github.com/supabase/postgrest-js/pull/247\n    const _fetch = this.fetch\n    let res = _fetch(this.url.toString(), {\n      method: this.method,\n      headers: this.headers,\n      body: JSON.stringify(this.body),\n      signal: this.signal,\n    }).then(async (res) => {\n      let error = null\n      let data = null\n      let count: number | null = null\n      let status = res.status\n      let statusText = res.statusText\n\n      if (res.ok) {\n        if (this.method !== 'HEAD') {\n          const body = await res.text()\n          if (body === '') {\n            // Prefer: return=minimal\n          } else if (this.headers.get('Accept') === 'text/csv') {\n            data = body\n          } else if (\n            this.headers.get('Accept') &&\n            this.headers.get('Accept')?.includes('application/vnd.pgrst.plan+text')\n          ) {\n            data = body\n          } else {\n            data = JSON.parse(body)\n          }\n        }\n\n        const countHeader = this.headers.get('Prefer')?.match(/count=(exact|planned|estimated)/)\n        const contentRange = res.headers.get('content-range')?.split('/')\n        if (countHeader && contentRange && contentRange.length > 1) {\n          count = parseInt(contentRange[1])\n        }\n\n        // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n        // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n        if (this.isMaybeSingle && this.method === 'GET' && Array.isArray(data)) {\n          if (data.length > 1) {\n            error = {\n              // https://github.com/PostgREST/postgrest/blob/a867d79c42419af16c18c3fb019eba8df992626f/src/PostgREST/Error.hs#L553\n              code: 'PGRST116',\n              details: `Results contain ${data.length} rows, application/vnd.pgrst.object+json requires 1 row`,\n              hint: null,\n              message: 'JSON object requested, multiple (or no) rows returned',\n            }\n            data = null\n            count = null\n            status = 406\n            statusText = 'Not Acceptable'\n          } else if (data.length === 1) {\n            data = data[0]\n          } else {\n            data = null\n          }\n        }\n      } else {\n        const body = await res.text()\n\n        try {\n          error = JSON.parse(body)\n\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (Array.isArray(error) && res.status === 404) {\n            data = []\n            error = null\n            status = 200\n            statusText = 'OK'\n          }\n        } catch {\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (res.status === 404 && body === '') {\n            status = 204\n            statusText = 'No Content'\n          } else {\n            error = {\n              message: body,\n            }\n          }\n        }\n\n        if (error && this.isMaybeSingle && error?.details?.includes('0 rows')) {\n          error = null\n          status = 200\n          statusText = 'OK'\n        }\n\n        if (error && this.shouldThrowOnError) {\n          throw new PostgrestError(error)\n        }\n      }\n\n      const postgrestResponse = {\n        error,\n        data,\n        count,\n        status,\n        statusText,\n      }\n\n      return postgrestResponse\n    })\n    if (!this.shouldThrowOnError) {\n      res = res.catch((fetchError) => {\n        // Build detailed error information including cause if available\n        // Note: We don't populate code/hint for client-side network errors since those\n        // fields are meant for upstream service errors (PostgREST/PostgreSQL)\n        let errorDetails = ''\n\n        // Add cause information if available (e.g., DNS errors, network failures)\n        const cause = fetchError?.cause\n        if (cause) {\n          const causeMessage = cause?.message ?? ''\n          const causeCode = cause?.code ?? ''\n\n          errorDetails = `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`\n          errorDetails += `\\n\\nCaused by: ${cause?.name ?? 'Error'}: ${causeMessage}`\n          if (causeCode) {\n            errorDetails += ` (${causeCode})`\n          }\n          if (cause?.stack) {\n            errorDetails += `\\n${cause.stack}`\n          }\n        } else {\n          // No cause available, just include the error stack\n          errorDetails = fetchError?.stack ?? ''\n        }\n\n        return {\n          error: {\n            message: `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`,\n            details: errorDetails,\n            hint: '',\n            code: '',\n          },\n          data: null,\n          count: null,\n          status: 0,\n          statusText: '',\n        }\n      })\n    }\n\n    return res.then(onfulfilled, onrejected)\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestBuilder<\n    ClientOptions,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    /* istanbul ignore next */\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n\n  /**\n   * Override the type of the returned `data` field in the response.\n   *\n   * @typeParam NewResult - The new type to cast the response data to\n   * @typeParam Options - Optional type configuration (defaults to { merge: true })\n   * @typeParam Options.merge - When true, merges the new type with existing return type. When false, replaces the existing types entirely (defaults to true)\n   * @example\n   * ```typescript\n   * // Merge with existing types (default behavior)\n   * const query = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ custom_field: string }>()\n   *\n   * // Replace existing types completely\n   * const replaceQuery = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ id: number; name: string }, { merge: false }>()\n   * ```\n   * @returns A PostgrestBuilder instance with the new type\n   */\n  overrideTypes<\n    NewResult,\n    Options extends { merge?: boolean } = { merge: true },\n  >(): PostgrestBuilder<\n    ClientOptions,\n    IsValidResultOverride<Result, NewResult, false, false> extends true\n      ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n        ContainsNull<Result> extends true\n        ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n        : MergePartialResult<NewResult, Result, Options>\n      : CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      IsValidResultOverride<Result, NewResult, false, false> extends true\n        ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n          ContainsNull<Result> extends true\n          ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n          : MergePartialResult<NewResult, Result, Options>\n        : CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n}\n","import PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestFilterBuilder, { InvalidMethodError } from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport { CheckMatchingArrayTypes } from './types/types'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\nimport type { MaxAffectedEnabled } from './types/feature-flags'\n\nexport default class PostgrestTransformBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestBuilder<ClientOptions, Result> {\n  /**\n   * Perform a SELECT on the query result.\n   *\n   * By default, `.insert()`, `.update()`, `.upsert()`, and `.delete()` do not\n   * return modified rows. By calling this method, modified rows are returned in\n   * `data`.\n   *\n   * @param columns - The columns to retrieve, separated by commas\n   */\n  select<\n    Query extends string = '*',\n    NewResultOne = GetResult<Schema, Row, RelationName, Relationships, Query, ClientOptions>,\n  >(\n    columns?: Query\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    Method extends 'RPC'\n      ? Result extends unknown[]\n        ? NewResultOne[]\n        : NewResultOne\n      : NewResultOne[],\n    RelationName,\n    Relationships,\n    Method\n  > {\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n    this.headers.append('Prefer', 'return=representation')\n    return this as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      Method extends 'RPC'\n        ? Result extends unknown[]\n          ? NewResultOne[]\n          : NewResultOne\n        : NewResultOne[],\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: undefined }\n  ): this\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: string }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: undefined }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: string }\n  ): this\n  /**\n   * Order the query result by `column`.\n   *\n   * You can call this method multiple times to order by multiple columns.\n   *\n   * You can order referenced tables, but it only affects the ordering of the\n   * parent table if you use `!inner` in the query.\n   *\n   * @param column - The column to order by\n   * @param options - Named parameters\n   * @param options.ascending - If `true`, the result will be in ascending order\n   * @param options.nullsFirst - If `true`, `null`s appear first. If `false`,\n   * `null`s appear last.\n   * @param options.referencedTable - Set this to order a referenced table by\n   * its columns\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  order(\n    column: string,\n    {\n      ascending = true,\n      nullsFirst,\n      foreignTable,\n      referencedTable = foreignTable,\n    }: {\n      ascending?: boolean\n      nullsFirst?: boolean\n      foreignTable?: string\n      referencedTable?: string\n    } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.order` : 'order'\n    const existingOrder = this.url.searchParams.get(key)\n\n    this.url.searchParams.set(\n      key,\n      `${existingOrder ? `${existingOrder},` : ''}${column}.${ascending ? 'asc' : 'desc'}${\n        nullsFirst === undefined ? '' : nullsFirst ? '.nullsfirst' : '.nullslast'\n      }`\n    )\n    return this\n  }\n\n  /**\n   * Limit the query result by `count`.\n   *\n   * @param count - The maximum number of rows to return\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  limit(\n    count: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(key, `${count}`)\n    return this\n  }\n\n  /**\n   * Limit the query result by starting at an offset `from` and ending at the offset `to`.\n   * Only records within this range are returned.\n   * This respects the query order and if there is no order clause the range could behave unexpectedly.\n   * The `from` and `to` values are 0-based and inclusive: `range(1, 3)` will include the second, third\n   * and fourth rows of the query.\n   *\n   * @param from - The starting index from which to limit the result\n   * @param to - The last index to which to limit the result\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  range(\n    from: number,\n    to: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const keyOffset =\n      typeof referencedTable === 'undefined' ? 'offset' : `${referencedTable}.offset`\n    const keyLimit = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(keyOffset, `${from}`)\n    // Range is inclusive, so add 1\n    this.url.searchParams.set(keyLimit, `${to - from + 1}`)\n    return this\n  }\n\n  /**\n   * Set the AbortSignal for the fetch request.\n   *\n   * @param signal - The AbortSignal to use for the fetch request\n   */\n  abortSignal(signal: AbortSignal): this {\n    this.signal = signal\n    return this\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be one row (e.g. using `.limit(1)`), otherwise this\n   * returns an error.\n   */\n  single<ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never>(): PostgrestBuilder<\n    ClientOptions,\n    ResultOne\n  > {\n    this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne>\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be zero or one row (e.g. using `.limit(1)`), otherwise\n   * this returns an error.\n   */\n  maybeSingle<\n    ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never,\n  >(): PostgrestBuilder<ClientOptions, ResultOne | null> {\n    // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n    // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n    if (this.method === 'GET') {\n      this.headers.set('Accept', 'application/json')\n    } else {\n      this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    }\n    this.isMaybeSingle = true\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne | null>\n  }\n\n  /**\n   * Return `data` as a string in CSV format.\n   */\n  csv(): PostgrestBuilder<ClientOptions, string> {\n    this.headers.set('Accept', 'text/csv')\n    return this as unknown as PostgrestBuilder<ClientOptions, string>\n  }\n\n  /**\n   * Return `data` as an object in [GeoJSON](https://geojson.org) format.\n   */\n  geojson(): PostgrestBuilder<ClientOptions, Record<string, unknown>> {\n    this.headers.set('Accept', 'application/geo+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>>\n  }\n\n  /**\n   * Return `data` as the EXPLAIN plan for the query.\n   *\n   * You need to enable the\n   * [db_plan_enabled](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain)\n   * setting before using this method.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.analyze - If `true`, the query will be executed and the\n   * actual run time will be returned\n   *\n   * @param options.verbose - If `true`, the query identifier will be returned\n   * and `data` will include the output columns of the query\n   *\n   * @param options.settings - If `true`, include information on configuration\n   * parameters that affect query planning\n   *\n   * @param options.buffers - If `true`, include information on buffer usage\n   *\n   * @param options.wal - If `true`, include information on WAL record generation\n   *\n   * @param options.format - The format of the output, can be `\"text\"` (default)\n   * or `\"json\"`\n   */\n  explain({\n    analyze = false,\n    verbose = false,\n    settings = false,\n    buffers = false,\n    wal = false,\n    format = 'text',\n  }: {\n    analyze?: boolean\n    verbose?: boolean\n    settings?: boolean\n    buffers?: boolean\n    wal?: boolean\n    format?: 'json' | 'text'\n  } = {}) {\n    const options = [\n      analyze ? 'analyze' : null,\n      verbose ? 'verbose' : null,\n      settings ? 'settings' : null,\n      buffers ? 'buffers' : null,\n      wal ? 'wal' : null,\n    ]\n      .filter(Boolean)\n      .join('|')\n    // An Accept header can carry multiple media types but postgrest-js always sends one\n    const forMediatype = this.headers.get('Accept') ?? 'application/json'\n    this.headers.set(\n      'Accept',\n      `application/vnd.pgrst.plan+${format}; for=\"${forMediatype}\"; options=${options};`\n    )\n    if (format === 'json') {\n      return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>[]>\n    } else {\n      return this as unknown as PostgrestBuilder<ClientOptions, string>\n    }\n  }\n\n  /**\n   * Rollback the query.\n   *\n   * `data` will still be returned, but the query is not committed.\n   */\n  rollback(): this {\n    this.headers.append('Prefer', 'tx=rollback')\n    return this\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestTransformBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    RelationName,\n    Relationships,\n    Method\n  > {\n    return this as unknown as PostgrestTransformBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  /**\n   * Set the maximum number of rows that can be affected by the query.\n   * Only available in PostgREST v13+ and only works with PATCH and DELETE methods.\n   *\n   * @param value - The maximum number of rows that can be affected\n   */\n  maxAffected(value: number): MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n    ? // TODO: update the RPC case to only work on RPC that returns SETOF rows\n      Method extends 'PATCH' | 'DELETE' | 'RPC'\n      ? this\n      : InvalidMethodError<'maxAffected method only available on update or delete'>\n    : InvalidMethodError<'maxAffected method only available on postgrest 13+'> {\n    this.headers.append('Prefer', 'handling=strict')\n    this.headers.append('Prefer', `max-affected=${value}`)\n    return this as unknown as MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n      ? Method extends 'PATCH' | 'DELETE' | 'RPC'\n        ? this\n        : InvalidMethodError<'maxAffected method only available on update or delete'>\n      : InvalidMethodError<'maxAffected method only available on postgrest 13+'>\n  }\n}\n","import PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport { JsonPathToAccessor, JsonPathToType } from './select-query-parser/utils'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\n\ntype FilterOperator =\n  | 'eq'\n  | 'neq'\n  | 'gt'\n  | 'gte'\n  | 'lt'\n  | 'lte'\n  | 'like'\n  | 'ilike'\n  | 'is'\n  | 'isdistinct'\n  | 'in'\n  | 'cs'\n  | 'cd'\n  | 'sl'\n  | 'sr'\n  | 'nxl'\n  | 'nxr'\n  | 'adj'\n  | 'ov'\n  | 'fts'\n  | 'plfts'\n  | 'phfts'\n  | 'wfts'\n  | 'match'\n  | 'imatch'\n\nexport type IsStringOperator<Path extends string> = Path extends `${string}->>${string}`\n  ? true\n  : false\n\nconst PostgrestReservedCharsRegexp = new RegExp('[,()]')\n\n// Match relationship filters with `table.column` syntax and resolve underlying\n// column value. If not matched, fallback to generic type.\n// TODO: Validate the relationship itself ala select-query-parser. Currently we\n// assume that all tables have valid relationships to each other, despite\n// nonexistent foreign keys.\ntype ResolveFilterValue<\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  ColumnName extends string,\n> = ColumnName extends `${infer RelationshipTable}.${infer Remainder}`\n  ? Remainder extends `${infer _}.${infer _}`\n    ? ResolveFilterValue<Schema, Row, Remainder>\n    : ResolveFilterRelationshipValue<Schema, RelationshipTable, Remainder>\n  : ColumnName extends keyof Row\n    ? Row[ColumnName]\n    : // If the column selection is a jsonpath like `data->value` or `data->>value` we attempt to match\n      // the expected type with the parsed custom json type\n      IsStringOperator<ColumnName> extends true\n      ? string\n      : JsonPathToType<Row, JsonPathToAccessor<ColumnName>> extends infer JsonPathValue\n        ? JsonPathValue extends never\n          ? never\n          : JsonPathValue\n        : never\n\ntype ResolveFilterRelationshipValue<\n  Schema extends GenericSchema,\n  RelationshipTable extends string,\n  RelationshipColumn extends string,\n> = Schema['Tables'] & Schema['Views'] extends infer TablesAndViews\n  ? RelationshipTable extends keyof TablesAndViews\n    ? 'Row' extends keyof TablesAndViews[RelationshipTable]\n      ? RelationshipColumn extends keyof TablesAndViews[RelationshipTable]['Row']\n        ? TablesAndViews[RelationshipTable]['Row'][RelationshipColumn]\n        : unknown\n      : unknown\n    : unknown\n  : never\n\nexport type InvalidMethodError<S extends string> = { Error: S }\n\nexport default class PostgrestFilterBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestTransformBuilder<\n  ClientOptions,\n  Schema,\n  Row,\n  Result,\n  RelationName,\n  Relationships,\n  Method\n> {\n  /**\n   * Match only rows where `column` is equal to `value`.\n   *\n   * To check if the value of `column` is NULL, you should use `.is()` instead.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  eq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? NonNullable<unknown>\n      : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n        // type resolution error\n        ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? NonNullable<ResolvedFilterValue>\n        : // We should never enter this case as all the branches are covered above\n          never\n  ): this {\n    this.url.searchParams.append(column, `eq.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is not equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  neq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `neq.${value}`)\n    return this\n  }\n\n  gt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gt.${value}`)\n    return this\n  }\n\n  gte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gte.${value}`)\n    return this\n  }\n\n  lt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lt.${value}`)\n    return this\n  }\n\n  lte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lte.${value}`)\n    return this\n  }\n\n  like<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  like(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  like(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `like.${pattern}`)\n    return this\n  }\n\n  likeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  likeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilike<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  ilike(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  ilike(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `ilike.${pattern}`)\n    return this\n  }\n\n  ilikeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilikeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  regexMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-sensitively (using the `~` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `match.${pattern}`)\n    return this\n  }\n\n  regexIMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexIMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-insensitively (using the `~*` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexIMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `imatch.${pattern}`)\n    return this\n  }\n\n  is<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: Row[ColumnName] & (boolean | null)\n  ): this\n  is(column: string, value: boolean | null): this\n  /**\n   * Match only rows where `column` IS `value`.\n   *\n   * For non-boolean columns, this is only relevant for checking if the value of\n   * `column` is NULL by setting `value` to `null`.\n   *\n   * For boolean columns, you can also set `value` to `true` or `false` and it\n   * will behave the same way as `.eq()`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  is(column: string, value: boolean | null): this {\n    this.url.searchParams.append(column, `is.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` IS DISTINCT FROM `value`.\n   *\n   * Unlike `.neq()`, this treats `NULL` as a comparable value. Two `NULL` values\n   * are considered equal (not distinct), and comparing `NULL` with any non-NULL\n   * value returns true (distinct).\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  isDistinct<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `isdistinct.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  in<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n          // type resolution error\n          ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : // We should never enter this case as all the branches are covered above\n            never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `in.(${cleanedValues})`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is NOT included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  notIn<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `not.in.(${cleanedValues})`)\n    return this\n  }\n\n  contains<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * `column` contains every element appearing in `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range types can be inclusive '[', ']' or exclusive '(', ')' so just\n      // keep it simple and accept a string\n      this.url.searchParams.append(column, `cs.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cs.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cs.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  containedBy<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * every element appearing in `column` is contained by `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `cd.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cd.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cd.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  rangeGt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is greater than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sr.${range}`)\n    return this\n  }\n\n  rangeGte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or greater than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxl.${range}`)\n    return this\n  }\n\n  rangeLt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is less than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sl.${range}`)\n    return this\n  }\n\n  rangeLte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or less than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxr.${range}`)\n    return this\n  }\n\n  rangeAdjacent<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeAdjacent(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where `column` is\n   * mutually exclusive to `range` and there can be no element between the two\n   * ranges.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeAdjacent(column: string, range: string): this {\n    this.url.searchParams.append(column, `adj.${range}`)\n    return this\n  }\n\n  overlaps<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]>\n  ): this\n  overlaps(column: string, value: string | readonly unknown[]): this\n  /**\n   * Only relevant for array and range columns. Match only rows where\n   * `column` and `value` have an element in common.\n   *\n   * @param column - The array or range column to filter on\n   * @param value - The array or range value to filter with\n   */\n  overlaps(column: string, value: string | readonly unknown[]): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `ov.${value}`)\n    } else {\n      // array\n      this.url.searchParams.append(column, `ov.{${value.join(',')}}`)\n    }\n    return this\n  }\n\n  textSearch<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  textSearch(\n    column: string,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  /**\n   * Only relevant for text and tsvector columns. Match only rows where\n   * `column` matches the query string in `query`.\n   *\n   * @param column - The text or tsvector column to filter on\n   * @param query - The query text to match with\n   * @param options - Named parameters\n   * @param options.config - The text search configuration to use\n   * @param options.type - Change how the `query` text is interpreted\n   */\n  textSearch(\n    column: string,\n    query: string,\n    { config, type }: { config?: string; type?: 'plain' | 'phrase' | 'websearch' } = {}\n  ): this {\n    let typePart = ''\n    if (type === 'plain') {\n      typePart = 'pl'\n    } else if (type === 'phrase') {\n      typePart = 'ph'\n    } else if (type === 'websearch') {\n      typePart = 'w'\n    }\n    const configPart = config === undefined ? '' : `(${config})`\n    this.url.searchParams.append(column, `${typePart}fts${configPart}.${query}`)\n    return this\n  }\n\n  match<ColumnName extends string & keyof Row>(query: Record<ColumnName, Row[ColumnName]>): this\n  match(query: Record<string, unknown>): this\n  /**\n   * Match only rows where each column in `query` keys is equal to its\n   * associated value. Shorthand for multiple `.eq()`s.\n   *\n   * @param query - The object to filter with, with column names as keys mapped\n   * to their filter values\n   */\n  match(query: Record<string, unknown>): this {\n    Object.entries(query).forEach(([column, value]) => {\n      this.url.searchParams.append(column, `eq.${value}`)\n    })\n    return this\n  }\n\n  not<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: FilterOperator,\n    value: Row[ColumnName]\n  ): this\n  not(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which doesn't satisfy the filter.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to be negated to filter with, following\n   * PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  not(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `not.${operator}.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows which satisfy at least one of the filters.\n   *\n   * Unlike most filters, `filters` is used as-is and needs to follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure it's properly sanitized.\n   *\n   * It's currently not possible to do an `.or()` filter across multiple tables.\n   *\n   * @param filters - The filters to use, following PostgREST syntax\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to filter on referenced tables\n   * instead of the parent table\n   * @param options.foreignTable - Deprecated, use `referencedTable` instead\n   */\n  or(\n    filters: string,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.or` : 'or'\n    this.url.searchParams.append(key, `(${filters})`)\n    return this\n  }\n\n  filter<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: `${'' | 'not.'}${FilterOperator}`,\n    value: unknown\n  ): this\n  filter(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which satisfy the filter. This is an escape hatch - you\n   * should use the specific filter methods wherever possible.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to filter with, following PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  filter(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `${operator}.${value}`)\n    return this\n  }\n}\n","import PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport {\n  ClientServerOptions,\n  Fetch,\n  GenericSchema,\n  GenericTable,\n  GenericView,\n} from './types/common/common'\n\nexport default class PostgrestQueryBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Relation extends GenericTable | GenericView,\n  RelationName = unknown,\n  Relationships = Relation extends { Relationships: infer R } ? R : unknown,\n> {\n  url: URL\n  headers: Headers\n  schema?: string\n  signal?: AbortSignal\n  fetch?: Fetch\n\n  /**\n   * Creates a query builder scoped to a Postgres table or view.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const query = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: { apikey: 'public-anon-key' } }\n   * )\n   * ```\n   */\n  constructor(\n    url: URL,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: string\n      fetch?: Fetch\n    }\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schema = schema\n    this.fetch = fetch\n  }\n\n  /**\n   * Perform a SELECT query on the table or view.\n   *\n   * @param columns - The columns to retrieve, separated by commas. Columns can be renamed when returned with `customName:columnName`\n   *\n   * @param options - Named parameters\n   *\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   *\n   * @param options.count - Count algorithm to use to count rows in the table or view.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  select<\n    Query extends string = '*',\n    ResultOne = GetResult<\n      Schema,\n      Relation['Row'],\n      RelationName,\n      Relationships,\n      Query,\n      ClientOptions\n    >,\n  >(\n    columns?: Query,\n    options?: {\n      head?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    ResultOne[],\n    RelationName,\n    Relationships,\n    'GET'\n  > {\n    const { head = false, count } = options ?? {}\n\n    const method = head ? 'HEAD' : 'GET'\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      fetch: this.fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk inserts.\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an INSERT into the table or view.\n   *\n   * By default, inserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to insert. Pass an object to insert a single row\n   * or an array to insert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count inserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. Only applies for bulk\n   * inserts.\n   */\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      count,\n      defaultToNull = true,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      this.headers.append('Prefer', `missing=default`)\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        this.url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk upserts.\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n    /**\n   * Perform an UPSERT on the table or view. Depending on the column(s) passed\n   * to `onConflict`, `.upsert()` allows you to perform the equivalent of\n   * `.insert()` if a row with the corresponding `onConflict` columns doesn't\n   * exist, or if it does exist, perform an alternative action depending on\n   * `ignoreDuplicates`.\n   *\n   * By default, upserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to upsert with. Pass an object to upsert a\n   * single row or an array to upsert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.onConflict - Comma-separated UNIQUE column(s) to specify how\n   * duplicate rows are determined. Two rows are duplicates if all the\n   * `onConflict` columns are equal.\n   *\n   * @param options.ignoreDuplicates - If `true`, duplicate rows are ignored. If\n   * `false`, duplicate rows are merged with existing rows.\n   *\n   * @param options.count - Count algorithm to use to count upserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. This only applies when\n   * inserting new rows, not when merging with existing rows under\n   * `ignoreDuplicates: false`. This also only applies when doing bulk upserts.\n   *\n   * @example Upsert a single row using a unique key\n   * ```ts\n   * // Upserting a single row, overwriting based on the 'username' unique column\n   * const { data, error } = await supabase\n   *   .from('users')\n   *   .upsert({ username: 'supabot' }, { onConflict: 'username' })\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     { id: 4, message: 'bar', username: 'supabot' }\n   * //   ],\n   * //   error: null\n   * // }\n   * ```\n   *\n   * @example Upsert with conflict resolution and exact row counting\n   * ```ts\n   * // Upserting and returning exact count\n   * const { data, error, count } = await supabase\n   *   .from('users')\n   *   .upsert(\n   *     {\n   *       id: 3,\n   *       message: 'foo',\n   *       username: 'supabot'\n   *     },\n   *     {\n   *       onConflict: 'username',\n   *       count: 'exact'\n   *     }\n   *   )\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     {\n   * //       id: 42,\n   * //       handle: \"saoirse\",\n   * //       display_name: \"Saoirse\"\n   * //     }\n   * //   ],\n   * //   count: 1,\n   * //   error: null\n   * // }\n   * ```\n   */\n\n\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      onConflict,\n      ignoreDuplicates = false,\n      count,\n      defaultToNull = true,\n    }: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n\n    this.headers.append('Prefer', `resolution=${ignoreDuplicates ? 'ignore' : 'merge'}-duplicates`)\n\n    if (onConflict !== undefined) this.url.searchParams.set('on_conflict', onConflict)\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      this.headers.append('Prefer', 'missing=default')\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        this.url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform an UPDATE on the table or view.\n   *\n   * By default, updated rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param values - The values to update with\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count updated rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  update<Row extends Relation extends { Update: unknown } ? Relation['Update'] : never>(\n    values: Row,\n    {\n      count,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'PATCH'\n  > {\n    const method = 'PATCH'\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform a DELETE on the table or view.\n   *\n   * By default, deleted rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count deleted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  delete({\n    count,\n  }: {\n    count?: 'exact' | 'planned' | 'estimated'\n  } = {}): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'DELETE'\n  > {\n    const method = 'DELETE'\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n","import PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { Fetch, GenericSchema, ClientServerOptions } from './types/common/common'\nimport { GetRpcFunctionFilterBuilderByArgs } from './types/common/rpc'\n\n/**\n * PostgREST client.\n *\n * @typeParam Database - Types for the schema from the [type\n * generator](https://supabase.com/docs/reference/javascript/next/typescript-support)\n *\n * @typeParam SchemaName - Postgres schema to switch to. Must be a string\n * literal, the same one passed to the constructor. If the schema is not\n * `\"public\"`, this must be supplied manually.\n */\nexport default class PostgrestClient<\n  Database = any,\n  ClientOptions extends ClientServerOptions = Database extends {\n    __InternalSupabase: infer I extends ClientServerOptions\n  }\n    ? I\n    : {},\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = 'public' extends keyof Omit<\n    Database,\n    '__InternalSupabase'\n  >\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  Schema extends GenericSchema = Omit<\n    Database,\n    '__InternalSupabase'\n  >[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : any,\n> {\n  url: string\n  headers: Headers\n  schemaName?: SchemaName\n  fetch?: Fetch\n\n  // TODO: Add back shouldThrowOnError once we figure out the typings\n  /**\n   * Creates a PostgREST client.\n   *\n   * @param url - URL of the PostgREST endpoint\n   * @param options - Named parameters\n   * @param options.headers - Custom headers\n   * @param options.schema - Postgres schema to switch to\n   * @param options.fetch - Custom fetch\n   * @example\n   * ```ts\n   * import PostgrestClient from '@supabase/postgrest-js'\n   *\n   * const postgrest = new PostgrestClient('https://xyzcompany.supabase.co/rest/v1', {\n   *   headers: { apikey: 'public-anon-key' },\n   *   schema: 'public',\n   * })\n   * ```\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: SchemaName\n      fetch?: Fetch\n    } = {}\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schemaName = schema\n    this.fetch = fetch\n  }\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any, any> {\n    if (!relation || typeof relation !== 'string' || relation.trim() === '') {\n      throw new Error('Invalid relation name: relation must be a non-empty string.')\n    }\n\n    const url = new URL(`${this.url}/${relation}`)\n    return new PostgrestQueryBuilder(url, {\n      headers: new Headers(this.headers),\n      schema: this.schemaName,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return new PostgrestClient(this.url, {\n      headers: this.headers,\n      schema,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @example\n   * ```ts\n   * // For cross-schema functions where type inference fails, use overrideTypes:\n   * const { data } = await supabase\n   *   .schema('schema_b')\n   *   .rpc('function_a', {})\n   *   .overrideTypes<{ id: string; user_id: string }[]>()\n   * ```\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    {\n      head = false,\n      get = false,\n      count,\n    }: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    let method: 'HEAD' | 'GET' | 'POST'\n    const url = new URL(`${this.url}/rpc/${fn}`)\n    let body: unknown | undefined\n    if (head || get) {\n      method = head ? 'HEAD' : 'GET'\n      Object.entries(args)\n        // params with undefined value needs to be filtered out, otherwise it'll\n        // show up as `?param=undefined`\n        .filter(([_, value]) => value !== undefined)\n        // array values need special syntax\n        .map(([name, value]) => [name, Array.isArray(value) ? `{${value.join(',')}}` : `${value}`])\n        .forEach(([name, value]) => {\n          url.searchParams.append(name, value)\n        })\n    } else {\n      method = 'POST'\n      body = args\n    }\n\n    const headers = new Headers(this.headers)\n    if (count) {\n      headers.set('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schemaName,\n      body,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n","// Always update wrapper.mjs when updating this file.\nimport PostgrestClient from './PostgrestClient'\nimport PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestError from './PostgrestError'\n\nexport {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport default {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport type {\n  PostgrestResponse,\n  PostgrestResponseFailure,\n  PostgrestResponseSuccess,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n} from './types/types'\nexport type { ClientServerOptions as PostgrestClientOptions } from './types/common/common'\n// https://github.com/supabase/postgrest-js/issues/551\n// To be replaced with a helper type that only uses public types\nexport type { GetResult as UnstableGetResult } from './select-query-parser/result'\n"],"names":["count: number | null","res","this","fetch","fetch","method: 'HEAD' | 'GET' | 'POST'","body: unknown | undefined"],"mappings":";;;;;;;;;;;;;;;;;;;;;GAKA,IAAqB,iBAArB,cAA4C,MAAM;;;;;;;;;;;;;IAkBhD,YAAY,OAAA,CAA2E;QACrF,KAAA,CAAM,QAAQ,OAAA,CAAQ;QACtB,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,OAAA,GAAU,QAAQ,OAAA;QACvB,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;QACpB,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;;;;;ACjBxB,IAA8B,mBAA9B,MAQA;;;;;;;;;;;;;IAwBE,YAAY,OAAA,CAUT;;aA5BO,kBAAA,GAAqB;QA6B7B,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,GAAA,GAAM,QAAQ,GAAA;QACnB,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,QAAQ,OAAA,CAAQ;QAC3C,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,IAAA,GAAO,QAAQ,IAAA;QACpB,IAAA,CAAK,kBAAA,GAAA,CAAA,wBAAqB,QAAQ,kBAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAsB;QACxD,IAAA,CAAK,MAAA,GAAS,QAAQ,MAAA;QACtB,IAAA,CAAK,aAAA,GAAA,CAAA,wBAAgB,QAAQ,aAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAiB;QAE9C,IAAI,QAAQ,KAAA,CACV,CAAA,IAAA,CAAK,KAAA,GAAQ,QAAQ,KAAA;aAErB,IAAA,CAAK,KAAA,GAAQ;;;;;;;IAUjB,eAAqE;QACnE,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;;;IAMT,UAAU,IAAA,EAAc,KAAA,EAAqB;QAC3C,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;QACxC,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,MAAM,MAAM;QAC7B,OAAO,IAAA;;IAGT,KAME,WAAA,EAQA,UAAA,EACkC;;QAElC,IAAI,IAAA,CAAK,MAAA,KAAW,KAAA,GAAW,CAAA,OAAA,IAEpB;YAAC;YAAO;SAAO,CAAC,QAAA,CAAS,IAAA,CAAK,MAAA,CAAO,CAC9C,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,kBAAkB,IAAA,CAAK,MAAA,CAAO;aAE/C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,mBAAmB,IAAA,CAAK,MAAA,CAAO;QAElD,IAAI,IAAA,CAAK,MAAA,KAAW,SAAS,IAAA,CAAK,MAAA,KAAW,OAC3C,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,gBAAgB,mBAAmB;QAKtD,MAAM,SAAS,IAAA,CAAK,KAAA;QACpB,IAAI,MAAM,OAAO,IAAA,CAAK,GAAA,CAAI,QAAA,EAAU,EAAE;YACpC,QAAQ,IAAA,CAAK,MAAA;YACb,SAAS,IAAA,CAAK,OAAA;YACd,MAAM,KAAK,SAAA,CAAU,IAAA,CAAK,IAAA,CAAK;YAC/B,QAAQ,IAAA,CAAK,MAAA;SACd,CAAC,CAAC,IAAA,CAAK,OAAO,UAAQ;YACrB,IAAI,QAAQ;YACZ,IAAI,OAAO;YACX,IAAIA,QAAuB;YAC3B,IAAI,SAASC,MAAI,MAAA;YACjB,IAAI,aAAaA,MAAI,UAAA;YAErB,IAAIA,MAAI,EAAA,EAAI;;gBACV,IAAIC,MAAK,MAAA,KAAW,QAAQ;;oBAC1B,MAAM,OAAO,MAAMD,MAAI,IAAA,EAAM;oBAC7B,IAAI,SAAS,IAAI,CAAA,OAAA,IAENC,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,KAAK,WACxC,CAAA,OAAO;6BAEPA,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,IAAA,CAAA,CAAA,oBAC1BA,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,MAAA,QAAA,sBAAA,KAAA,IAAA,KAAA,IAAA,kBAAE,QAAA,CAAS,kCAAkC,EAEvE,CAAA,OAAO;yBAEP,OAAO,KAAK,KAAA,CAAM,KAAK;;gBAI3B,MAAM,cAAA,CAAA,qBAAcA,MAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,MAAA,QAAA,uBAAA,KAAA,IAAA,KAAA,IAAA,mBAAE,KAAA,CAAM,kCAAkC;gBACxF,MAAM,eAAA,CAAA,mBAAeD,MAAI,OAAA,CAAQ,GAAA,CAAI,gBAAgB,MAAA,QAAA,qBAAA,KAAA,IAAA,KAAA,IAAA,iBAAE,KAAA,CAAM,IAAI;gBACjE,IAAI,eAAe,gBAAgB,aAAa,MAAA,GAAS,EACvD,CAAA,QAAQ,SAAS,YAAA,CAAa,EAAA,CAAG;gBAKnC,IAAIC,MAAK,aAAA,IAAiBA,MAAK,MAAA,KAAW,SAAS,MAAM,OAAA,CAAQ,KAAK,CACpE,CAAA,IAAI,KAAK,MAAA,GAAS,GAAG;oBACnB,QAAQ;wBAEN,MAAM;wBACN,SAAS,CAAA,gBAAA,EAAmB,KAAK,MAAA,CAAO,uDAAA,CAAA;wBACxC,MAAM;wBACN,SAAS;qBACV;oBACD,OAAO;oBACP,QAAQ;oBACR,SAAS;oBACT,aAAa;2BACJ,KAAK,MAAA,KAAW,EACzB,CAAA,OAAO,IAAA,CAAK,EAAA;qBAEZ,OAAO;mBAGN;;gBACL,MAAM,OAAO,MAAMD,MAAI,IAAA,EAAM;gBAE7B,IAAI;oBACF,QAAQ,KAAK,KAAA,CAAM,KAAK;oBAGxB,IAAI,MAAM,OAAA,CAAQ,MAAM,IAAIA,MAAI,MAAA,KAAW,KAAK;wBAC9C,OAAO,EAAE;wBACT,QAAQ;wBACR,SAAS;wBACT,aAAa;;kCAET;oBAEN,IAAIA,MAAI,MAAA,KAAW,OAAO,SAAS,IAAI;wBACrC,SAAS;wBACT,aAAa;0BAEb,CAAA,QAAQ;wBACN,SAAS;oBAAA,CACV;;gBAIL,IAAI,SAASC,MAAK,aAAA,IAAA,CAAA,UAAA,QAAA,UAAA,KAAA,KAAA,CAAA,iBAAiB,MAAO,OAAA,MAAA,QAAA,mBAAA,KAAA,IAAA,KAAA,IAAA,eAAS,QAAA,CAAS,SAAS,GAAE;oBACrE,QAAQ;oBACR,SAAS;oBACT,aAAa;;gBAGf,IAAI,SAASA,MAAK,kBAAA,CAChB,CAAA,MAAM,IAAI,eAAe,MAAM;;YAYnC,OAR0B;gBACxB;gBACA;gBACA;gBACA;gBACA;aACD;UAGD;QACF,IAAI,CAAC,IAAA,CAAK,kBAAA,CACR,CAAA,MAAM,IAAI,KAAA,CAAA,CAAO,eAAe;;YAI9B,IAAI,eAAe;YAGnB,MAAM,QAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAQ,WAAY,KAAA;YAC1B,IAAI,OAAO;;gBACT,MAAM,eAAA,CAAA,iBAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAe,MAAO,OAAA,MAAA,QAAA,mBAAA,KAAA,IAAA,iBAAW;gBACvC,MAAM,YAAA,CAAA,cAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAY,MAAO,IAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAQ;gBAEjC,eAAe,GAAA,CAAA,mBAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAG,WAAY,IAAA,MAAA,QAAA,qBAAA,KAAA,IAAA,mBAAQ,aAAa,EAAA,EAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAI,WAAY,OAAA,EAAA;gBACnE,gBAAgB,CAAA,eAAA,EAAA,CAAA,cAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAkB,MAAO,IAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAQ,QAAQ,EAAA,EAAI,cAAA;gBAC7D,IAAI,UACF,CAAA,gBAAgB,CAAA,EAAA,EAAK,UAAU,CAAA,CAAA;gBAEjC,IAAA,UAAA,QAAA,UAAA,KAAA,IAAA,KAAA,IAAI,MAAO,KAAA,CACT,CAAA,gBAAgB,CAAA,EAAA,EAAK,MAAM,KAAA,EAAA;mBAExB;;gBAEL,eAAA,CAAA,oBAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAe,WAAY,KAAA,MAAA,QAAA,sBAAA,KAAA,IAAA,oBAAS;;YAGtC,OAAO;gBACL,OAAO;oBACL,SAAS,GAAA,CAAA,oBAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAG,WAAY,IAAA,MAAA,QAAA,sBAAA,KAAA,IAAA,oBAAQ,aAAa,EAAA,EAAA,eAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAI,WAAY,OAAA,EAAA;oBAC7D,SAAS;oBACT,MAAM;oBACN,MAAM;iBACP;gBACD,MAAM;gBACN,OAAO;gBACP,QAAQ;gBACR,YAAY;aACb;UACD;QAGJ,OAAO,IAAI,IAAA,CAAK,aAAa,WAAW;;;;;;;IAS1C,UAIE;mCAEA,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;IA6BT,gBAYE;QACA,OAAO,IAAA;;;;;AC1TX,IAAqB,4BAArB,cAQU,iBAAwC;;;;;;;;;IAUhD,OAIE,OAAA,EAaA;QAEA,IAAI,SAAS;QACb,MAAM,iBAAA,CAAkB,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,GAAA,EAChC,KAAA,CAAM,GAAG,CACT,GAAA,CAAA,CAAK,MAAM;YACV,IAAI,KAAK,IAAA,CAAK,EAAE,IAAI,CAAC,OACnB,CAAA,OAAO;YAET,IAAI,MAAM,KACR,CAAA,SAAS,CAAC;YAEZ,OAAO;UACP,CACD,IAAA,CAAK,GAAG;QACX,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAU,eAAe;QACnD,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,wBAAwB;QACtD,OAAO,IAAA;;;;;;;;;;;;;;;;;;;IAuDT,MACE,MAAA,EACA,EACE,YAAY,IAAA,EACZ,UAAA,EACA,YAAA,EACA,kBAAkB,YAAA,EAAA,GAMhB,CAAA,CAAE,EACA;QACN,MAAM,MAAM,kBAAkB,GAAG,gBAAgB,MAAA,CAAA,GAAU;QAC3D,MAAM,gBAAgB,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,IAAI;QAEpD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CACpB,KACA,GAAG,gBAAgB,GAAG,cAAc,CAAA,CAAA,GAAK,KAAK,OAAO,CAAA,EAAG,YAAY,QAAQ,SAC1E,eAAe,KAAA,IAAY,KAAK,aAAa,gBAAgB,cAAA,CAEhE;QACD,OAAO,IAAA;;;;;;;;;;;IAaT,MACE,KAAA,EACA,EACE,YAAA,EACA,kBAAkB,YAAA,EAAA,GACqC,CAAA,CAAE,EACrD;QACN,MAAM,MAAM,OAAO,oBAAoB,cAAc,UAAU,GAAG,gBAAgB,MAAA,CAAA;QAClF,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,KAAK,GAAG,OAAA,CAAQ;QAC1C,OAAO,IAAA;;;;;;;;;;;;;;;;IAkBT,MACE,IAAA,EACA,EAAA,EACA,EACE,YAAA,EACA,kBAAkB,YAAA,EAAA,GACqC,CAAA,CAAE,EACrD;QACN,MAAM,YACJ,OAAO,oBAAoB,cAAc,WAAW,GAAG,gBAAgB,OAAA,CAAA;QACzE,MAAM,WAAW,OAAO,oBAAoB,cAAc,UAAU,GAAG,gBAAgB,MAAA,CAAA;QACvF,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,WAAW,GAAG,MAAA,CAAO;QAE/C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAU,GAAG,KAAK,OAAO,GAAA,CAAI;QACvD,OAAO,IAAA;;;;;;IAQT,YAAY,MAAA,EAA2B;QACrC,IAAA,CAAK,MAAA,GAAS;QACd,OAAO,IAAA;;;;;;;IAST,SAGE;QACA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,oCAAoC;QAC/D,OAAO,IAAA;;;;;;;IAST,cAEuD;QAGrD,IAAI,IAAA,CAAK,MAAA,KAAW,MAClB,CAAA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,mBAAmB;aAE9C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,oCAAoC;QAEjE,IAAA,CAAK,aAAA,GAAgB;QACrB,OAAO,IAAA;;;;IAMT,MAA+C;QAC7C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,WAAW;QACtC,OAAO,IAAA;;;;IAMT,UAAoE;QAClE,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,UAAU,uBAAuB;QAClD,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;IA4BT,QAAQ,EACN,UAAU,KAAA,EACV,UAAU,KAAA,EACV,WAAW,KAAA,EACX,UAAU,KAAA,EACV,MAAM,KAAA,EACN,SAAS,MAAA,EAAA,GAQP,CAAA,CAAE,EAAE;;QACN,MAAM,UAAU;YACd,UAAU,YAAY;YACtB,UAAU,YAAY;YACtB,WAAW,aAAa;YACxB,UAAU,YAAY;YACtB,MAAM,QAAQ;SACf,CACE,MAAA,CAAO,QAAQ,CACf,IAAA,CAAK,IAAI;QAEZ,MAAM,eAAA,CAAA,oBAAe,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAS,MAAA,QAAA,sBAAA,KAAA,IAAA,oBAAI;QACnD,IAAA,CAAK,OAAA,CAAQ,GAAA,CACX,UACA,CAAA,2BAAA,EAA8B,OAAO,OAAA,EAAS,aAAa,WAAA,EAAa,QAAQ,CAAA,CAAA,CACjF;QACD,IAAI,WAAW,OACb,CAAA,OAAO,IAAA;aAEP,OAAO,IAAA;;;;;;IASX,WAAiB;QACf,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,cAAc;QAC5C,OAAO,IAAA;;;;;;;IAST,UAQE;QACA,OAAO,IAAA;;;;;;;IAiBT,YAAY,KAAA,EAKiE;QAC3E,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,kBAAkB;QAChD,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,aAAA,EAAgB,OAAA,CAAQ;QACtD,OAAO,IAAA;;;;;AC3UX,MAAM,+BAAA,aAAA,GAA+B,IAAI,OAAO,QAAQ;AA2CxD,IAAqB,yBAArB,cAQU,0BAQR;;;;;;;;IASA,GACE,MAAA,EACA,KAAA,EAQM;QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;IAST,IACE,MAAA,EACA,KAAA,EAKM;QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;IAWT,GAAG,MAAA,EAAgB,KAAA,EAAsB;QACvC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;IAWT,IAAI,MAAA,EAAgB,KAAA,EAAsB;QACxC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;IAWT,GAAG,MAAA,EAAgB,KAAA,EAAsB;QACvC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;IAWT,IAAI,MAAA,EAAgB,KAAA,EAAsB;QACxC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;IAWT,KAAK,MAAA,EAAgB,OAAA,EAAuB;QAC1C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,KAAA,EAAQ,SAAA,CAAU;QACvD,OAAO,IAAA;;;;;;;IAcT,UAAU,MAAA,EAAgB,QAAA,EAAmC;QAC3D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,WAAA,EAAc,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QACzE,OAAO,IAAA;;;;;;;IAcT,UAAU,MAAA,EAAgB,QAAA,EAAmC;QAC3D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,WAAA,EAAc,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QACzE,OAAO,IAAA;;;;;;;IAWT,MAAM,MAAA,EAAgB,OAAA,EAAuB;QAC3C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,MAAA,EAAS,SAAA,CAAU;QACxD,OAAO,IAAA;;;;;;;IAcT,WAAW,MAAA,EAAgB,QAAA,EAAmC;QAC5D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,YAAA,EAAe,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QAC1E,OAAO,IAAA;;;;;;;IAcT,WAAW,MAAA,EAAgB,QAAA,EAAmC;QAC5D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,YAAA,EAAe,SAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QAC1E,OAAO,IAAA;;;;;;;;IAYT,WAAW,MAAA,EAAgB,OAAA,EAAuB;QAChD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,MAAA,EAAS,SAAA,CAAU;QACxD,OAAO,IAAA;;;;;;;;IAYT,YAAY,MAAA,EAAgB,OAAA,EAAuB;QACjD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,OAAA,EAAU,SAAA,CAAU;QACzD,OAAO,IAAA;;;;;;;;;;;;;IAoBT,GAAG,MAAA,EAAgB,KAAA,EAA6B;QAC9C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;;;;;IAaT,WACE,MAAA,EACA,KAAA,EAKM;QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,WAAA,EAAc,OAAA,CAAQ;QAC3D,OAAO,IAAA;;;;;;;IAST,GACE,MAAA,EACA,MAAA,EAUM;QACN,MAAM,gBAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,OAAO,CAAC,CAC9C,GAAA,CAAA,CAAK,MAAM;YAGV,IAAI,OAAO,MAAM,YAAY,6BAA6B,IAAA,CAAK,EAAE,CAAE,CAAA,OAAO,CAAA,CAAA,EAAI,EAAE,CAAA,CAAA;iBAC3E,OAAO,GAAG,GAAA;UACf,CACD,IAAA,CAAK,IAAI;QACZ,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,cAAc,CAAA,CAAA,CAAG;QAC7D,OAAO,IAAA;;;;;;;IAST,MACE,MAAA,EACA,MAAA,EAOM;QACN,MAAM,gBAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,OAAO,CAAC,CAC9C,GAAA,CAAA,CAAK,MAAM;YAGV,IAAI,OAAO,MAAM,YAAY,6BAA6B,IAAA,CAAK,EAAE,CAAE,CAAA,OAAO,CAAA,CAAA,EAAI,EAAE,CAAA,CAAA;iBAC3E,OAAO,GAAG,GAAA;UACf,CACD,IAAA,CAAK,IAAI;QACZ,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,QAAA,EAAW,cAAc,CAAA,CAAA,CAAG;QACjE,OAAO,IAAA;;;;;;;;IAeT,SAAS,MAAA,EAAgB,KAAA,EAAoE;QAC3F,IAAI,OAAO,UAAU,SAGnB,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;iBAC1C,MAAM,OAAA,CAAQ,MAAM,CAE7B,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;aAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,MAAM,EAAA,CAAG;QAErE,OAAO,IAAA;;;;;;;;IAeT,YAAY,MAAA,EAAgB,KAAA,EAAoE;QAC9F,IAAI,OAAO,UAAU,SAEnB,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;iBAC1C,MAAM,OAAA,CAAQ,MAAM,CAE7B,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;aAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,MAAM,EAAA,CAAG;QAErE,OAAO,IAAA;;;;;;;;IAYT,QAAQ,MAAA,EAAgB,KAAA,EAAqB;QAC3C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;;;IAaT,SAAS,MAAA,EAAgB,KAAA,EAAqB;QAC5C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;;IAYT,QAAQ,MAAA,EAAgB,KAAA,EAAqB;QAC3C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;QACnD,OAAO,IAAA;;;;;;;;;IAaT,SAAS,MAAA,EAAgB,KAAA,EAAqB;QAC5C,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;;;IAaT,cAAc,MAAA,EAAgB,KAAA,EAAqB;QACjD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,OAAA,CAAQ;QACpD,OAAO,IAAA;;;;;;;;IAeT,SAAS,MAAA,EAAgB,KAAA,EAA0C;QACjE,IAAI,OAAO,UAAU,SAEnB,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;aAGnD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG;QAEjE,OAAO,IAAA;;;;;;;;;;;IAuBT,WACE,MAAA,EACA,KAAA,EACA,EAAE,MAAA,EAAQ,IAAA,EAAA,GAAuE,CAAA,CAAE,EAC7E;QACN,IAAI,WAAW;QACf,IAAI,SAAS,QACX,CAAA,WAAW;iBACF,SAAS,SAClB,CAAA,WAAW;iBACF,SAAS,YAClB,CAAA,WAAW;QAEb,MAAM,aAAa,WAAW,KAAA,IAAY,KAAK,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA;QAC1D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,GAAG,SAAS,GAAA,EAAK,WAAW,CAAA,EAAG,OAAA,CAAQ;QAC5E,OAAO,IAAA;;;;;;;;IAYT,MAAM,KAAA,EAAsC;QAC1C,OAAO,OAAA,CAAQ,MAAM,CAAC,OAAA,CAAA,CAAS,CAAC,QAAQ,MAAA,KAAW;YACjD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,GAAA,EAAM,OAAA,CAAQ;UACnD;QACF,OAAO,IAAA;;;;;;;;;;;;;;IAsBT,IAAI,MAAA,EAAgB,QAAA,EAAkB,KAAA,EAAsB;QAC1D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,CAAA,IAAA,EAAO,SAAS,CAAA,EAAG,OAAA,CAAQ;QAChE,OAAO,IAAA;;;;;;;;;;;;;;;;IAkBT,GACE,OAAA,EACA,EACE,YAAA,EACA,kBAAkB,YAAA,EAAA,GACqC,CAAA,CAAE,EACrD;QACN,MAAM,MAAM,kBAAkB,GAAG,gBAAgB,GAAA,CAAA,GAAO;QACxD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,KAAK,CAAA,CAAA,EAAI,QAAQ,CAAA,CAAA,CAAG;QACjD,OAAO,IAAA;;;;;;;;;;;;;;IAsBT,OAAO,MAAA,EAAgB,QAAA,EAAkB,KAAA,EAAsB;QAC7D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,QAAQ,GAAG,SAAS,CAAA,EAAG,OAAA,CAAQ;QAC5D,OAAO,IAAA;;;;;AClqBX,IAAqB,wBAArB,MAME;;;;;;;;;;;;;IAoBA,YACE,GAAA,EACA,EACE,UAAU,CAAA,CAAE,EACZ,MAAA,EACA,OAAA,OAAA,EAAA,CAMF;QACA,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,QAAQ;QACnC,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,KAAA,GAAQC;;;;;;;;;;;;;;;;;;;;;;IAwBf,OAWE,OAAA,EACA,OAAA,EAYA;QACA,MAAM,EAAE,OAAO,KAAA,EAAO,KAAA,EAAA,GAAU,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,CAAA,CAAE;QAE7C,MAAM,SAAS,OAAO,SAAS;QAE/B,IAAI,SAAS;QACb,MAAM,iBAAA,CAAkB,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,GAAA,EAChC,KAAA,CAAM,GAAG,CACT,GAAA,CAAA,CAAK,MAAM;YACV,IAAI,KAAK,IAAA,CAAK,EAAE,IAAI,CAAC,OACnB,CAAA,OAAO;YAET,IAAI,MAAM,KACR,CAAA,SAAS,CAAC;YAEZ,OAAO;UACP,CACD,IAAA,CAAK,GAAG;QACX,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,UAAU,eAAe;QAEnD,IAAI,MACF,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAGjD,OAAO,IAAI,uBAAuB;YAChC;YACA,KAAK,IAAA,CAAK,GAAA;YACV,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;IA2DJ,OACE,MAAA,EACA,EACE,KAAA,EACA,gBAAgB,IAAA,EAAA,GAId,CAAA,CAAE,EASN;;QACA,MAAM,SAAS;QAEf,IAAI,MACF,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAEjD,IAAI,CAAC,cACH,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,eAAA,CAAA,CAAkB;QAGlD,IAAI,MAAM,OAAA,CAAQ,OAAO,EAAE;YACzB,MAAM,UAAU,OAAO,MAAA,CAAA,CAAQ,KAAK,IAAM,IAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,EAAE,EAAE,CAAa;YACrF,IAAI,QAAQ,MAAA,GAAS,GAAG;gBACtB,MAAM,gBAAgB,CAAC;uBAAG,IAAI,IAAI,QAAQ;iBAAC,CAAC,GAAA,CAAA,CAAK,SAAW,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA,CAAG;gBAC1E,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,WAAW,cAAc,IAAA,CAAK,IAAI,CAAC;;;QAIjE,OAAO,IAAI,uBAAuB;YAChC;YACA,KAAK,IAAA,CAAK,GAAA;YACV,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,MAAM;YACN,OAAA,CAAA,cAAO,IAAA,CAAK,KAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAS;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA4HJ,OACE,MAAA,EACA,EACE,UAAA,EACA,mBAAmB,KAAA,EACnB,KAAA,EACA,gBAAgB,IAAA,EAAA,GAMd,CAAA,CAAE,EASN;;QACA,MAAM,SAAS;QAEf,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,WAAA,EAAc,mBAAmB,WAAW,QAAQ,WAAA,CAAA,CAAa;QAE/F,IAAI,eAAe,KAAA,EAAW,CAAA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,eAAe,WAAW;QAClF,IAAI,MACF,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAEjD,IAAI,CAAC,cACH,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,kBAAkB;QAGlD,IAAI,MAAM,OAAA,CAAQ,OAAO,EAAE;YACzB,MAAM,UAAU,OAAO,MAAA,CAAA,CAAQ,KAAK,IAAM,IAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,EAAE,EAAE,CAAa;YACrF,IAAI,QAAQ,MAAA,GAAS,GAAG;gBACtB,MAAM,gBAAgB,CAAC;uBAAG,IAAI,IAAI,QAAQ;iBAAC,CAAC,GAAA,CAAA,CAAK,SAAW,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA,CAAG;gBAC1E,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,WAAW,cAAc,IAAA,CAAK,IAAI,CAAC;;;QAIjE,OAAO,IAAI,uBAAuB;YAChC;YACA,KAAK,IAAA,CAAK,GAAA;YACV,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,MAAM;YACN,OAAA,CAAA,eAAO,IAAA,CAAK,KAAA,MAAA,QAAA,iBAAA,KAAA,IAAA,eAAS;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;;;IAwBJ,OACE,MAAA,EACA,EACE,KAAA,EAAA,GAGE,CAAA,CAAE,EASN;;QACA,MAAM,SAAS;QACf,IAAI,MACF,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAGjD,OAAO,IAAI,uBAAuB;YAChC;YACA,KAAK,IAAA,CAAK,GAAA;YACV,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,MAAM;YACN,OAAA,CAAA,eAAO,IAAA,CAAK,KAAA,MAAA,QAAA,iBAAA,KAAA,IAAA,eAAS;SACtB,CAAC;;;;;;;;;;;;;;;;;;;;IAsBJ,OAAO,EACL,KAAA,EAAA,GAGE,CAAA,CAAE,EAQJ;;QACA,MAAM,SAAS;QACf,IAAI,MACF,CAAA,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAGjD,OAAO,IAAI,uBAAuB;YAChC;YACA,KAAK,IAAA,CAAK,GAAA;YACV,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,OAAA,CAAA,eAAO,IAAA,CAAK,KAAA,MAAA,QAAA,iBAAA,KAAA,IAAA,eAAS;SACtB,CAAC;;;;;;;;;;;;;;GCteN,IAAqB,kBAArB,MAAqB,gBAoBnB;;;;;;;;;;;;;;;;;;IAyBA,YACE,GAAA,EACA,EACE,UAAU,CAAA,CAAE,EACZ,MAAA,EACA,OAAA,OAAA,EAAA,GAKE,CAAA,CAAE,CACN;QACA,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU,IAAI,QAAQ,QAAQ;QACnC,IAAA,CAAK,UAAA,GAAa;QAClB,IAAA,CAAK,KAAA,GAAQC;;;;;;IAcf,KAAK,QAAA,EAA0E;QAC7E,IAAI,CAAC,YAAY,OAAO,aAAa,YAAY,SAAS,IAAA,EAAM,KAAK,GACnE,CAAA,MAAM,IAAI,MAAM,8DAA8D;QAIhF,OAAO,IAAI,sBADC,IAAI,IAAI,GAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,UAAA,CAAW,EACR;YACpC,SAAS,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;YAClC,QAAQ,IAAA,CAAK,UAAA;YACb,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;;;;;;;;IAUJ,OACE,MAAA,EAMA;QACA,OAAO,IAAI,gBAAgB,IAAA,CAAK,GAAA,EAAK;YACnC,SAAS,IAAA,CAAK,OAAA;YACd;YACA,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAmCJ,IASE,EAAA,EACA,OAAa,CAAA,CAAE,EACf,EACE,OAAO,KAAA,EACP,MAAM,KAAA,EACN,KAAA,EAAA,GAKE,CAAA,CAAE,EASN;;QACA,IAAIC;QACJ,MAAM,MAAM,IAAI,IAAI,GAAG,IAAA,CAAK,GAAA,CAAI,KAAA,EAAO,IAAA,CAAK;QAC5C,IAAIC;QACJ,IAAI,QAAQ,KAAK;YACf,SAAS,OAAO,SAAS;YACzB,OAAO,OAAA,CAAQ,KAAK,CAGjB,MAAA,CAAA,CAAQ,CAAC,GAAG,MAAA,GAAW,UAAU,KAAA,EAAU,CAE3C,GAAA,CAAA,CAAK,CAAC,MAAM,MAAA,GAAW;oBAAC;oBAAM,MAAM,OAAA,CAAQ,MAAM,GAAG,CAAA,CAAA,EAAI,MAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,GAAK,GAAG,OAAA;iBAAQ,CAAC,CAC1F,OAAA,CAAA,CAAS,CAAC,MAAM,MAAA,KAAW;gBAC1B,IAAI,YAAA,CAAa,MAAA,CAAO,MAAM,MAAM;cACpC;eACC;YACL,SAAS;YACT,OAAO;;QAGT,MAAM,UAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ;QACzC,IAAI,MACF,CAAA,QAAQ,GAAA,CAAI,UAAU,CAAA,MAAA,EAAS,OAAA,CAAQ;QAGzC,OAAO,IAAI,uBAAuB;YAChC;YACA;YACA;YACA,QAAQ,IAAA,CAAK,UAAA;YACb;YACA,OAAA,CAAA,cAAO,IAAA,CAAK,KAAA,MAAA,QAAA,gBAAA,KAAA,IAAA,cAAS;SACtB,CAAC;;;;;ACxMN,IAAA,cAAe;IACb;IACA;IACA;IACA;IACA;IACA;CACD"}},
    {"offset": {"line": 1437, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/index.mjs","sources":["file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/errors.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/helpers.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/fetch.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/packages/StreamDownloadBuilder.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/packages/BlobDownloadBuilder.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/packages/StorageFileApi.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/version.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/constants.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/packages/StorageBucketApi.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/packages/StorageAnalyticsClient.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/constants.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/errors.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/helpers.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/fetch.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/VectorIndexApi.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/VectorDataApi.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/VectorBucketApi.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/lib/vectors/StorageVectorsClient.ts","file:///home/runner/workspace/node_modules/%40supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["export class StorageError extends Error {\n  protected __isStorageError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageError'\n  }\n}\n\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\nexport class StorageApiError extends StorageError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n * source: https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Validates if a given bucket name is valid according to Supabase Storage API rules\n * Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n *\n * Rules:\n * - Length: 1-100 characters\n * - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n * - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n * - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n *\n * AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n *\n * @param bucketName - The bucket name to validate\n * @returns true if valid, false otherwise\n */\nexport const isValidBucketName = (bucketName: string): boolean => {\n  if (!bucketName || typeof bucketName !== 'string') {\n    return false\n  }\n\n  // Check length constraints (1-100 characters)\n  if (bucketName.length === 0 || bucketName.length > 100) {\n    return false\n  }\n\n  // Check for leading/trailing whitespace\n  if (bucketName.trim() !== bucketName) {\n    return false\n  }\n\n  // Explicitly reject path separators (security)\n  // Note: Consecutive periods (..) are allowed by backend - the AWS restriction\n  // on relative paths applies to object keys, not bucket names\n  if (bucketName.includes('/') || bucketName.includes('\\\\')) {\n    return false\n  }\n\n  // Validate against allowed character set\n  // Pattern matches backend regex: /^(\\w|!|-|\\.|\\*|'|\\(|\\)| |&|\\$|@|=|;|:|\\+|,|\\?)*$/\n  // This explicitly excludes path separators (/, \\) and other problematic characters\n  const bucketNameRegex = /^[\\w!.\\*'() &$@=;:+,?-]+$/\n  return bucketNameRegex.test(bucketName)\n}\n","import { StorageApiError, StorageUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\nconst _getErrorMessage = (err: any): string =>\n  err.msg ||\n  err.message ||\n  err.error_description ||\n  (typeof err.error === 'string' ? err.error : err.error?.message) ||\n  JSON.stringify(err)\n\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  const Res = await resolveResponse()\n\n  if (error instanceof Res && !options?.noResolveJson) {\n    error\n      .json()\n      .then((err) => {\n        const status = error.status || 500\n        const statusCode = err?.statusCode || status + ''\n        reject(new StorageApiError(_getErrorMessage(err), status, statusCode))\n      })\n      .catch((err) => {\n        reject(new StorageUnknownError(_getErrorMessage(err), err))\n      })\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error))\n  }\n}\n\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\nexport async function head(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(\n    fetcher,\n    'HEAD',\n    url,\n    {\n      ...options,\n      noResolveJson: true,\n    },\n    parameters\n  )\n}\n\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements Promise<DownloadResult<Blob>> {\n  readonly [Symbol.toStringTag]: string = 'BlobDownloadBuilder'\n  private promise: Promise<DownloadResult<Blob>> | null = null\n\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.getPromise().then(onfulfilled, onrejected)\n  }\n\n  catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | null\n  ): Promise<DownloadResult<Blob> | TResult> {\n    return this.getPromise().catch(onrejected)\n  }\n\n  finally(onfinally?: (() => void) | null): Promise<DownloadResult<Blob>> {\n    return this.getPromise().finally(onfinally)\n  }\n\n  private getPromise(): Promise<DownloadResult<Blob>> {\n    if (!this.promise) {\n      this.promise = this.execute()\n    }\n    return this.promise\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { isStorageError, StorageError, StorageUnknownError } from '../lib/errors'\nimport { Fetch, get, head, post, put, remove } from '../lib/fetch'\nimport { recursiveToCamel, resolveFetch } from '../lib/helpers'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected bucketId?: string\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    this.url = url\n    this.headers = headers\n    this.bucketId = bucketId\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        // Only append if not already present\n        if (!body.has('cacheControl')) {\n          body.append('cacheControl', options.cacheControl as string)\n        }\n        if (metadata && !body.has('metadata')) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n\n        // Node.js streams require duplex option for fetch in Node 20+\n        // Check for both web ReadableStream and Node.js streams\n        const isStream =\n          (typeof ReadableStream !== 'undefined' && body instanceof ReadableStream) ||\n          (body && typeof body === 'object' && 'pipe' in body && typeof body.pipe === 'function')\n\n        if (isStream && !options.duplex) {\n          options.duplex = 'half'\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return {\n        data: { path: cleanPath, id: data.Id, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Upload file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: false\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Upload file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import { decode } from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n   * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n   * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n   * @returns Promise with response containing file path and fullPath or error\n   *\n   * @example Upload to a signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"fullPath\": \"avatars/folder/cat.jpg\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    try {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return {\n        data: { path: cleanPath, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   * @returns Promise with response containing signed upload URL, token, and path or error\n   *\n   * @example Create Signed Upload URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUploadUrl('folder/cat.jpg')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"token\": \"<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { data: { signedUrl: url.toString(), path, token }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @category File Buckets\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Update file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: true\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Update file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import {decode} from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Move file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .move('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully moved\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing copied file path or error\n   *\n   * @example Copy file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .copy('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"avatars/private/avatar2.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data: { path: data.Key }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Promise with response containing signed URL or error\n   *\n   * @example Create Signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Create a signed URL for an asset with transformations\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Create a signed URL which triggers the download of the asset\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     download: true,\n   *   })\n   * ```\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      data = { signedUrl }\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n   *\n   * @example Create Signed URLs\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar1.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *     },\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar2.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return {\n        data: data.map((datum: { signedURL: string }) => ({\n          ...datum,\n          signedUrl: datum.signedURL\n            ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n            : null,\n        })),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @category File Buckets\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns BlobDownloadBuilder instance for downloading the file\n   *\n   * @example Download file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": <BLOB>,\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Download file with transformations\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *       quality: 80\n   *     }\n   *   })\n   * ```\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n        headers: this.headers,\n        noResolveJson: true,\n      })\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing file metadata or error\n   *\n   * @example Get file info\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .info('folder/avatar1.png')\n   * ```\n   */\n  async info(path: string): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: recursiveToCamel(data) as Camelize<FileObjectV2>, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Checks the existence of a file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing boolean indicating file existence or error\n   *\n   * @example Check file existence\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .exists('folder/avatar1.png')\n   * ```\n   */\n  async exists(path: string): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError as unknown as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @category File Buckets\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Object with public URL\n   *\n   * @example Returns the URL for an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n   *   }\n   * }\n   * ```\n   *\n   * @example Returns the URL for an asset in a public bucket with transformations\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Returns the URL which triggers the download of an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     download: true,\n   *   })\n   * ```\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString: string[] = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @category File Buckets\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   * @returns Promise with response containing array of deleted file objects or error\n   *\n   * @example Delete file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .remove(['folder/avatar1.png'])\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async remove(paths: string[]): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   *\n   * @category File Buckets\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   * @param parameters Optional fetch parameters including signal for cancellation\n   * @returns Promise with response containing array of files or error\n   *\n   * @example List files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"avatar1.png\",\n   *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n   *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n   *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"metadata\": {\n   *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n   *         \"size\": 32175,\n   *         \"mimetype\": \"image/png\",\n   *         \"cacheControl\": \"max-age=3600\",\n   *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n   *         \"contentLength\": 32175,\n   *         \"httpStatusCode\": 200\n   *       }\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Search files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *     search: 'jon'\n   *   })\n   * ```\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   *\n   * @category File Buckets\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...options }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params: string[] = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.89.0'\n","import { version } from './version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, put, remove } from '../lib/fetch'\nimport { resolveFetch } from '../lib/helpers'\nimport { Bucket, BucketType, ListBucketOptions } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    this.url = baseUrl.href.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   *\n   * @category File Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of buckets or error\n   *\n   * @example List buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets()\n   * ```\n   *\n   * @example List buckets with options\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc',\n   *     search: 'prod'\n   *   })\n   * ```\n   */\n  async listBuckets(options?: ListBucketOptions): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const queryString = this.listBucketOptionsToQueryString(options)\n      const data = await get(this.fetch, `${this.url}/bucket${queryString}`, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   * @returns Promise with response containing bucket details or error\n   *\n   * @example Get bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .getBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"id\": \"avatars\",\n   *     \"name\": \"avatars\",\n   *     \"owner\": \"\",\n   *     \"public\": false,\n   *     \"file_size_limit\": 1024,\n   *     \"allowed_mime_types\": [\n   *       \"image/png\"\n   *     ],\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async getBucket(id: string): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   * @returns Promise with response containing newly created bucket name or error\n   *\n   * @example Create bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .createBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"avatars\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Update bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .updateBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully updated\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to empty.\n   * @returns Promise with success message or error\n   *\n   * @example Empty bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .emptyBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully emptied\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async emptyBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket/${id}/empty`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to delete.\n   * @returns Promise with success message or error\n   *\n   * @example Delete bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .deleteBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  private listBucketOptionsToQueryString(options?: ListBucketOptions): string {\n    const params: Record<string, string> = {}\n    if (options) {\n      if ('limit' in options) {\n        params.limit = String(options.limit)\n      }\n      if ('offset' in options) {\n        params.offset = String(options.offset)\n      }\n      if (options.search) {\n        params.search = options.search\n      }\n      if (options.sortColumn) {\n        params.sortColumn = options.sortColumn\n      }\n      if (options.sortOrder) {\n        params.sortOrder = options.sortOrder\n      }\n    }\n    return Object.keys(params).length > 0 ? '?' + new URLSearchParams(params).toString() : ''\n  }\n}\n","import { IcebergRestCatalog, IcebergError } from 'iceberg-js'\nimport { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, remove } from '../lib/fetch'\nimport { isValidBucketName, resolveFetch } from '../lib/helpers'\nimport { AnalyticBucket } from '../lib/types'\n\ntype WrapAsyncMethod<T> = T extends (...args: infer A) => Promise<infer R>\n  ? (...args: A) => Promise<{ data: R; error: null } | { data: null; error: IcebergError }>\n  : T\n\nexport type WrappedIcebergRestCatalog = {\n  [K in keyof IcebergRestCatalog]: WrapAsyncMethod<IcebergRestCatalog[K]>\n}\n\n/**\n * Client class for managing Analytics Buckets using Iceberg tables\n * Provides methods for creating, listing, and deleting analytics buckets\n */\nexport default class StorageAnalyticsClient {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /**\n   * @alpha\n   *\n   * Creates a new StorageAnalyticsClient instance\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param url - The base URL for the storage API\n   * @param headers - HTTP headers to include in requests\n   * @param fetch - Optional custom fetch implementation\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageAnalyticsClient(url, headers)\n   * ```\n   */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * @alpha\n   *\n   * Enable throwing errors instead of returning them in the response\n   * When enabled, failed operations will throw instead of returning { data: null, error }\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns This instance for method chaining\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * @alpha\n   *\n   * Creates a new analytics bucket using Iceberg tables\n   * Analytics buckets are optimized for analytical queries and data processing\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param name A unique name for the bucket you are creating\n   * @returns Promise with response containing newly created analytics bucket or error\n   *\n   * @example Create analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"analytics-data\",\n   *     \"type\": \"ANALYTICS\",\n   *     \"format\": \"iceberg\",\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(name: string): Promise<\n    | {\n        data: AnalyticBucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(this.fetch, `${this.url}/bucket`, { name }, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Retrieves the details of all Analytics Storage buckets within an existing project\n   * Only returns buckets of type 'ANALYTICS'\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of analytics buckets or error\n   *\n   * @example List analytics buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc'\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"analytics-data\",\n   *       \"type\": \"ANALYTICS\",\n   *       \"format\": \"iceberg\",\n   *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async listBuckets(options?: {\n    limit?: number\n    offset?: number\n    sortColumn?: 'name' | 'created_at' | 'updated_at'\n    sortOrder?: 'asc' | 'desc'\n    search?: string\n  }): Promise<\n    | {\n        data: AnalyticBucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      // Build query string from options\n      const queryParams = new URLSearchParams()\n      if (options?.limit !== undefined) queryParams.set('limit', options.limit.toString())\n      if (options?.offset !== undefined) queryParams.set('offset', options.offset.toString())\n      if (options?.sortColumn) queryParams.set('sortColumn', options.sortColumn)\n      if (options?.sortOrder) queryParams.set('sortOrder', options.sortOrder)\n      if (options?.search) queryParams.set('search', options.search)\n\n      const queryString = queryParams.toString()\n      const url = queryString ? `${this.url}/bucket?${queryString}` : `${this.url}/bucket`\n\n      const data = await get(this.fetch, url, { headers: this.headers })\n\n      return { data: data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Deletes an existing analytics bucket\n   * A bucket can't be deleted with existing objects inside it\n   * You must first empty the bucket before deletion\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName The unique identifier of the bucket you would like to delete\n   * @returns Promise with response containing success message or error\n   *\n   * @example Delete analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .deleteBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(bucketName: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${bucketName}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n   * Use this to perform advanced table and namespace operations within the bucket\n   * The returned client provides full access to the Apache Iceberg REST Catalog API\n   * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n   * @returns The wrapped Iceberg catalog client\n   * @throws {StorageError} If the bucket name is invalid\n   *\n   * @example Get catalog and create table\n   * ```js\n   * // First, create an analytics bucket\n   * const { data: bucket, error: bucketError } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   *\n   * // Get the Iceberg catalog for that bucket\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Create a namespace\n   * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n   *\n   * // Create a table with schema\n   * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n   *   { namespace: ['default'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n   *         { id: 3, name: 'user_id', type: 'string', required: false }\n   *       ],\n   *       'schema-id': 0,\n   *       'identifier-field-ids': [1]\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: []\n   *     },\n   *     'write-order': {\n   *       'order-id': 0,\n   *       fields: []\n   *     },\n   *     properties: {\n   *       'write.format.default': 'parquet'\n   *     }\n   *   }\n   * )\n   * ```\n   *\n   * @example List tables in namespace\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all tables in the default namespace\n   * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n   * if (listError) {\n   *   if (listError.isNotFound()) {\n   *     console.log('Namespace not found')\n   *   }\n   *   return\n   * }\n   * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n   * ```\n   *\n   * @example Working with namespaces\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all namespaces\n   * const { data: namespaces } = await catalog.listNamespaces()\n   *\n   * // Create namespace with properties\n   * await catalog.createNamespace(\n   *   { namespace: ['production'] },\n   *   { properties: { owner: 'data-team', env: 'prod' } }\n   * )\n   * ```\n   *\n   * @example Cleanup operations\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Drop table with purge option (removes all data)\n   * const { error: dropError } = await catalog.dropTable(\n   *   { namespace: ['default'], name: 'events' },\n   *   { purge: true }\n   * )\n   *\n   * if (dropError?.isNotFound()) {\n   *   console.log('Table does not exist')\n   * }\n   *\n   * // Drop namespace (must be empty)\n   * await catalog.dropNamespace({ namespace: ['default'] })\n   * ```\n   *\n   * @remarks\n   * This method provides a bridge between Supabase's bucket management and the standard\n   * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n   * All authentication and configuration is handled automatically using your Supabase credentials.\n   *\n   * **Error Handling**: Invalid bucket names throw immediately. All catalog\n   * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n   * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n   * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n   *\n   * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n   * deletes all table data. Without it, the table is marked as deleted but data remains.\n   *\n   * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n   * For complete API documentation and advanced usage, refer to the\n   * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n   */\n  from(bucketName: string): WrappedIcebergRestCatalog {\n    // Validate bucket name using same rules as Supabase Storage API backend\n    if (!isValidBucketName(bucketName)) {\n      throw new StorageError(\n        'Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines ' +\n          'and should avoid the use of any other characters.'\n      )\n    }\n\n    // Construct the Iceberg REST Catalog URL\n    // The base URL is /storage/v1/iceberg\n    // Note: IcebergRestCatalog from iceberg-js automatically adds /v1/ prefix to API paths\n    // so we should NOT append /v1 here (it would cause double /v1/v1/ in the URL)\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName, // Maps to the warehouse parameter in Supabase's implementation\n      auth: {\n        type: 'custom',\n        getHeaders: async () => this.headers,\n      },\n      fetch: this.fetch,\n    })\n\n    const shouldThrowOnError = this.shouldThrowOnError\n\n    const wrappedCatalog = new Proxy(catalog, {\n      get(target, prop: keyof IcebergRestCatalog) {\n        const value = target[prop]\n        if (typeof value !== 'function') {\n          return value\n        }\n\n        return async (...args: unknown[]) => {\n          try {\n            const data = await (value as Function).apply(target, args)\n            return { data, error: null }\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error\n            }\n            return { data: null, error: error as IcebergError }\n          }\n        }\n      },\n    }) as unknown as WrappedIcebergRestCatalog\n\n    return wrappedCatalog\n  }\n}\n","import { version } from '../version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n  'Content-Type': 'application/json',\n}\n","/**\n * Base error class for all Storage Vectors errors\n */\nexport class StorageVectorsError extends Error {\n  protected __isStorageVectorsError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageVectorsError'\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageVectorsError\n * @param error - The error to check\n * @returns True if the error is a StorageVectorsError\n */\nexport function isStorageVectorsError(error: unknown): error is StorageVectorsError {\n  return typeof error === 'object' && error !== null && '__isStorageVectorsError' in error\n}\n\n/**\n * API error returned from S3 Vectors service\n * Includes HTTP status code and service-specific error code\n */\nexport class StorageVectorsApiError extends StorageVectorsError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageVectorsApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\n/**\n * Unknown error that doesn't match expected error patterns\n * Wraps the original error for debugging\n */\nexport class StorageVectorsUnknownError extends StorageVectorsError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageVectorsUnknownError'\n    this.originalError = originalError\n  }\n}\n\n/**\n * Error codes specific to S3 Vectors API\n * Maps AWS service errors to application-friendly error codes\n */\nexport enum StorageVectorsErrorCode {\n  /** Internal server fault (HTTP 500) */\n  InternalError = 'InternalError',\n  /** Resource already exists / conflict (HTTP 409) */\n  S3VectorConflictException = 'S3VectorConflictException',\n  /** Resource not found (HTTP 404) */\n  S3VectorNotFoundException = 'S3VectorNotFoundException',\n  /** Delete bucket while not empty (HTTP 400) */\n  S3VectorBucketNotEmpty = 'S3VectorBucketNotEmpty',\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  S3VectorMaxBucketsExceeded = 'S3VectorMaxBucketsExceeded',\n  /** Exceeds index quota/limit (HTTP 400) */\n  S3VectorMaxIndexesExceeded = 'S3VectorMaxIndexesExceeded',\n}\n","type Fetch = typeof fetch\n\n/**\n * Resolves the fetch implementation to use\n * Uses custom fetch if provided, otherwise uses native fetch\n *\n * @param customFetch - Optional custom fetch implementation\n * @returns Resolved fetch function\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\n/**\n * Resolves the Response constructor to use\n * Returns native Response constructor\n *\n * @returns Response constructor\n */\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n *\n * @param value - Value to check\n * @returns True if value is a plain object\n * @source https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Normalizes a number array to float32 format\n * Ensures all vector values are valid 32-bit floats\n *\n * @param values - Array of numbers to normalize\n * @returns Normalized float32 array\n */\nexport const normalizeToFloat32 = (values: number[]): number[] => {\n  // Use Float32Array to ensure proper precision\n  return Array.from(new Float32Array(values))\n}\n\n/**\n * Validates vector dimensions match expected dimension\n * Throws error if dimensions don't match\n *\n * @param vector - Vector data to validate\n * @param expectedDimension - Expected vector dimension\n * @throws Error if dimensions don't match\n */\nexport const validateVectorDimension = (\n  vector: { float32: number[] },\n  expectedDimension?: number\n): void => {\n  if (expectedDimension !== undefined && vector.float32.length !== expectedDimension) {\n    throw new Error(\n      `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.float32.length}`\n    )\n  }\n}\n","import { StorageVectorsApiError, StorageVectorsUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { VectorFetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\n/**\n * Options for fetch requests\n * @property headers - Custom HTTP headers\n * @property noResolveJson - If true, return raw Response instead of parsing JSON\n */\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  noResolveJson?: boolean\n}\n\n/**\n * HTTP methods supported by the API\n */\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE'\n\n/**\n * Extracts error message from various error response formats\n * @param err - Error object from API\n * @returns Human-readable error message\n */\nconst _getErrorMessage = (err: any): string =>\n  err.msg || err.message || err.error_description || err.error || JSON.stringify(err)\n\n/**\n * Handles fetch errors and converts them to StorageVectors error types\n * @param error - The error caught from fetch\n * @param reject - Promise rejection function\n * @param options - Fetch options that may affect error handling\n */\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  // Check if error is a Response-like object (has status and ok properties)\n  // This is more reliable than instanceof which can fail across realms\n  const isResponseLike =\n    error &&\n    typeof error === 'object' &&\n    'status' in error &&\n    'ok' in error &&\n    typeof (error as any).status === 'number'\n\n  if (isResponseLike && !options?.noResolveJson) {\n    const status = (error as any).status || 500\n    const responseError = error as any\n\n    // Try to parse JSON body if available\n    if (typeof responseError.json === 'function') {\n      responseError\n        .json()\n        .then((err: any) => {\n          const statusCode = err?.statusCode || err?.code || status + ''\n          reject(new StorageVectorsApiError(_getErrorMessage(err), status, statusCode))\n        })\n        .catch(() => {\n          // If JSON parsing fails, create an ApiError with the HTTP status code\n          const statusCode = status + ''\n          const message = responseError.statusText || `HTTP ${status} error`\n          reject(new StorageVectorsApiError(message, status, statusCode))\n        })\n    } else {\n      // No json() method available, create error from status\n      const statusCode = status + ''\n      const message = responseError.statusText || `HTTP ${status} error`\n      reject(new StorageVectorsApiError(message, status, statusCode))\n    }\n  } else {\n    reject(new StorageVectorsUnknownError(_getErrorMessage(error), error))\n  }\n}\n\n/**\n * Builds request parameters for fetch calls\n * @param method - HTTP method\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters like AbortSignal\n * @param body - Request body (will be JSON stringified if plain object)\n * @returns Complete fetch request parameters\n */\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  return { ...params, ...parameters }\n}\n\n/**\n * Internal request handler that wraps fetch with error handling\n * @param fetcher - Fetch function to use\n * @param method - HTTP method\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @param body - Request body\n * @returns Promise with parsed response or error\n */\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        // Handle empty responses (204, empty body)\n        const contentType = result.headers.get('content-type')\n        if (!contentType || !contentType.includes('application/json')) {\n          return {}\n        }\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\n/**\n * Performs a GET request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\n/**\n * Performs a POST request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\n/**\n * Performs a PUT request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\n/**\n * Performs a DELETE request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorIndex,\n  ListIndexesOptions,\n  ListIndexesResponse,\n  VectorDataType,\n  DistanceMetric,\n  MetadataConfiguration,\n} from './types'\n\n/**\n * @alpha\n *\n * Options for creating a vector index\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface CreateIndexOptions {\n  vectorBucketName: string\n  indexName: string\n  dataType: VectorDataType\n  dimension: number\n  distanceMetric: DistanceMetric\n  metadataConfiguration?: MetadataConfiguration\n}\n\n/**\n * @hidden\n * Base implementation for vector index operations.\n * Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n */\nexport default class VectorIndexApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorIndexApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector index within a bucket */\n  async createIndex(options: CreateIndexOptions): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/CreateIndex`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(\n    vectorBucketName: string,\n    indexName: string\n  ): Promise<ApiResponse<{ index: VectorIndex }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options: ListIndexesOptions): Promise<ApiResponse<ListIndexesResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListIndexes`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName: string, indexName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  PutVectorsOptions,\n  GetVectorsOptions,\n  GetVectorsResponse,\n  DeleteVectorsOptions,\n  ListVectorsOptions,\n  ListVectorsResponse,\n  QueryVectorsOptions,\n  QueryVectorsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector data operations.\n * Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n */\nexport default class VectorDataApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorDataApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options: PutVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.vectors.length < 1 || options.vectors.length > 500) {\n        throw new Error('Vector batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/PutVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options: GetVectorsOptions): Promise<ApiResponse<GetVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/GetVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vectors in an index with pagination */\n  async listVectors(options: ListVectorsOptions): Promise<ApiResponse<ListVectorsResponse>> {\n    try {\n      // Validate segment configuration\n      if (options.segmentCount !== undefined) {\n        if (options.segmentCount < 1 || options.segmentCount > 16) {\n          throw new Error('segmentCount must be between 1 and 16')\n        }\n        if (options.segmentIndex !== undefined) {\n          if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) {\n            throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`)\n          }\n        }\n      }\n\n      const data = await post(this.fetch, `${this.url}/ListVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options: QueryVectorsOptions): Promise<ApiResponse<QueryVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/QueryVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options: DeleteVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.keys.length < 1 || options.keys.length > 500) {\n        throw new Error('Keys batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/DeleteVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorBucket,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector bucket operations.\n * Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n */\nexport default class VectorBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorBucketApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/CreateVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListVectorBuckets`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import VectorIndexApi, { CreateIndexOptions } from './VectorIndexApi'\nimport VectorDataApi from './VectorDataApi'\nimport { Fetch } from './fetch'\nimport VectorBucketApi from './VectorBucketApi'\nimport {\n  ApiResponse,\n  DeleteVectorsOptions,\n  GetVectorsOptions,\n  ListIndexesOptions,\n  ListVectorsOptions,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n  PutVectorsOptions,\n  QueryVectorsOptions,\n  VectorBucket,\n} from './types'\n\n/**\n *\n * @alpha\n *\n * Configuration options for the Storage Vectors client\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface StorageVectorsClientOptions {\n  /**\n   * Custom headers to include in all requests\n   */\n  headers?: { [key: string]: string }\n  /**\n   * Custom fetch implementation (optional)\n   * Useful for testing or custom request handling\n   */\n  fetch?: Fetch\n}\n\n/**\n *\n * @alpha\n *\n * Main client for interacting with S3 Vectors API\n * Provides access to bucket, index, and vector data operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n *\n * **Usage Patterns:**\n *\n * ```typescript\n * const { data, error } = await supabase\n *  .storage\n *  .vectors\n *  .createBucket('embeddings-prod')\n *\n * // Access index operations via buckets\n * const bucket = supabase.storage.vectors.from('embeddings-prod')\n * await bucket.createIndex({\n *   indexName: 'documents',\n *   dataType: 'float32',\n *   dimension: 1536,\n *   distanceMetric: 'cosine'\n * })\n *\n * // Access vector operations via index\n * const index = bucket.index('documents')\n * await index.putVectors({\n *   vectors: [\n *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n *   ]\n * })\n *\n * // Query similar vectors\n * const { data } = await index.queryVectors({\n *   queryVector: { float32: [...] },\n *   topK: 5,\n *   returnDistance: true\n * })\n * ```\n */\nexport class StorageVectorsClient extends VectorBucketApi {\n  /**\n   * @alpha\n   *\n   * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param url - Base URL of the Storage Vectors REST API.\n   * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n   * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageVectorsClient(url, options)\n   * ```\n   */\n  constructor(url: string, options: StorageVectorsClientOptions = {}) {\n    super(url, options.headers || {}, options.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific vector bucket\n   * Returns a scoped client for index and vector operations within the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Bucket-scoped client with index and vector operations\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  from(vectorBucketName: string): VectorBucketScope {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector bucket\n   * Vector buckets are containers for vector indexes and their data\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Unique name for the vector bucket\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .createBucket('embeddings-prod')\n   * ```\n   */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.createBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific vector bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Promise with bucket metadata or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .getBucket('embeddings-prod')\n   *\n   * console.log('Bucket created:', data?.vectorBucket.creationTime)\n   * ```\n   */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return super.getBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists all vector buckets with optional filtering and pagination\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Optional filters (prefix, maxResults, nextToken)\n   * @returns Promise with list of buckets or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .listBuckets({ prefix: 'embeddings-' })\n   *\n   * data?.vectorBuckets.forEach(bucket => {\n   *   console.log(bucket.vectorBucketName)\n   * })\n   * ```\n   */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return super.listBuckets(options)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes a vector bucket (bucket must be empty)\n   * All indexes must be deleted before deleting the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .deleteBucket('embeddings-old')\n   * ```\n   */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.deleteBucket(vectorBucketName)\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector bucket\n * Provides index management and access to vector operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorBucketScope extends VectorIndexApi {\n  private vectorBucketName: string\n\n  /**\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all index operations to the provided bucket.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Index configuration (vectorBucketName is automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.createIndex({\n   *   indexName: 'documents-openai',\n   *   dataType: 'float32',\n   *   dimension: 1536,\n   *   distanceMetric: 'cosine',\n   *   metadataConfiguration: {\n   *     nonFilterableMetadataKeys: ['raw_text']\n   *   }\n   * })\n   * ```\n   */\n  override async createIndex(options: Omit<CreateIndexOptions, 'vectorBucketName'>) {\n    return super.createIndex({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists indexes in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (vectorBucketName is automatically set)\n   * @returns Promise with response containing indexes array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n   * ```\n   */\n  override async listIndexes(options: Omit<ListIndexesOptions, 'vectorBucketName'> = {}) {\n    return super.listIndexes({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to retrieve\n   * @returns Promise with index metadata or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.getIndex('documents-openai')\n   * console.log('Dimension:', data?.index.dimension)\n   * ```\n   */\n  override async getIndex(indexName: string) {\n    return super.getIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes an index from this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.deleteIndex('old-index')\n   * ```\n   */\n  override async deleteIndex(indexName: string) {\n    return super.deleteIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific index within this bucket\n   * Returns a scoped client for vector data operations\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index\n   * @returns Index-scoped client with vector data operations\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   *\n   * // Insert vectors\n   * await index.putVectors({\n   *   vectors: [\n   *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n   *   ]\n   * })\n   *\n   * // Query similar vectors\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [...] },\n   *   topK: 5\n   * })\n   * ```\n   */\n  index(indexName: string): VectorIndexScope {\n    return new VectorIndexScope(\n      this.url,\n      this.headers,\n      this.vectorBucketName,\n      indexName,\n      this.fetch\n    )\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector index\n * Provides vector data operations (put, get, list, query, delete)\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorIndexScope extends VectorDataApi {\n  private vectorBucketName: string\n  private indexName: string\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    indexName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n    this.indexName = indexName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Inserts or updates vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector insertion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.putVectors({\n   *   vectors: [\n   *     {\n   *       key: 'doc-1',\n   *       data: { float32: [0.1, 0.2, ...] },\n   *       metadata: { title: 'Introduction', page: 1 }\n   *     }\n   *   ]\n   * })\n   * ```\n   */\n  override async putVectors(options: Omit<PutVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.putVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector retrieval options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.getVectors({\n   *   keys: ['doc-1', 'doc-2'],\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async getVectors(options: Omit<GetVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.getVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists vectors in this index with pagination\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.listVectors({\n   *   maxResults: 500,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async listVectors(\n    options: Omit<ListVectorsOptions, 'vectorBucketName' | 'indexName'> = {}\n  ) {\n    return super.listVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Queries for similar vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Query options (bucket and index names automatically set)\n   * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [0.1, 0.2, ...] },\n   *   topK: 5,\n   *   filter: { category: 'technical' },\n   *   returnDistance: true,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async queryVectors(\n    options: Omit<QueryVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.queryVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Deletion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.deleteVectors({\n   *   keys: ['doc-1', 'doc-2', 'doc-3']\n   * })\n   * ```\n   */\n  override async deleteVectors(\n    options: Omit<DeleteVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.deleteVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n}\n","import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport StorageAnalyticsClient from './packages/StorageAnalyticsClient'\nimport { Fetch } from './lib/fetch'\nimport { StorageVectorsClient } from './lib/vectors'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  /**\n   * Creates a client for Storage buckets, files, analytics, and vectors.\n   *\n   * @category File Buckets\n   * @example\n   * ```ts\n   * import { StorageClient } from '@supabase/storage-js'\n   *\n   * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n   *   apikey: 'public-anon-key',\n   * })\n   * const avatars = storage.from('avatars')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @category File Buckets\n   * @param id The bucket id to operate on.\n   *\n   * @example\n   * ```typescript\n   * const avatars = supabase.storage.from('avatars')\n   * ```\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access vector storage operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @returns A StorageVectorsClient instance configured with the current storage settings.\n   */\n  get vectors(): StorageVectorsClient {\n    return new StorageVectorsClient(this.url + '/vector', {\n      headers: this.headers,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access analytics storage operations using Iceberg tables.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n   */\n  get analytics(): StorageAnalyticsClient {\n    return new StorageAnalyticsClient(this.url + '/iceberg', this.headers, this.fetch)\n  }\n}\n"],"names":["resolveFetch","resolveResponse","result: Record<string, any>","isPlainObject","_getErrorMessage","handleError","resolveResponse","_getRequestParams","params: { [k: string]: any }","isPlainObject","_handleRequest","post","downloadFn: () => Promise<Response>","shouldThrowOnError: boolean","this","downloadFn: () => Promise<Response>","shouldThrowOnError: boolean","this","DEFAULT_FILE_OPTIONS: FileOptions","resolveFetch","fetch","headers: Record<string, string>","this","post","_queryString: string[]","params: string[]","DEFAULT_HEADERS","DEFAULT_HEADERS","resolveFetch","fetch","this","post","params: Record<string, string>","DEFAULT_HEADERS","resolveFetch","fetch","post","this","params: { [k: string]: any }","fetch","this","fetch","this","fetch","this","fetch","this","fetch"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AK8uCe;;;;AL9uCf,IAAa,eAAb,cAAkC,MAAM;IAGtC,YAAY,OAAA,CAAiB;QAC3B,KAAA,CAAM,QAAQ;aAHN,gBAAA,GAAmB;QAI3B,IAAA,CAAK,IAAA,GAAO;;;AAIhB,SAAgB,eAAe,KAAA,EAAuC;IACpE,OAAO,OAAO,UAAU,YAAY,UAAU,QAAQ,sBAAsB;;AAG9E,IAAa,kBAAb,cAAqC,aAAa;IAIhD,YAAY,OAAA,EAAiB,MAAA,EAAgB,UAAA,CAAoB;QAC/D,KAAA,CAAM,QAAQ;QACd,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,UAAA,GAAa;;IAGpB,SAAS;QACP,OAAO;YACL,MAAM,IAAA,CAAK,IAAA;YACX,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,YAAY,IAAA,CAAK,UAAA;SAClB;;;AAIL,IAAa,sBAAb,cAAyC,aAAa;IAGpD,YAAY,OAAA,EAAiB,aAAA,CAAwB;QACnD,KAAA,CAAM,QAAQ;QACd,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,aAAA,GAAgB;;;;;ACtCzB,MAAaA,iBAAAA,CAAgB,gBAA+B;IAC1D,IAAI,YACF,CAAA,OAAA,CAAQ,GAAG,OAAS,YAAY,GAAG,KAAK;IAE1C,OAAA,CAAQ,GAAG,OAAS,MAAM,GAAG,KAAK;;AAGpC,MAAaC,oBAAAA,MAAyC;IACpD,OAAO;;AAGT,MAAa,mBAAA,CAAoB,SAAuC;IACtE,IAAI,MAAM,OAAA,CAAQ,KAAK,CACrB,CAAA,OAAO,KAAK,GAAA,CAAA,CAAK,KAAO,iBAAiB,GAAG,CAAC;aACpC,OAAO,SAAS,cAAc,SAAS,OAAO,KAAK,CAC5D,CAAA,OAAO;IAGT,MAAMC,SAA8B,CAAA,CAAE;IACtC,OAAO,OAAA,CAAQ,KAAK,CAAC,OAAA,CAAA,CAAS,CAAC,KAAK,MAAA,KAAW;QAC7C,MAAM,SAAS,IAAI,OAAA,CAAQ,iBAAA,CAAkB,IAAM,EAAE,WAAA,EAAa,CAAC,OAAA,CAAQ,SAAS,GAAG,CAAC;QACxF,MAAA,CAAO,OAAA,GAAU,iBAAiB,MAAM;MACxC;IAEF,OAAO;;;;;;GAQT,MAAaC,kBAAAA,CAAiB,UAA2B;IACvD,IAAI,OAAO,UAAU,YAAY,UAAU,KACzC,CAAA,OAAO;IAGT,MAAM,YAAY,OAAO,cAAA,CAAe,MAAM;IAC9C,OAAA,CACG,cAAc,QACb,cAAc,OAAO,SAAA,IACrB,OAAO,cAAA,CAAe,UAAU,KAAK,IAAA,KACvC,CAAA,CAAE,OAAO,WAAA,IAAe,KAAA,KACxB,CAAA,CAAE,OAAO,QAAA,IAAY,KAAA;;;;;;;;;;;;;;;;GAmBzB,MAAa,oBAAA,CAAqB,eAAgC;IAChE,IAAI,CAAC,cAAc,OAAO,eAAe,SACvC,CAAA,OAAO;IAIT,IAAI,WAAW,MAAA,KAAW,KAAK,WAAW,MAAA,GAAS,IACjD,CAAA,OAAO;IAIT,IAAI,WAAW,IAAA,EAAM,KAAK,WACxB,CAAA,OAAO;IAMT,IAAI,WAAW,QAAA,CAAS,IAAI,IAAI,WAAW,QAAA,CAAS,KAAK,CACvD,CAAA,OAAO;IAOT,OADwB,4BACD,IAAA,CAAK,WAAW;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1EzC,MAAMC,qBAAAA,CAAoB,QACxB;;eAAI,GAAA,IACJ,IAAI,OAAA,IACJ,IAAI,iBAAA,IAAA,CACH,OAAO,IAAI,KAAA,KAAU,WAAW,IAAI,KAAA,GAAA,CAAA,aAAQ,IAAI,KAAA,MAAA,QAAA,eAAA,KAAA,IAAA,KAAA,IAAA,WAAO,OAAA,KACxD,KAAK,SAAA,CAAU,IAAI;;AAErB,MAAMC,gBAAc,OAClB,OACA,QACA,YACG;IAGH,IAAI,iBAFQ,MAAMC,mBAAiB,IAEP,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAC,QAAS,aAAA,EACpC,CAAA,MACG,IAAA,EAAM,CACN,IAAA,CAAA,CAAM,QAAQ;QACb,MAAM,SAAS,MAAM,MAAA,IAAU;QAC/B,MAAM,aAAA,CAAA,QAAA,QAAA,QAAA,KAAA,IAAA,KAAA,IAAa,IAAK,UAAA,KAAc,SAAS;QAC/C,OAAO,IAAI,gBAAgBF,mBAAiB,IAAI,EAAE,QAAQ,WAAW,CAAC;MACtE,CACD,KAAA,CAAA,CAAO,QAAQ;QACd,OAAO,IAAI,oBAAoBA,mBAAiB,IAAI,EAAE,IAAI,CAAC;MAC3D;SAEJ,OAAO,IAAI,oBAAoBA,mBAAiB,MAAM,EAAE,MAAM,CAAC;;AAInE,MAAMG,sBAAAA,CACJ,QACA,SACA,YACA,SACG;IACH,MAAMC,SAA+B;QAAE;QAAQ,SAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAS,QAAS,OAAA,KAAW,CAAA,CAAE;KAAE;IAEhF,IAAI,WAAW,SAAS,CAAC,KACvB,CAAA,OAAO;IAGT,IAAIC,gBAAc,KAAK,EAAE;QACvB,OAAO,OAAA,GAAA,eAAA;YAAY,gBAAgB;QAAA,GAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAuB,QAAS,OAAA;QACnE,OAAO,IAAA,GAAO,KAAK,SAAA,CAAU,KAAK;UAElC,CAAA,OAAO,IAAA,GAAO;IAGhB,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,CACX,CAAA,OAAO,MAAA,GAAS,QAAQ,MAAA;IAG1B,OAAA,eAAA,eAAA,CAAA,GAAY,SAAW;;AAGzB,eAAeC,iBACb,OAAA,EACA,MAAA,EACA,GAAA,EACA,OAAA,EACA,UAAA,EACA,IAAA,EACc;IACd,OAAO,IAAI,QAAA,CAAS,SAAS,WAAW;QACtC,QAAQ,KAAKH,oBAAkB,QAAQ,SAAS,YAAY,KAAK,CAAC,CAC/D,IAAA,CAAA,CAAM,WAAW;YAChB,IAAI,CAAC,OAAO,EAAA,CAAI,CAAA,MAAM;YACtB,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,aAAA,CAAe,CAAA,OAAO;YACnC,OAAO,OAAO,IAAA,EAAM;UACpB,CACD,IAAA,CAAA,CAAM,OAAS,QAAQ,KAAK,CAAC,CAC7B,KAAA,CAAA,CAAO,QAAUF,cAAY,OAAO,QAAQ,QAAQ,CAAC;MACxD;;AAGJ,eAAsB,IACpB,OAAA,EACA,GAAA,EACA,OAAA,EACA,UAAA,EACc;IACd,OAAOK,iBAAe,SAAS,OAAO,KAAK,SAAS,WAAW;;AAGjE,eAAsBC,OACpB,OAAA,EACA,GAAA,EACA,IAAA,EACA,OAAA,EACA,UAAA,EACc;IACd,OAAOD,iBAAe,SAAS,QAAQ,KAAK,SAAS,YAAY,KAAK;;AAGxE,eAAsB,IACpB,OAAA,EACA,GAAA,EACA,IAAA,EACA,OAAA,EACA,UAAA,EACc;IACd,OAAOA,iBAAe,SAAS,OAAO,KAAK,SAAS,YAAY,KAAK;;AAGvE,eAAsB,KACpB,OAAA,EACA,GAAA,EACA,OAAA,EACA,UAAA,EACc;IACd,OAAOA,iBACL,SACA,QACA,KAAA,eAAA,eAAA,CAAA,GAEK,UAAA,CAAA,GAAA;QACH,eAAe;IAAA,IAEjB,WACD;;AAGH,eAAsB,OACpB,OAAA,EACA,GAAA,EACA,IAAA,EACA,OAAA,EACA,UAAA,EACc;IACd,OAAOA,iBAAe,SAAS,UAAU,KAAK,SAAS,YAAY,KAAK;;;;AC/I1E,IAAqB,wBAArB,MAAkG;IAChG,YACUE,UAAAA,EACAC,kBAAAA,CACR;QAFQ,IAAA,CAAA,UAAA,GAAA;QACA,IAAA,CAAA,kBAAA,GAAA;;IAGV,KACE,WAAA,EAGA,UAAA,EAC8B;QAC9B,OAAO,IAAA,CAAK,OAAA,EAAS,CAAC,IAAA,CAAK,aAAa,WAAW;;IAGrD,MAAc,UAAmD;;QAC/D,IAAI;YAGF,OAAO;gBACL,MAAA,CAHa,MAAMC,MAAK,UAAA,EAAY,EAGvB,IAAA;gBACb,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAGR,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;sBC9BA,OAAO,WAAA;AADnB,IAAqB,sBAArB,MAAkF;IAIhF,YACUC,UAAAA,EACAC,kBAAAA,CACR;QAFQ,IAAA,CAAA,UAAA,GAAA;QACA,IAAA,CAAA,kBAAA,GAAA;oCAL8B;aAChC,OAAA,GAAgD;;IAOxD,WAAkC;QAChC,OAAO,IAAI,sBAAsB,IAAA,CAAK,UAAA,EAAY,IAAA,CAAK,kBAAA,CAAmB;;IAG5E,KACE,WAAA,EACA,UAAA,EAC8B;QAC9B,OAAO,IAAA,CAAK,UAAA,EAAY,CAAC,IAAA,CAAK,aAAa,WAAW;;IAGxD,MACE,UAAA,EACyC;QACzC,OAAO,IAAA,CAAK,UAAA,EAAY,CAAC,KAAA,CAAM,WAAW;;IAG5C,QAAQ,SAAA,EAAgE;QACtE,OAAO,IAAA,CAAK,UAAA,EAAY,CAAC,OAAA,CAAQ,UAAU;;IAGrC,aAA4C;QAClD,IAAI,CAAC,IAAA,CAAK,OAAA,CACR,CAAA,IAAA,CAAK,OAAA,GAAU,IAAA,CAAK,OAAA,EAAS;QAE/B,OAAO,IAAA,CAAK,OAAA;;IAGd,MAAc,UAAyC;;QACrD,IAAI;YAGF,OAAO;gBACL,MAAM,MAAA,CAHO,MAAMC,MAAK,UAAA,EAAY,EAGjB,IAAA,EAAM;gBACzB,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAGR,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;ACzCZ,MAAM,yBAAyB;IAC7B,OAAO;IACP,QAAQ;IACR,QAAQ;QACN,QAAQ;QACR,OAAO;KACR;CACF;AAED,MAAMC,uBAAoC;IACxC,cAAc;IACd,aAAa;IACb,QAAQ;CACT;AAcD,IAAqB,iBAArB,MAAoC;IAOlC,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,QAAA,EACA,OAAA,CACA;aAPQ,kBAAA,GAAqB;QAQ7B,IAAA,CAAK,GAAA,GAAM;QACX,IAAA,CAAK,OAAA,GAAU;QACf,IAAA,CAAK,QAAA,GAAW;QAChB,IAAA,CAAK,KAAA,GAAQC,eAAaC,QAAM;;;;;;IAQ3B,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;;;;;;;IAUT,MAAc,eACZ,MAAA,EACA,IAAA,EACA,QAAA,EACA,WAAA,EAUA;;QACA,IAAI;YACF,IAAI;YACJ,MAAM,UAAA,eAAA,eAAA,CAAA,GAAe,uBAAyB;YAC9C,IAAIC,UAAAA,eAAAA,eAAAA,CAAAA,GACCC,MAAK,OAAA,GACJ,WAAW,UAAU;gBAAE,YAAY,OAAO,QAAQ,MAAA,CAAkB;YAAA,CAAE;YAG5E,MAAM,WAAW,QAAQ,QAAA;YAEzB,IAAI,OAAO,SAAS,eAAe,oBAAoB,MAAM;gBAC3D,OAAO,IAAI,UAAU;gBACrB,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;gBAC3D,IAAI,SACF,CAAA,KAAK,MAAA,CAAO,YAAYA,MAAK,cAAA,CAAe,SAAS,CAAC;gBAExD,KAAK,MAAA,CAAO,IAAI,SAAS;uBAChB,OAAO,aAAa,eAAe,oBAAoB,UAAU;gBAC1E,OAAO;gBAEP,IAAI,CAAC,KAAK,GAAA,CAAI,eAAe,CAC3B,CAAA,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;gBAE7D,IAAI,YAAY,CAAC,KAAK,GAAA,CAAI,WAAW,CACnC,CAAA,KAAK,MAAA,CAAO,YAAYA,MAAK,cAAA,CAAe,SAAS,CAAC;mBAEnD;gBACL,OAAO;gBACP,OAAA,CAAQ,gBAAA,GAAmB,CAAA,QAAA,EAAW,QAAQ,YAAA,EAAA;gBAC9C,OAAA,CAAQ,eAAA,GAAkB,QAAQ,WAAA;gBAElC,IAAI,SACF,CAAA,OAAA,CAAQ,aAAA,GAAgBA,MAAK,QAAA,CAASA,MAAK,cAAA,CAAe,SAAS,CAAC;gBAStE,IAAA,CAHG,OAAO,mBAAmB,eAAe,gBAAgB,kBACzD,QAAQ,OAAO,SAAS,YAAY,UAAU,QAAQ,OAAO,KAAK,IAAA,KAAS,UAAA,KAE9D,CAAC,QAAQ,MAAA,CACvB,CAAA,QAAQ,MAAA,GAAS;;YAIrB,IAAA,gBAAA,QAAA,gBAAA,KAAA,IAAA,KAAA,IAAI,YAAa,OAAA,CACf,CAAA,UAAA,eAAA,eAAA,CAAA,GAAe,UAAY,YAAY,OAAA;YAGzC,MAAM,YAAYA,MAAK,mBAAA,CAAoB,KAAK;YAChD,MAAM,QAAQA,MAAK,aAAA,CAAc,UAAU;YAC3C,MAAM,OAAO,MAAA,CAAO,UAAU,QAAQ,MAAMC,MAAAA,EAC1CD,MAAK,KAAA,EACL,GAAGA,MAAK,GAAA,CAAI,QAAA,EAAU,OAAA,EACtB,MAAA,eAAA;gBACE;YAAA,GAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAa,QAAS,MAAA,IAAS;gBAAE,QAAQ,QAAQ,MAAA;YAAA,CAAQ,GAAG,CAAA,CAAE,EACjE;YAED,OAAO;gBACL,MAAM;oBAAE,MAAM;oBAAW,IAAI,KAAK,EAAA;oBAAI,UAAU,KAAK,GAAA;iBAAK;gBAC1D,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAgDV,MAAM,OACJ,IAAA,EACA,QAAA,EACA,WAAA,EAUA;QACA,OAAA,IAAA,CAAY,cAAA,CAAe,QAAQ,MAAM,UAAU,YAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkCjE,MAAM,kBACJ,IAAA,EACA,KAAA,EACA,QAAA,EACA,WAAA,EACA;;QACA,MAAM,YAAYA,OAAK,mBAAA,CAAoB,KAAK;QAChD,MAAM,QAAQA,OAAK,aAAA,CAAc,UAAU;QAE3C,MAAM,MAAM,IAAI,IAAIA,OAAK,GAAA,GAAM,CAAA,oBAAA,EAAuB,OAAA,CAAQ;QAC9D,IAAI,YAAA,CAAa,GAAA,CAAI,SAAS,MAAM;QAEpC,IAAI;YACF,IAAI;YACJ,MAAM,UAAA,eAAA;gBAAY,QAAQ,qBAAqB,MAAA;YAAA,GAAW;YAC1D,MAAMD,UAAAA,eAAAA,eAAAA,CAAAA,GACDC,OAAK,OAAA,GACL;gBAAE,YAAY,OAAO,QAAQ,MAAA,CAAkB;YAAA,CAAE;YAGtD,IAAI,OAAO,SAAS,eAAe,oBAAoB,MAAM;gBAC3D,OAAO,IAAI,UAAU;gBACrB,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;gBAC3D,KAAK,MAAA,CAAO,IAAI,SAAS;uBAChB,OAAO,aAAa,eAAe,oBAAoB,UAAU;gBAC1E,OAAO;gBACP,KAAK,MAAA,CAAO,gBAAgB,QAAQ,YAAA,CAAuB;mBACtD;gBACL,OAAO;gBACP,OAAA,CAAQ,gBAAA,GAAmB,CAAA,QAAA,EAAW,QAAQ,YAAA,EAAA;gBAC9C,OAAA,CAAQ,eAAA,GAAkB,QAAQ,WAAA;;YAKpC,OAAO;gBACL,MAAM;oBAAE,MAAM;oBAAW,UAAA,CAHd,MAAM,IAAIA,OAAK,KAAA,EAAO,IAAI,QAAA,EAAU,EAAE,MAAgB;wBAAE;oBAAA,CAAS,CAAC,EAGrC,GAAA;iBAAK;gBAC7C,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkCV,MAAM,sBACJ,IAAA,EACA,OAAA,EAUA;;QACA,IAAI;YACF,IAAI,QAAQA,OAAK,aAAA,CAAc,KAAK;YAEpC,MAAM,UAAA,eAAA,CAAA,GAAeA,OAAK,OAAA;YAE1B,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,CACX,CAAA,OAAA,CAAQ,WAAA,GAAc;YAGxB,MAAM,OAAO,MAAMC,OACjBD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,oBAAA,EAAsB,OAAA,EAClC,CAAA,CAAE,EACF;gBAAE;YAAA,CAAS,CACZ;YAED,MAAM,MAAM,IAAI,IAAIA,OAAK,GAAA,GAAM,KAAK,GAAA,CAAI;YAExC,MAAM,QAAQ,IAAI,YAAA,CAAa,GAAA,CAAI,QAAQ;YAE3C,IAAI,CAAC,MACH,CAAA,MAAM,IAAI,aAAa,2BAA2B;YAGpD,OAAO;gBAAE,MAAM;oBAAE,WAAW,IAAI,QAAA,EAAU;oBAAE;oBAAM;iBAAO;gBAAE,OAAO;aAAM;iBACjE,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAgDV,MAAM,OACJ,IAAA,EACA,QAAA,EAWA,WAAA,EAUA;QACA,OAAA,IAAA,CAAY,cAAA,CAAe,OAAO,MAAM,UAAU,YAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8BhE,MAAM,KACJ,QAAA,EACA,MAAA,EACA,OAAA,EAUA;;QACA,IAAI;YAYF,OAAO;gBAAE,MAXI,MAAMC,OACjBD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EACZ;oBACE,UAAUA,OAAK,QAAA;oBACf,WAAW;oBACX,gBAAgB;oBAChB,mBAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAmB,QAAS,iBAAA;iBAC7B,EACD;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA+BV,MAAM,KACJ,QAAA,EACA,MAAA,EACA,OAAA,EAUA;;QACA,IAAI;YAYF,OAAO;gBAAE,MAAM;oBAAE,MAAA,CAXJ,MAAMC,OACjBD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EACZ;wBACE,UAAUA,OAAK,QAAA;wBACf,WAAW;wBACX,gBAAgB;wBAChB,mBAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAmB,QAAS,iBAAA;qBAC7B,EACD;wBAAE,SAASA,OAAK,OAAA;oBAAA,CAAS,CAC1B,EAC2B,GAAA;gBAAA,CAAK;gBAAE,OAAO;aAAM;iBACzC,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAuDV,MAAM,gBACJ,IAAA,EACA,SAAA,EACA,OAAA,EAUA;;QACA,IAAI;YACF,IAAI,QAAQA,OAAK,aAAA,CAAc,KAAK;YAEpC,IAAI,OAAO,MAAMC,OACfD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,aAAA,EAAe,OAAA,EAAA,eAAA;gBACzB;YAAA,GAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAe,QAAS,SAAA,IAAY;gBAAE,WAAW,QAAQ,SAAA;YAAA,CAAW,GAAG,CAAA,CAAE,GAC3E;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;YACD,MAAM,qBAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAqB,QAAS,QAAA,IAChC,CAAA,UAAA,EAAa,QAAQ,QAAA,KAAa,OAAO,KAAK,QAAQ,QAAA,EAAA,GACtD;YAEJ,OAAO;gBAAE,WADS,UAAU,GAAGA,OAAK,GAAA,GAAM,KAAK,SAAA,GAAY,oBAAA,CAAqB;YAAA,CAC5D;YACpB,OAAO;gBAAE;gBAAM,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA0CV,MAAM,iBACJ,KAAA,EACA,SAAA,EACA,OAAA,EAUA;;QACA,IAAI;YACF,MAAM,OAAO,MAAMC,OACjBD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,aAAA,EAAeA,OAAK,QAAA,EAAA,EAChC;gBAAE;gBAAW;aAAO,EACpB;gBAAE,SAASA,OAAK,OAAA;YAAA,CAAS,CAC1B;YAED,MAAM,qBAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAqB,QAAS,QAAA,IAChC,CAAA,UAAA,EAAa,QAAQ,QAAA,KAAa,OAAO,KAAK,QAAQ,QAAA,EAAA,GACtD;YACJ,OAAO;gBACL,MAAM,KAAK,GAAA,CAAA,CAAK,QAAA,eAAA,eAAA,CAAA,GACX,QAAA,CAAA,GAAA;wBACH,WAAW,MAAM,SAAA,GACb,UAAU,GAAGA,OAAK,GAAA,GAAM,MAAM,SAAA,GAAY,oBAAA,CAAqB,GAC/D;oBAAA,GACH;gBACH,OAAO;aACR;iBACM,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA0CV,SACE,IAAA,EACA,OAAA,EACqB;QAErB,MAAM,aADsB,OAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAO,QAAS,SAAA,MAAc,cACjB,+BAA+B;QACxE,MAAM,sBAAsB,IAAA,CAAK,0BAAA,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAA2B,QAAS,SAAA,KAAa,CAAA,CAAE,CAAC;QACrF,MAAM,cAAc,sBAAsB,CAAA,CAAA,EAAI,qBAAA,GAAwB;QACtE,MAAM,QAAQ,IAAA,CAAK,aAAA,CAAc,KAAK;QACtC,MAAM,aAAA,IACJ,IAAI,IAAA,CAAK,KAAA,EAAO,GAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,WAAW,CAAA,EAAG,QAAQ,aAAA,EAAe;gBAClE,SAAS,IAAA,CAAK,OAAA;gBACd,eAAe;aAChB,CAAC;QACJ,OAAO,IAAI,oBAAoB,YAAY,IAAA,CAAK,kBAAA,CAAmB;;;;;;;;;;;;;;;;IAkBrE,MAAM,KAAK,IAAA,EAST;;QACA,MAAM,QAAQA,QAAK,aAAA,CAAc,KAAK;QAEtC,IAAI;YAKF,OAAO;gBAAE,MAAM,iBAJF,MAAM,IAAIA,QAAK,KAAA,EAAO,GAAGA,QAAK,GAAA,CAAI,aAAA,EAAe,OAAA,EAAS;oBACrE,SAASA,QAAK,OAAA;gBAAA,CACf,CAAC,CAEmC;gBAA4B,OAAO;aAAM;iBACvE,OAAO;YACd,IAAIA,QAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;IAmBV,MAAM,OAAO,IAAA,EASX;;QACA,MAAM,QAAQA,QAAK,aAAA,CAAc,KAAK;QAEtC,IAAI;YACF,MAAM,KAAKA,QAAK,KAAA,EAAO,GAAGA,QAAK,GAAA,CAAI,QAAA,EAAU,OAAA,EAAS;gBACpD,SAASA,QAAK,OAAA;YAAA,CACf,CAAC;YAEF,OAAO;gBAAE,MAAM;gBAAM,OAAO;aAAM;iBAC3B,OAAO;YACd,IAAIA,QAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,IAAI,iBAAiB,qBAAqB;gBACjE,MAAM,gBAAgB,MAAM,aAAA;gBAE5B,IAAI;oBAAC;oBAAK;iBAAI,CAAC,QAAA,CAAA,kBAAA,QAAA,kBAAA,KAAA,IAAA,KAAA,IAAS,cAAe,MAAA,CAAO,CAC5C,CAAA,OAAO;oBAAE,MAAM;oBAAO;iBAAO;;YAIjC,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAsDV,aACE,IAAA,EACA,OAAA,EACiC;QACjC,MAAM,QAAQ,IAAA,CAAK,aAAA,CAAc,KAAK;QACtC,MAAME,eAAyB,EAAE;QAEjC,MAAM,qBAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAqB,QAAS,QAAA,IAChC,CAAA,SAAA,EAAY,QAAQ,QAAA,KAAa,OAAO,KAAK,QAAQ,QAAA,EAAA,GACrD;QAEJ,IAAI,uBAAuB,GACzB,CAAA,aAAa,IAAA,CAAK,mBAAmB;QAIvC,MAAM,aADsB,OAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAO,QAAS,SAAA,MAAc,cACjB,iBAAiB;QAC1D,MAAM,sBAAsB,IAAA,CAAK,0BAAA,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAA2B,QAAS,SAAA,KAAa,CAAA,CAAE,CAAC;QAErF,IAAI,wBAAwB,GAC1B,CAAA,aAAa,IAAA,CAAK,oBAAoB;QAGxC,IAAI,cAAc,aAAa,IAAA,CAAK,IAAI;QACxC,IAAI,gBAAgB,GAClB,CAAA,cAAc,CAAA,CAAA,EAAI,aAAA;QAGpB,OAAO;YACL,MAAM;gBAAE,WAAW,UAAU,GAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,WAAW,QAAA,EAAU,QAAQ,aAAA,CAAc;YAAA,CAAE;QAAA,CAC1F;;;;;;;;;;;;;;;;;;;;;;;;IA0BH,MAAM,OAAO,KAAA,EASX;;QACA,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,OACjBF,QAAK,KAAA,EACL,GAAGA,QAAK,GAAA,CAAI,QAAA,EAAUA,QAAK,QAAA,EAAA,EAC3B;oBAAE,UAAU;gBAAA,CAAO,EACnB;oBAAE,SAASA,QAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,QAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8HV,MAAM,KACJ,IAAA,EACA,OAAA,EACA,UAAA,EAUA;;QACA,IAAI;YACF,MAAM,OAAA,eAAA,eAAA,eAAA,CAAA,GAAY,yBAA2B,UAAA,CAAA,GAAA;gBAAS,QAAQ,QAAQ;YAAA;YAQtE,OAAO;gBAAE,MAPI,MAAMC,OACjBD,QAAK,KAAA,EACL,GAAGA,QAAK,GAAA,CAAI,aAAA,EAAeA,QAAK,QAAA,EAAA,EAChC,MACA;oBAAE,SAASA,QAAK,OAAA;gBAAA,CAAS,EACzB,WACD;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,QAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;IAWV,MAAM,OACJ,OAAA,EACA,UAAA,EAUA;;QACA,IAAI;YACF,MAAM,OAAA,eAAA,CAAA,GAAY;YAQlB,OAAO;gBAAE,MAPI,MAAMC,OACjBD,QAAK,KAAA,EACL,GAAGA,QAAK,GAAA,CAAI,gBAAA,EAAkBA,QAAK,QAAA,EAAA,EACnC,MACA;oBAAE,SAASA,QAAK,OAAA;gBAAA,CAAS,EACzB,WACD;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,QAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;IAIA,eAAe,QAAA,EAA+B;QACtD,OAAO,KAAK,SAAA,CAAU,SAAS;;IAGjC,SAAS,IAAA,EAAc;QACrB,IAAI,+KAAO,KAAW,YACpB,CAAA,OAAO,wKAAA,CAAO,IAAA,CAAK,KAAK,CAAC,QAAA,CAAS,SAAS;QAE7C,OAAO,KAAK,KAAK;;IAGX,cAAc,IAAA,EAAc;QAClC,OAAO,GAAG,IAAA,CAAK,QAAA,CAAS,CAAA,EAAG,KAAK,OAAA,CAAQ,QAAQ,GAAG,EAAA;;IAG7C,oBAAoB,IAAA,EAAc;QACxC,OAAO,KAAK,OAAA,CAAQ,YAAY,GAAG,CAAC,OAAA,CAAQ,QAAQ,IAAI;;IAGlD,2BAA2B,SAAA,EAA6B;QAC9D,MAAMG,SAAmB,EAAE;QAC3B,IAAI,UAAU,KAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,MAAA,EAAS,UAAU,KAAA,EAAA,CAAQ;QAGzC,IAAI,UAAU,MAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,OAAA,EAAU,UAAU,MAAA,EAAA,CAAS;QAG3C,IAAI,UAAU,MAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,OAAA,EAAU,UAAU,MAAA,EAAA,CAAS;QAG3C,IAAI,UAAU,MAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,OAAA,EAAU,UAAU,MAAA,EAAA,CAAS;QAG3C,IAAI,UAAU,OAAA,CACZ,CAAA,OAAO,IAAA,CAAK,CAAA,QAAA,EAAW,UAAU,OAAA,EAAA,CAAU;QAG7C,OAAO,OAAO,IAAA,CAAK,IAAI;;;;;AC5wC3B,MAAa,UAAU;;;ACLvB,MAAaC,oBAAkB;IAC7B,iBAAiB,CAAA,WAAA,EAAc,SAAA;AAAA,CAChC;;;ACID,IAAqB,mBAArB,MAAsC;IAMpC,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,OAAA,EACA,IAAA,CACA;aAPQ,kBAAA,GAAqB;QAQ7B,MAAM,UAAU,IAAI,IAAI,IAAI;QAI5B,IAAA,SAAA,QAAA,SAAA,KAAA,IAAA,KAAA,IAAI,KAAM,cAAA,EAER;gBADuB,yBAAyB,IAAA,CAAK,QAAQ,QAAA,CAAS,IAChD,CAAC,QAAQ,QAAA,CAAS,QAAA,CAAS,oBAAoB,CACnE,CAAA,QAAQ,QAAA,GAAW,QAAQ,QAAA,CAAS,OAAA,CAAQ,aAAa,oBAAoB;;QAIjF,IAAA,CAAK,GAAA,GAAM,QAAQ,IAAA,CAAK,OAAA,CAAQ,OAAO,GAAG;QAC1C,IAAA,CAAK,OAAA,GAAA,eAAA,eAAA,CAAA,GAAeC,oBAAoB;QACxC,IAAA,CAAK,KAAA,GAAQC,eAAaC,QAAM;;;;;;IAQ3B,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAmCT,MAAM,YAAY,OAAA,EAShB;;QACA,IAAI;YACF,MAAM,cAAcC,MAAK,8BAAA,CAA+B,QAAQ;YAIhE,OAAO;gBAAE,MAHI,MAAM,IAAIA,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,OAAA,EAAS,aAAA,EAAe;oBACrE,SAASA,MAAK,OAAA;gBAAA,CACf,CAAC;gBACa,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAqCV,MAAM,UAAU,EAAA,EASd;;QACA,IAAI;YAEF,OAAO;gBAAE,MADI,MAAM,IAAIA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,IAAA,EAAM;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAAC;gBAC1E,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAyCV,MAAM,aACJ,EAAA,EACA,UAKI;QACF,QAAQ;IAAA,CACT,EAUD;;QACA,IAAI;YAcF,OAAO;gBAAE,MAbI,MAAMC,OACjBD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,OAAA,CAAA,EACZ;oBACE;oBACA,MAAM;oBACN,MAAM,QAAQ,IAAA;oBACd,QAAQ,QAAQ,MAAA;oBAChB,iBAAiB,QAAQ,aAAA;oBACzB,oBAAoB,QAAQ,gBAAA;iBAC7B,EACD;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAuCV,MAAM,aACJ,EAAA,EACA,OAAA,EAcA;;QACA,IAAI;YAaF,OAAO;gBAAE,MAZI,MAAM,IACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,IAAA,EACtB;oBACE;oBACA,MAAM;oBACN,QAAQ,QAAQ,MAAA;oBAChB,iBAAiB,QAAQ,aAAA;oBACzB,oBAAoB,QAAQ,gBAAA;iBAC7B,EACD;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;IA4BV,MAAM,YAAY,EAAA,EAShB;;QACA,IAAI;YAOF,OAAO;gBAAE,MANI,MAAMC,OACjBD,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,GAAG,MAAA,CAAA,EACzB,CAAA,CAAE,EACF;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6BV,MAAM,aAAa,EAAA,EASjB;;QACA,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,OACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,IAAA,EACtB,CAAA,CAAE,EACF;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;IAIF,+BAA+B,OAAA,EAAqC;QAC1E,MAAME,SAAiC,CAAA,CAAE;QACzC,IAAI,SAAS;YACX,IAAI,WAAW,QACb,CAAA,OAAO,KAAA,GAAQ,OAAO,QAAQ,KAAA,CAAM;YAEtC,IAAI,YAAY,QACd,CAAA,OAAO,MAAA,GAAS,OAAO,QAAQ,MAAA,CAAO;YAExC,IAAI,QAAQ,MAAA,CACV,CAAA,OAAO,MAAA,GAAS,QAAQ,MAAA;YAE1B,IAAI,QAAQ,UAAA,CACV,CAAA,OAAO,UAAA,GAAa,QAAQ,UAAA;YAE9B,IAAI,QAAQ,SAAA,CACV,CAAA,OAAO,SAAA,GAAY,QAAQ,SAAA;;QAG/B,OAAO,OAAO,IAAA,CAAK,OAAO,CAAC,MAAA,GAAS,IAAI,MAAM,IAAI,gBAAgB,OAAO,CAAC,QAAA,EAAU,GAAG;;;;;;;;GClb3F,IAAqB,yBAArB,MAA4C;;;;;;;;;;;;;;;;;IAuB1C,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;aAnBvE,kBAAA,GAAqB;QAoB7B,IAAA,CAAK,GAAA,GAAM,IAAI,OAAA,CAAQ,OAAO,GAAG;QACjC,IAAA,CAAK,OAAA,GAAA,eAAA,eAAA,CAAA,GAAeC,oBAAoB;QACxC,IAAA,CAAK,KAAA,GAAQC,eAAaC,QAAM;;;;;;;;;;;;IAc3B,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAqCT,MAAM,aAAa,IAAA,EASjB;;QACA,IAAI;YAEF,OAAO;gBAAE,MADI,MAAMC,OAAKC,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,OAAA,CAAA,EAAU;oBAAE;gBAAA,CAAM,EAAE;oBAAE,SAASA,MAAK,OAAA;gBAAA,CAAS,CAAC;gBAC/E,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkDV,MAAM,YAAY,OAAA,EAehB;;QACA,IAAI;YAEF,MAAM,cAAc,IAAI,iBAAiB;YACzC,IAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,KAAA,MAAU,KAAA,EAAW,CAAA,YAAY,GAAA,CAAI,SAAS,QAAQ,KAAA,CAAM,QAAA,EAAU,CAAC;YACpF,IAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,MAAW,KAAA,EAAW,CAAA,YAAY,GAAA,CAAI,UAAU,QAAQ,MAAA,CAAO,QAAA,EAAU,CAAC;YACvF,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,UAAA,CAAY,CAAA,YAAY,GAAA,CAAI,cAAc,QAAQ,UAAA,CAAW;YAC1E,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,SAAA,CAAW,CAAA,YAAY,GAAA,CAAI,aAAa,QAAQ,SAAA,CAAU;YACvE,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,MAAA,CAAQ,CAAA,YAAY,GAAA,CAAI,UAAU,QAAQ,MAAA,CAAO;YAE9D,MAAM,cAAc,YAAY,QAAA,EAAU;YAC1C,MAAM,MAAM,cAAc,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,aAAA,GAAgB,GAAGA,OAAK,GAAA,CAAI,OAAA,CAAA;YAI5E,OAAO;gBAAE,MAFI,MAAM,IAAIA,OAAK,KAAA,EAAO,KAAK;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAAC;gBAE7C,OAAO;aAAM;iBAC3B,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAmCV,MAAM,aAAa,UAAA,EASjB;;QACA,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,OACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,QAAA,EAAU,YAAA,EACtB,CAAA,CAAE,EACF;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,eAAe,MAAM,CACvB,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAG9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA+HV,KAAK,UAAA,EAA+C;;QAElD,IAAI,CAAC,kBAAkB,WAAW,CAChC,CAAA,MAAM,IAAI,aACR,qJAED;QAOH,MAAM,UAAU,IAAI,wKAAA,CAAmB;YACrC,SAAS,IAAA,CAAK,GAAA;YACd,aAAa;YACb,MAAM;gBACJ,MAAM;gBACN,YAAY,UAAYA,OAAK,OAAA;aAC9B;YACD,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;QAEF,MAAM,qBAAqB,IAAA,CAAK,kBAAA;QAuBhC,OArBuB,IAAI,MAAM,SAAS;YACxC,KAAI,MAAA,EAAQ,IAAA,EAAgC;gBAC1C,MAAM,QAAQ,MAAA,CAAO,KAAA;gBACrB,IAAI,OAAO,UAAU,WACnB,CAAA,OAAO;gBAGT,OAAO,OAAO,GAAG,SAAoB;oBACnC,IAAI;wBAEF,OAAO;4BAAE,MADI,MAAO,MAAmB,KAAA,CAAM,QAAQ,KAAK;4BAC3C,OAAO;yBAAM;6BACrB,OAAO;wBACd,IAAI,mBACF,CAAA,MAAM;wBAER,OAAO;4BAAE,MAAM;4BAAa;yBAAuB;;;;SAI1D,CAAC;;;;;ACvbN,MAAa,kBAAkB;IAC7B,iBAAiB,CAAA,WAAA,EAAc,SAAA;IAC/B,gBAAgB;CACjB;;;;;GCDD,IAAa,sBAAb,cAAyC,MAAM;IAG7C,YAAY,OAAA,CAAiB;QAC3B,KAAA,CAAM,QAAQ;aAHN,uBAAA,GAA0B;QAIlC,IAAA,CAAK,IAAA,GAAO;;;;;;;GAShB,SAAgB,sBAAsB,KAAA,EAA8C;IAClF,OAAO,OAAO,UAAU,YAAY,UAAU,QAAQ,6BAA6B;;;;;GAOrF,IAAa,yBAAb,cAA4C,oBAAoB;IAI9D,YAAY,OAAA,EAAiB,MAAA,EAAgB,UAAA,CAAoB;QAC/D,KAAA,CAAM,QAAQ;QACd,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,MAAA,GAAS;QACd,IAAA,CAAK,UAAA,GAAa;;IAGpB,SAAS;QACP,OAAO;YACL,MAAM,IAAA,CAAK,IAAA;YACX,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,IAAA,CAAK,MAAA;YACb,YAAY,IAAA,CAAK,UAAA;SAClB;;;;;;GAQL,IAAa,6BAAb,cAAgD,oBAAoB;IAGlE,YAAY,OAAA,EAAiB,aAAA,CAAwB;QACnD,KAAA,CAAM,QAAQ;QACd,IAAA,CAAK,IAAA,GAAO;QACZ,IAAA,CAAK,aAAA,GAAgB;;;;;;GAQzB,IAAY,0BAAA,aAAA,GAAA,SAAA,yBAAA,EAAL;4CAEL,yBAAA,CAAA,gBAAA,GAAA;yDAEA,yBAAA,CAAA,4BAAA,GAAA;yCAEA,yBAAA,CAAA,4BAAA,GAAA;oDAEA,yBAAA,CAAA,yBAAA,GAAA;iDAEA,yBAAA,CAAA,6BAAA,GAAA;gDAEA,yBAAA,CAAA,6BAAA,GAAA;;;;;;;;;;;GCnEF,MAAa,eAAA,CAAgB,gBAA+B;IAC1D,IAAI,YACF,CAAA,OAAA,CAAQ,GAAG,OAAS,YAAY,GAAG,KAAK;IAE1C,OAAA,CAAQ,GAAG,OAAS,MAAM,GAAG,KAAK;;;;;;;GASpC,MAAa,kBAAA,MAAyC;IACpD,OAAO;;;;;;;;;GAWT,MAAa,gBAAA,CAAiB,UAA2B;IACvD,IAAI,OAAO,UAAU,YAAY,UAAU,KACzC,CAAA,OAAO;IAGT,MAAM,YAAY,OAAO,cAAA,CAAe,MAAM;IAC9C,OAAA,CACG,cAAc,QACb,cAAc,OAAO,SAAA,IACrB,OAAO,cAAA,CAAe,UAAU,KAAK,IAAA,KACvC,CAAA,CAAE,OAAO,WAAA,IAAe,KAAA,KACxB,CAAA,CAAE,OAAO,QAAA,IAAY,KAAA;;;;;;;;GAWzB,MAAa,qBAAA,CAAsB,WAA+B;IAEhE,OAAO,MAAM,IAAA,CAAK,IAAI,aAAa,OAAO,CAAC;;;;;;;;;GAW7C,MAAa,0BAAA,CACX,QACA,sBACS;IACT,IAAI,sBAAsB,KAAA,KAAa,OAAO,OAAA,CAAQ,MAAA,KAAW,kBAC/D,CAAA,MAAM,IAAI,MACR,CAAA,oCAAA,EAAuC,kBAAkB,MAAA,EAAQ,OAAO,OAAA,CAAQ,MAAA,EAAA,CACjF;;;;;;;;GChDL,MAAM,mBAAA,CAAoB,MACxB,IAAI,GAAA,IAAO,IAAI,OAAA,IAAW,IAAI,iBAAA,IAAqB,IAAI,KAAA,IAAS,KAAK,SAAA,CAAU,IAAI;;;;;;GAQrF,MAAM,cAAc,OAClB,OACA,QACA,YACG;IAUH,IANE,SACA,OAAO,UAAU,YACjB,YAAY,SACZ,QAAQ,SACR,OAAQ,MAAc,MAAA,KAAW,YAEb,CAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAC,QAAS,aAAA,GAAe;QAC7C,MAAM,SAAU,MAAc,MAAA,IAAU;QACxC,MAAM,gBAAgB;QAGtB,IAAI,OAAO,cAAc,IAAA,KAAS,WAChC,CAAA,cACG,IAAA,EAAM,CACN,IAAA,CAAA,CAAM,QAAa;YAClB,MAAM,aAAA,CAAA,QAAA,QAAA,QAAA,KAAA,IAAA,KAAA,IAAa,IAAK,UAAA,KAAA,CAAA,QAAA,QAAA,QAAA,KAAA,IAAA,KAAA,IAAc,IAAK,IAAA,KAAQ,SAAS;YAC5D,OAAO,IAAI,uBAAuB,iBAAiB,IAAI,EAAE,QAAQ,WAAW,CAAC;UAC7E,CACD,KAAA,CAAA,MAAY;YAEX,MAAM,aAAa,SAAS;YAE5B,OAAO,IAAI,uBADK,cAAc,UAAA,IAAc,CAAA,KAAA,EAAQ,OAAO,MAAA,CAAA,EAChB,QAAQ,WAAW,CAAC;UAC/D;aACC;YAEL,MAAM,aAAa,SAAS;YAE5B,OAAO,IAAI,uBADK,cAAc,UAAA,IAAc,CAAA,KAAA,EAAQ,OAAO,MAAA,CAAA,EAChB,QAAQ,WAAW,CAAC;;UAGjE,CAAA,OAAO,IAAI,2BAA2B,iBAAiB,MAAM,EAAE,MAAM,CAAC;;;;;;;;;GAY1E,MAAM,oBAAA,CACJ,QACA,SACA,YACA,SACG;IACH,MAAMC,SAA+B;QAAE;QAAQ,SAAA,CAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAS,QAAS,OAAA,KAAW,CAAA,CAAE;KAAE;IAEhF,IAAI,WAAW,SAAS,CAAC,KACvB,CAAA,OAAO;IAGT,IAAI,cAAc,KAAK,EAAE;QACvB,OAAO,OAAA,GAAA,eAAA;YAAY,gBAAgB;QAAA,GAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAuB,QAAS,OAAA;QACnE,OAAO,IAAA,GAAO,KAAK,SAAA,CAAU,KAAK;UAElC,CAAA,OAAO,IAAA,GAAO;IAGhB,OAAA,eAAA,eAAA,CAAA,GAAY,SAAW;;;;;;;;;;;GAazB,eAAe,eACb,OAAA,EACA,MAAA,EACA,GAAA,EACA,OAAA,EACA,UAAA,EACA,IAAA,EACc;IACd,OAAO,IAAI,QAAA,CAAS,SAAS,WAAW;QACtC,QAAQ,KAAK,kBAAkB,QAAQ,SAAS,YAAY,KAAK,CAAC,CAC/D,IAAA,CAAA,CAAM,WAAW;YAChB,IAAI,CAAC,OAAO,EAAA,CAAI,CAAA,MAAM;YACtB,IAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAI,QAAS,aAAA,CAAe,CAAA,OAAO;YAEnC,MAAM,cAAc,OAAO,OAAA,CAAQ,GAAA,CAAI,eAAe;YACtD,IAAI,CAAC,eAAe,CAAC,YAAY,QAAA,CAAS,mBAAmB,CAC3D,CAAA,OAAO,CAAA,CAAE;YAEX,OAAO,OAAO,IAAA,EAAM;UACpB,CACD,IAAA,CAAA,CAAM,OAAS,QAAQ,KAAK,CAAC,CAC7B,KAAA,CAAA,CAAO,QAAU,YAAY,OAAO,QAAQ,QAAQ,CAAC;MACxD;;;;;;;;;;GA6BJ,eAAsB,KACpB,OAAA,EACA,GAAA,EACA,IAAA,EACA,OAAA,EACA,UAAA,EACc;IACd,OAAO,eAAe,SAAS,QAAQ,KAAK,SAAS,YAAY,KAAK;;;;;;;;GC/IxE,IAAqB,iBAArB,MAAoC;iDAOlC,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;aAHvE,kBAAA,GAAqB;QAI7B,IAAA,CAAK,GAAA,GAAM,IAAI,OAAA,CAAQ,OAAO,GAAG;QACjC,IAAA,CAAK,OAAA,GAAA,eAAA,eAAA,CAAA,GAAe,kBAAoB;QACxC,IAAA,CAAK,KAAA,GAAQ,aAAaC,QAAM;;4EAI3B,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;sDAIT,MAAM,YAAY,OAAA,EAA8D;;QAC9E,IAAI;YAIF,OAAO;gBAAE,MAHI,MAAM,KAAKC,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,YAAA,CAAA,EAAe,SAAS;oBACtE,SAASA,MAAK,OAAA;gBAAA,CACf,CAAC,IACqB,CAAA,CAAE;gBAAE,OAAO;aAAM;iBACjC,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;0DAKV,MAAM,SACJ,gBAAA,EACA,SAAA,EAC8C;;QAC9C,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,SAAA,CAAA,EACZ;oBAAE;oBAAkB;iBAAW,EAC/B;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;uFAKV,MAAM,YAAY,OAAA,EAAwE;;QACxF,IAAI;YAIF,OAAO;gBAAE,MAHI,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EAAe,SAAS;oBACtE,SAASA,OAAK,OAAA;gBAAA,CACf,CAAC;gBACa,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;mDAKV,MAAM,YAAY,gBAAA,EAA0B,SAAA,EAAoD;;QAC9F,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EACZ;oBAAE;oBAAkB;iBAAW,EAC/B;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B,IACsB,CAAA,CAAE;gBAAE,OAAO;aAAM;iBACjC,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;;;;;;;;GC9GZ,IAAqB,gBAArB,MAAmC;gDAOjC,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;aAHvE,kBAAA,GAAqB;QAI7B,IAAA,CAAK,GAAA,GAAM,IAAI,OAAA,CAAQ,OAAO,GAAG;QACjC,IAAA,CAAK,OAAA,GAAA,eAAA,eAAA,CAAA,GAAe,kBAAoB;QACxC,IAAA,CAAK,KAAA,GAAQ,aAAaC,QAAM;;4EAI3B,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;mEAIT,MAAM,WAAW,OAAA,EAA6D;;QAC5E,IAAI;YAEF,IAAI,QAAQ,OAAA,CAAQ,MAAA,GAAS,KAAK,QAAQ,OAAA,CAAQ,MAAA,GAAS,IACzD,CAAA,MAAM,IAAI,MAAM,oDAAoD;YAMtE,OAAO;gBAAE,MAHI,MAAM,KAAKC,MAAK,KAAA,EAAO,GAAGA,MAAK,GAAA,CAAI,WAAA,CAAA,EAAc,SAAS;oBACrE,SAASA,MAAK,OAAA;gBAAA,CACf,CAAC,IACqB,CAAA,CAAE;gBAAE,OAAO;aAAM;iBACjC,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;oDAKV,MAAM,WAAW,OAAA,EAAsE;;QACrF,IAAI;YAIF,OAAO;gBAAE,MAHI,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,WAAA,CAAA,EAAc,SAAS;oBACrE,SAASA,OAAK,OAAA;gBAAA,CACf,CAAC;gBACa,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;qDAKV,MAAM,YAAY,OAAA,EAAwE;;QACxF,IAAI;YAEF,IAAI,QAAQ,YAAA,KAAiB,KAAA,GAAW;gBACtC,IAAI,QAAQ,YAAA,GAAe,KAAK,QAAQ,YAAA,GAAe,GACrD,CAAA,MAAM,IAAI,MAAM,wCAAwC;gBAE1D,IAAI,QAAQ,YAAA,KAAiB,KAAA,GAC3B;wBAAI,QAAQ,YAAA,GAAe,KAAK,QAAQ,YAAA,IAAgB,QAAQ,YAAA,CAC9D,CAAA,MAAM,IAAI,MAAM,CAAA,mCAAA,EAAsC,QAAQ,YAAA,GAAe,GAAA,CAAI;;;YAQvF,OAAO;gBAAE,MAHI,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,YAAA,CAAA,EAAe,SAAS;oBACtE,SAASA,OAAK,OAAA;gBAAA,CACf,CAAC;gBACa,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;iFAKV,MAAM,aAAa,OAAA,EAA0E;;QAC3F,IAAI;YAIF,OAAO;gBAAE,MAHI,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,aAAA,CAAA,EAAgB,SAAS;oBACvE,SAASA,OAAK,OAAA;gBAAA,CACf,CAAC;gBACa,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;sEAKV,MAAM,cAAc,OAAA,EAAgE;;QAClF,IAAI;YAEF,IAAI,QAAQ,IAAA,CAAK,MAAA,GAAS,KAAK,QAAQ,IAAA,CAAK,MAAA,GAAS,IACnD,CAAA,MAAM,IAAI,MAAM,kDAAkD;YAMpE,OAAO;gBAAE,MAHI,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,cAAA,CAAA,EAAiB,SAAS;oBACxE,SAASA,OAAK,OAAA;gBAAA,CACf,CAAC,IACqB,CAAA,CAAE;gBAAE,OAAO;aAAM;iBACjC,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;;;;;;;;GCpIZ,IAAqB,kBAArB,MAAqC;kDAOnC,YAAY,GAAA,EAAa,UAAqC,CAAA,CAAE,EAAE,OAAA,CAAe;aAHvE,kBAAA,GAAqB;QAI7B,IAAA,CAAK,GAAA,GAAM,IAAI,OAAA,CAAQ,OAAO,GAAG;QACjC,IAAA,CAAK,OAAA,GAAA,eAAA,eAAA,CAAA,GAAe,kBAAoB;QACxC,IAAA,CAAK,KAAA,GAAQ,aAAaC,QAAM;;4EAI3B,eAAqB;QAC1B,IAAA,CAAK,kBAAA,GAAqB;QAC1B,OAAO,IAAA;;uCAIT,MAAM,aAAa,gBAAA,EAA2D;;QAC5E,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,KACjBC,MAAK,KAAA,EACL,GAAGA,MAAK,GAAA,CAAI,mBAAA,CAAA,EACZ;oBAAE;gBAAA,CAAkB,EACpB;oBAAE,SAASA,MAAK,OAAA;gBAAA,CAAS,CAC1B,IACsB,CAAA,CAAE;gBAAE,OAAO;aAAM;iBACjC,OAAO;YACd,IAAIA,MAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;2DAKV,MAAM,UAAU,gBAAA,EAAgF;;QAC9F,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,gBAAA,CAAA,EACZ;oBAAE;gBAAA,CAAkB,EACpB;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B;gBACc,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;uEAKV,MAAM,YACJ,UAAoC,CAAA,CAAE,EACW;;QACjD,IAAI;YAIF,OAAO;gBAAE,MAHI,MAAM,KAAKA,OAAK,KAAA,EAAO,GAAGA,OAAK,GAAA,CAAI,kBAAA,CAAA,EAAqB,SAAS;oBAC5E,SAASA,OAAK,OAAA;gBAAA,CACf,CAAC;gBACa,OAAO;aAAM;iBACrB,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;yDAKV,MAAM,aAAa,gBAAA,EAA2D;;QAC5E,IAAI;YAOF,OAAO;gBAAE,MANI,MAAM,KACjBA,OAAK,KAAA,EACL,GAAGA,OAAK,GAAA,CAAI,mBAAA,CAAA,EACZ;oBAAE;gBAAA,CAAkB,EACpB;oBAAE,SAASA,OAAK,OAAA;gBAAA,CAAS,CAC1B,IACsB,CAAA,CAAE;gBAAE,OAAO;aAAM;iBACjC,OAAO;YACd,IAAIA,OAAK,kBAAA,CACP,CAAA,MAAM;YAER,IAAI,sBAAsB,MAAM,CAC9B,CAAA,OAAO;gBAAE,MAAM;gBAAM;aAAO;YAE9B,MAAM;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GCnCZ,IAAa,uBAAb,cAA0C,gBAAgB;;;;;;;;;;;;;;;;;IAkBxD,YAAY,GAAA,EAAa,UAAuC,CAAA,CAAE,CAAE;QAClE,KAAA,CAAM,KAAK,QAAQ,OAAA,IAAW,CAAA,CAAE,EAAE,QAAQ,KAAA,CAAM;;;;;;;;;;;;;;;;;;;IAqBlD,KAAK,gBAAA,EAA6C;QAChD,OAAO,IAAI,kBAAkB,IAAA,CAAK,GAAA,EAAK,IAAA,CAAK,OAAA,EAAS,kBAAkB,IAAA,CAAK,KAAA,CAAM;;;;;;;;;;;;;;;;;;;;;;IAwBpF,MAAM,aAAa,gBAAA,EAA2D;6CACrE,KAAA,CAAM,cAAA,QAAA,IAAA;QAAb,OAAA,6BAAA,IAAA,CAAA,OAA0B;;;;;;;;;;;;;;;;;;;;;;;IAyB5B,MAAM,UAAU,gBAAA,EAAgF;0CACvF,KAAA,CAAM,WAAA,SAAA,IAAA;QAAb,OAAA,0BAAA,IAAA,CAAA,QAAuB;;;;;;;;;;;;;;;;;;;;;;;;;IA2BzB,MAAM,YACJ,UAAoC,CAAA,CAAE,EACW;4CAC1C,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAyB;;;;;;;;;;;;;;;;;;;;;;IAwB3B,MAAM,aAAa,gBAAA,EAA2D;6CACrE,KAAA,CAAM,cAAA,SAAA,IAAA;QAAb,OAAA,6BAAA,IAAA,CAAA,QAA0B;;;;;;;;;;;GAa9B,IAAa,oBAAb,cAAuC,eAAe;;;;;;;;;;;;;IAgBpD,YACE,GAAA,EACA,OAAA,EACA,gBAAA,EACA,OAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASC,QAAM;QAC1B,IAAA,CAAK,gBAAA,GAAmB;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8B1B,MAAe,YAAY,OAAA,EAAuD;4CACzE,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBC,OAAK,gBAAA;QAAA;;;;;;;;;;;;;;;;;;;;IAuB3B,MAAe,YAAY,UAAwD,CAAA,CAAE,EAAE;4CAC9E,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,OAAK,gBAAA;QAAA;;;;;;;;;;;;;;;;;;;;;IAwB3B,MAAe,SAAS,SAAA,EAAmB;yCAClC,KAAA,CAAM,UAAA,SAAA,IAAA;QAAb,OAAA,yBAAA,IAAA,CAAA,QAAsBA,OAAK,gBAAA,EAAkB;;;;;;;;;;;;;;;;;;;;IAsB/C,MAAe,YAAY,SAAA,EAAmB;4CACrC,KAAA,CAAM,aAAA,SAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,QAAyBA,OAAK,gBAAA,EAAkB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAkClD,MAAM,SAAA,EAAqC;QACzC,OAAO,IAAI,iBACT,IAAA,CAAK,GAAA,EACL,IAAA,CAAK,OAAA,EACL,IAAA,CAAK,gBAAA,EACL,WACA,IAAA,CAAK,KAAA,CACN;;;;;;;;;;;GAaL,IAAa,mBAAb,cAAsC,cAAc;;;;;;;;;;;;;;IAkBlD,YACE,GAAA,EACA,OAAA,EACA,gBAAA,EACA,SAAA,EACA,OAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASD,QAAM;QAC1B,IAAA,CAAK,gBAAA,GAAmB;QACxB,IAAA,CAAK,SAAA,GAAY;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA8BnB,MAAe,WAAW,OAAA,EAAoE;2CACrF,KAAA,CAAM,YAAA,SAAA,IAAA;QAAb,OAAA,2BAAA,IAAA,CAAA,QAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBC,OAAK,gBAAA;YACvB,WAAWA,OAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;;IA0BpB,MAAe,WAAW,OAAA,EAAoE;2CACrF,KAAA,CAAM,YAAA,UAAA,IAAA;QAAb,OAAA,2BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;;IA0BpB,MAAe,YACb,UAAsE,CAAA,CAAE,EACxE;4CACO,KAAA,CAAM,aAAA,UAAA,IAAA;QAAb,OAAA,4BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;IA6BpB,MAAe,aACb,OAAA,EACA;6CACO,KAAA,CAAM,cAAA,UAAA,IAAA;QAAb,OAAA,6BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;;;;;;;;;;;;;;;;;;IAyBpB,MAAe,cACb,OAAA,EACA;8CACO,KAAA,CAAM,eAAA,UAAA,IAAA;QAAb,OAAA,8BAAA,IAAA,CAAA,SAAA,eAAA,eAAA,CAAA,GACK,UAAA,CAAA,GAAA;YACH,kBAAkBA,QAAK,gBAAA;YACvB,WAAWA,QAAK,SAAA;;;;;;AC1lBtB,IAAa,gBAAb,cAAmC,iBAAiB;;;;;;;;;;;;;;IAelD,YACE,GAAA,EACA,UAAqC,CAAA,CAAE,EACvC,OAAA,EACA,IAAA,CACA;QACA,KAAA,CAAM,KAAK,SAASC,SAAO,KAAK;;;;;;;;;;;;IAclC,KAAK,EAAA,EAA4B;QAC/B,OAAO,IAAI,eAAe,IAAA,CAAK,GAAA,EAAK,IAAA,CAAK,OAAA,EAAS,IAAI,IAAA,CAAK,KAAA,CAAM;;;;;;;;;;;;IAcnE,IAAI,UAAgC;QAClC,OAAO,IAAI,qBAAqB,IAAA,CAAK,GAAA,GAAM,WAAW;YACpD,SAAS,IAAA,CAAK,OAAA;YACd,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;;;;;;;;;;;;IAcJ,IAAI,YAAoC;QACtC,OAAO,IAAI,uBAAuB,IAAA,CAAK,GAAA,GAAM,YAAY,IAAA,CAAK,OAAA,EAAS,IAAA,CAAK,KAAA,CAAM"}},
    {"offset": {"line": 4479, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/index.mjs","sources":["file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/lib/version.ts","file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/lib/constants.ts","file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/lib/fetch.ts","file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/lib/helpers.ts","file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/lib/SupabaseAuthClient.ts","file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/SupabaseClient.ts","file:///home/runner/workspace/node_modules/%40supabase/supabase-js/src/index.ts"],"sourcesContent":["// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.89.0'\n","// constants.ts\nimport { RealtimeClientOptions } from '@supabase/realtime-js'\nimport { SupabaseAuthClientOptions } from './types'\nimport { version } from './version'\n\nlet JS_ENV = ''\n// @ts-ignore\nif (typeof Deno !== 'undefined') {\n  JS_ENV = 'deno'\n} else if (typeof document !== 'undefined') {\n  JS_ENV = 'web'\n} else if (typeof navigator !== 'undefined' && navigator.product === 'ReactNative') {\n  JS_ENV = 'react-native'\n} else {\n  JS_ENV = 'node'\n}\n\nexport const DEFAULT_HEADERS = { 'X-Client-Info': `supabase-js-${JS_ENV}/${version}` }\n\nexport const DEFAULT_GLOBAL_OPTIONS = {\n  headers: DEFAULT_HEADERS,\n}\n\nexport const DEFAULT_DB_OPTIONS = {\n  schema: 'public',\n}\n\nexport const DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions = {\n  autoRefreshToken: true,\n  persistSession: true,\n  detectSessionInUrl: true,\n  flowType: 'implicit',\n}\n\nexport const DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions = {}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args: Parameters<Fetch>) => customFetch(...args)\n  }\n  return (...args: Parameters<Fetch>) => fetch(...args)\n}\n\nexport const resolveHeadersConstructor = () => {\n  return Headers\n}\n\nexport const fetchWithAuth = (\n  supabaseKey: string,\n  getAccessToken: () => Promise<string | null>,\n  customFetch?: Fetch\n): Fetch => {\n  const fetch = resolveFetch(customFetch)\n  const HeadersConstructor = resolveHeadersConstructor()\n\n  return async (input, init) => {\n    const accessToken = (await getAccessToken()) ?? supabaseKey\n    let headers = new HeadersConstructor(init?.headers)\n\n    if (!headers.has('apikey')) {\n      headers.set('apikey', supabaseKey)\n    }\n\n    if (!headers.has('Authorization')) {\n      headers.set('Authorization', `Bearer ${accessToken}`)\n    }\n\n    return fetch(input, { ...init, headers })\n  }\n}\n","// helpers.ts\nimport { SupabaseClientOptions } from './types'\n\nexport function uuid() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n    var r = (Math.random() * 16) | 0,\n      v = c == 'x' ? r : (r & 0x3) | 0x8\n    return v.toString(16)\n  })\n}\n\nexport function ensureTrailingSlash(url: string): string {\n  return url.endsWith('/') ? url : url + '/'\n}\n\nexport const isBrowser = () => typeof window !== 'undefined'\n\nexport function applySettingDefaults<\n  Database = any,\n  SchemaName extends string & keyof Database = 'public' extends keyof Database\n    ? 'public'\n    : string & keyof Database,\n>(\n  options: SupabaseClientOptions<SchemaName>,\n  defaults: SupabaseClientOptions<any>\n): Required<SupabaseClientOptions<SchemaName>> {\n  const {\n    db: dbOptions,\n    auth: authOptions,\n    realtime: realtimeOptions,\n    global: globalOptions,\n  } = options\n  const {\n    db: DEFAULT_DB_OPTIONS,\n    auth: DEFAULT_AUTH_OPTIONS,\n    realtime: DEFAULT_REALTIME_OPTIONS,\n    global: DEFAULT_GLOBAL_OPTIONS,\n  } = defaults\n\n  const result: Required<SupabaseClientOptions<SchemaName>> = {\n    db: {\n      ...DEFAULT_DB_OPTIONS,\n      ...dbOptions,\n    },\n    auth: {\n      ...DEFAULT_AUTH_OPTIONS,\n      ...authOptions,\n    },\n    realtime: {\n      ...DEFAULT_REALTIME_OPTIONS,\n      ...realtimeOptions,\n    },\n    storage: {},\n    global: {\n      ...DEFAULT_GLOBAL_OPTIONS,\n      ...globalOptions,\n      headers: {\n        ...(DEFAULT_GLOBAL_OPTIONS?.headers ?? {}),\n        ...(globalOptions?.headers ?? {}),\n      },\n    },\n    accessToken: async () => '',\n  }\n\n  if (options.accessToken) {\n    result.accessToken = options.accessToken\n  } else {\n    // hack around Required<>\n    delete (result as any).accessToken\n  }\n\n  return result\n}\n\n/**\n * Validates a Supabase client URL\n *\n * @param {string} supabaseUrl - The Supabase client URL string.\n * @returns {URL} - The validated base URL.\n * @throws {Error}\n */\nexport function validateSupabaseUrl(supabaseUrl: string): URL {\n  const trimmedUrl = supabaseUrl?.trim()\n\n  if (!trimmedUrl) {\n    throw new Error('supabaseUrl is required.')\n  }\n\n  if (!trimmedUrl.match(/^https?:\\/\\//i)) {\n    throw new Error('Invalid supabaseUrl: Must be a valid HTTP or HTTPS URL.')\n  }\n\n  try {\n    return new URL(ensureTrailingSlash(trimmedUrl))\n  } catch {\n    throw Error('Invalid supabaseUrl: Provided URL is malformed.')\n  }\n}\n","import { AuthClient } from '@supabase/auth-js'\nimport { SupabaseAuthClientOptions } from './types'\n\nexport class SupabaseAuthClient extends AuthClient {\n  constructor(options: SupabaseAuthClientOptions) {\n    super(options)\n  }\n}\n","import type { AuthChangeEvent } from '@supabase/auth-js'\nimport { FunctionsClient } from '@supabase/functions-js'\nimport {\n  PostgrestClient,\n  type PostgrestFilterBuilder,\n  type PostgrestQueryBuilder,\n} from '@supabase/postgrest-js'\nimport {\n  type RealtimeChannel,\n  type RealtimeChannelOptions,\n  RealtimeClient,\n  type RealtimeClientOptions,\n} from '@supabase/realtime-js'\nimport { StorageClient as SupabaseStorageClient } from '@supabase/storage-js'\nimport {\n  DEFAULT_AUTH_OPTIONS,\n  DEFAULT_DB_OPTIONS,\n  DEFAULT_GLOBAL_OPTIONS,\n  DEFAULT_REALTIME_OPTIONS,\n} from './lib/constants'\nimport { fetchWithAuth } from './lib/fetch'\nimport { applySettingDefaults, validateSupabaseUrl } from './lib/helpers'\nimport { SupabaseAuthClient } from './lib/SupabaseAuthClient'\nimport type {\n  Fetch,\n  GenericSchema,\n  SupabaseAuthClientOptions,\n  SupabaseClientOptions,\n} from './lib/types'\nimport { GetRpcFunctionFilterBuilderByArgs } from './lib/rest/types/common/rpc'\n\n/**\n * Supabase Client.\n *\n * An isomorphic Javascript client for interacting with Postgres.\n */\nexport default class SupabaseClient<\n  Database = any,\n  // The second type parameter is also used for specifying db_schema, so we\n  // support both cases.\n  // TODO: Allow setting db_schema from ClientOptions.\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n  Schema extends Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never = Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never,\n  ClientOptions extends { PostgrestVersion: string } = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? // If the version isn't explicitly set, look for it in the __InternalSupabase object to infer the right version\n      Database extends { __InternalSupabase: { PostgrestVersion: string } }\n      ? Database['__InternalSupabase']\n      : // otherwise default to 12\n        { PostgrestVersion: '12' }\n    : SchemaNameOrClientOptions extends { PostgrestVersion: string }\n      ? SchemaNameOrClientOptions\n      : never,\n> {\n  /**\n   * Supabase Auth allows you to create and manage user sessions for access to data that is secured by access policies.\n   */\n  auth: SupabaseAuthClient\n  realtime: RealtimeClient\n  /**\n   * Supabase Storage allows you to manage user-generated content, such as photos or videos.\n   */\n  storage: SupabaseStorageClient\n\n  protected realtimeUrl: URL\n  protected authUrl: URL\n  protected storageUrl: URL\n  protected functionsUrl: URL\n  protected rest: PostgrestClient<Database, ClientOptions, SchemaName>\n  protected storageKey: string\n  protected fetch?: Fetch\n  protected changedAccessToken?: string\n  protected accessToken?: () => Promise<string | null>\n\n  protected headers: Record<string, string>\n\n  /**\n   * Create a new client for use in the browser.\n   * @param supabaseUrl The unique Supabase URL which is supplied when you create a new project in your project dashboard.\n   * @param supabaseKey The unique Supabase Key which is supplied when you create a new project in your project dashboard.\n   * @param options.db.schema You can switch in between schemas. The schema needs to be on the list of exposed schemas inside Supabase.\n   * @param options.auth.autoRefreshToken Set to \"true\" if you want to automatically refresh the token before expiring.\n   * @param options.auth.persistSession Set to \"true\" if you want to automatically save the user session into local storage.\n   * @param options.auth.detectSessionInUrl Set to \"true\" if you want to automatically detects OAuth grants in the URL and signs in the user.\n   * @param options.realtime Options passed along to realtime-js constructor.\n   * @param options.storage Options passed along to the storage-js constructor.\n   * @param options.global.fetch A custom fetch implementation.\n   * @param options.global.headers Any additional headers to send with each network request.\n   * @example\n   * ```ts\n   * import { createClient } from '@supabase/supabase-js'\n   *\n   * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n   * const { data } = await supabase.from('profiles').select('*')\n   * ```\n   */\n  constructor(\n    protected supabaseUrl: string,\n    protected supabaseKey: string,\n    options?: SupabaseClientOptions<SchemaName>\n  ) {\n    const baseUrl = validateSupabaseUrl(supabaseUrl)\n    if (!supabaseKey) throw new Error('supabaseKey is required.')\n\n    this.realtimeUrl = new URL('realtime/v1', baseUrl)\n    this.realtimeUrl.protocol = this.realtimeUrl.protocol.replace('http', 'ws')\n    this.authUrl = new URL('auth/v1', baseUrl)\n    this.storageUrl = new URL('storage/v1', baseUrl)\n    this.functionsUrl = new URL('functions/v1', baseUrl)\n\n    // default storage key uses the supabase project ref as a namespace\n    const defaultStorageKey = `sb-${baseUrl.hostname.split('.')[0]}-auth-token`\n    const DEFAULTS = {\n      db: DEFAULT_DB_OPTIONS,\n      realtime: DEFAULT_REALTIME_OPTIONS,\n      auth: { ...DEFAULT_AUTH_OPTIONS, storageKey: defaultStorageKey },\n      global: DEFAULT_GLOBAL_OPTIONS,\n    }\n\n    const settings = applySettingDefaults(options ?? {}, DEFAULTS)\n\n    this.storageKey = settings.auth.storageKey ?? ''\n    this.headers = settings.global.headers ?? {}\n\n    if (!settings.accessToken) {\n      this.auth = this._initSupabaseAuthClient(\n        settings.auth ?? {},\n        this.headers,\n        settings.global.fetch\n      )\n    } else {\n      this.accessToken = settings.accessToken\n\n      this.auth = new Proxy<SupabaseAuthClient>({} as any, {\n        get: (_, prop) => {\n          throw new Error(\n            `@supabase/supabase-js: Supabase Client is configured with the accessToken option, accessing supabase.auth.${String(\n              prop\n            )} is not possible`\n          )\n        },\n      })\n    }\n\n    this.fetch = fetchWithAuth(supabaseKey, this._getAccessToken.bind(this), settings.global.fetch)\n    this.realtime = this._initRealtimeClient({\n      headers: this.headers,\n      accessToken: this._getAccessToken.bind(this),\n      ...settings.realtime,\n    })\n    if (this.accessToken) {\n      // Start auth immediately to avoid race condition with channel subscriptions\n      this.accessToken()\n        .then((token) => this.realtime.setAuth(token))\n        .catch((e) => console.warn('Failed to set initial Realtime auth token:', e))\n    }\n\n    this.rest = new PostgrestClient(new URL('rest/v1', baseUrl).href, {\n      headers: this.headers,\n      schema: settings.db.schema,\n      fetch: this.fetch,\n    })\n\n    this.storage = new SupabaseStorageClient(\n      this.storageUrl.href,\n      this.headers,\n      this.fetch,\n      options?.storage\n    )\n\n    if (!settings.accessToken) {\n      this._listenForAuthEvents()\n    }\n  }\n\n  /**\n   * Supabase Functions allows you to deploy and invoke edge functions.\n   */\n  get functions(): FunctionsClient {\n    return new FunctionsClient(this.functionsUrl.href, {\n      headers: this.headers,\n      customFetch: this.fetch,\n    })\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.from\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any> {\n    return this.rest.from(relation)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.schema\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return this.rest.schema<DynamicSchema>(schema)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.rpc\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    options: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {\n      head: false,\n      get: false,\n      count: undefined,\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    return this.rest.rpc(fn, args, options) as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      FilterBuilder['Row'],\n      FilterBuilder['Result'],\n      FilterBuilder['RelationName'],\n      FilterBuilder['Relationships'],\n      'RPC'\n    >\n  }\n\n  /**\n   * Creates a Realtime channel with Broadcast, Presence, and Postgres Changes.\n   *\n   * @param {string} name - The name of the Realtime channel.\n   * @param {Object} opts - The options to pass to the Realtime channel.\n   *\n   */\n  channel(name: string, opts: RealtimeChannelOptions = { config: {} }): RealtimeChannel {\n    return this.realtime.channel(name, opts)\n  }\n\n  /**\n   * Returns all Realtime channels.\n   */\n  getChannels(): RealtimeChannel[] {\n    return this.realtime.getChannels()\n  }\n\n  /**\n   * Unsubscribes and removes Realtime channel from Realtime client.\n   *\n   * @param {RealtimeChannel} channel - The name of the Realtime channel.\n   *\n   */\n  removeChannel(channel: RealtimeChannel): Promise<'ok' | 'timed out' | 'error'> {\n    return this.realtime.removeChannel(channel)\n  }\n\n  /**\n   * Unsubscribes and removes all Realtime channels from Realtime client.\n   */\n  removeAllChannels(): Promise<('ok' | 'timed out' | 'error')[]> {\n    return this.realtime.removeAllChannels()\n  }\n\n  private async _getAccessToken() {\n    if (this.accessToken) {\n      return await this.accessToken()\n    }\n\n    const { data } = await this.auth.getSession()\n\n    return data.session?.access_token ?? this.supabaseKey\n  }\n\n  private _initSupabaseAuthClient(\n    {\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      storageKey,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n    }: SupabaseAuthClientOptions,\n    headers?: Record<string, string>,\n    fetch?: Fetch\n  ) {\n    const authHeaders = {\n      Authorization: `Bearer ${this.supabaseKey}`,\n      apikey: `${this.supabaseKey}`,\n    }\n    return new SupabaseAuthClient({\n      url: this.authUrl.href,\n      headers: { ...authHeaders, ...headers },\n      storageKey: storageKey,\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n      fetch,\n      // auth checks if there is a custom authorizaiton header using this flag\n      // so it knows whether to return an error when getUser is called with no session\n      hasCustomAuthorizationHeader: Object.keys(this.headers).some(\n        (key) => key.toLowerCase() === 'authorization'\n      ),\n    })\n  }\n\n  private _initRealtimeClient(options: RealtimeClientOptions) {\n    return new RealtimeClient(this.realtimeUrl.href, {\n      ...options,\n      params: { ...{ apikey: this.supabaseKey }, ...options?.params },\n    })\n  }\n\n  private _listenForAuthEvents() {\n    const data = this.auth.onAuthStateChange((event, session) => {\n      this._handleTokenChanged(event, 'CLIENT', session?.access_token)\n    })\n    return data\n  }\n\n  private _handleTokenChanged(\n    event: AuthChangeEvent,\n    source: 'CLIENT' | 'STORAGE',\n    token?: string\n  ) {\n    if (\n      (event === 'TOKEN_REFRESHED' || event === 'SIGNED_IN') &&\n      this.changedAccessToken !== token\n    ) {\n      this.changedAccessToken = token\n      this.realtime.setAuth(token)\n    } else if (event === 'SIGNED_OUT') {\n      this.realtime.setAuth()\n      if (source == 'STORAGE') this.auth.signOut()\n      this.changedAccessToken = undefined\n    }\n  }\n}\n","import SupabaseClient from './SupabaseClient'\nimport type { SupabaseClientOptions } from './lib/types'\n\nexport * from '@supabase/auth-js'\nexport type { User as AuthUser, Session as AuthSession } from '@supabase/auth-js'\nexport {\n  type PostgrestResponse,\n  type PostgrestSingleResponse,\n  type PostgrestMaybeSingleResponse,\n  PostgrestError,\n} from '@supabase/postgrest-js'\nexport {\n  FunctionsHttpError,\n  FunctionsFetchError,\n  FunctionsRelayError,\n  FunctionsError,\n  type FunctionInvokeOptions,\n  FunctionRegion,\n} from '@supabase/functions-js'\nexport * from '@supabase/realtime-js'\nexport { default as SupabaseClient } from './SupabaseClient'\nexport type {\n  SupabaseClientOptions,\n  QueryResult,\n  QueryData,\n  QueryError,\n  DatabaseWithoutInternals,\n} from './lib/types'\n\n/**\n * Creates a new Supabase Client.\n *\n * @example\n * ```ts\n * import { createClient } from '@supabase/supabase-js'\n *\n * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n * const { data, error } = await supabase.from('profiles').select('*')\n * ```\n */\nexport const createClient = <\n  Database = any,\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName>\n): SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName> => {\n  return new SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName>(\n    supabaseUrl,\n    supabaseKey,\n    options\n  )\n}\n\n// Check for Node.js <= 18 deprecation\nfunction shouldShowDeprecationWarning(): boolean {\n  // Skip in browser environments\n  if (typeof window !== 'undefined') {\n    return false\n  }\n\n  // Skip if process is not available (e.g., Edge Runtime)\n  if (typeof process === 'undefined') {\n    return false\n  }\n\n  // Use dynamic property access to avoid Next.js Edge Runtime static analysis warnings\n  const processVersion = (process as any)['version']\n  if (processVersion === undefined || processVersion === null) {\n    return false\n  }\n\n  const versionMatch = processVersion.match(/^v(\\d+)\\./)\n  if (!versionMatch) {\n    return false\n  }\n\n  const majorVersion = parseInt(versionMatch[1], 10)\n  return majorVersion <= 18\n}\n\nif (shouldShowDeprecationWarning()) {\n  console.warn(\n    `  Node.js 18 and below are deprecated and will no longer be supported in future versions of @supabase/supabase-js. ` +\n      `Please upgrade to Node.js 20 or later. ` +\n      `For more information, visit: https://github.com/orgs/supabase/discussions/37217`\n  )\n}\n"],"names":["DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions","DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions","fetch","DEFAULT_DB_OPTIONS","DEFAULT_AUTH_OPTIONS","DEFAULT_REALTIME_OPTIONS","DEFAULT_GLOBAL_OPTIONS","result: Required<SupabaseClientOptions<SchemaName>>","supabaseUrl: string","supabaseKey: string","SupabaseStorageClient","this"],"mappings":";;;;;;AM0Ea;;;;;;;;;;;;;;;;;ANpEb,MAAa,UAAU;;;ACDvB,IAAI,SAAS;AAEb,IAAI,OAAO,SAAS,YAClB,CAAA,SAAS;SACA,OAAO,aAAa,YAC7B,CAAA,SAAS;SACA,OAAO,cAAc,eAAe,UAAU,OAAA,KAAY,cACnE,CAAA,SAAS;KAET,SAAS;AAGX,MAAa,kBAAkB;IAAE,iBAAiB,CAAA,YAAA,EAAe,OAAO,CAAA,EAAG,SAAA;AAAA,CAAW;AAEtF,MAAa,yBAAyB;IACpC,SAAS;AAAA,CACV;AAED,MAAa,qBAAqB;IAChC,QAAQ;AAAA,CACT;AAED,MAAaA,uBAAkD;IAC7D,kBAAkB;IAClB,gBAAgB;IAChB,oBAAoB;IACpB,UAAU;CACX;AAED,MAAaC,2BAAkD,CAAA,CAAE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChCjE,MAAa,eAAA,CAAgB,gBAA+B;IAC1D,IAAI,YACF,CAAA,OAAA,CAAQ,GAAG,OAA4B,YAAY,GAAG,KAAK;IAE7D,OAAA,CAAQ,GAAG,OAA4B,MAAM,GAAG,KAAK;;AAGvD,MAAa,4BAAA,MAAkC;IAC7C,OAAO;;AAGT,MAAa,gBAAA,CACX,aACA,gBACA,gBACU;IACV,MAAMC,UAAQ,aAAa,YAAY;IACvC,MAAM,qBAAqB,2BAA2B;IAEtD,OAAO,OAAO,OAAO,SAAS;;QAC5B,MAAM,cAAA,CAAA,wBAAe,MAAM,gBAAgB,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAK;QAChD,IAAI,UAAU,IAAI,mBAAA,SAAA,QAAA,SAAA,KAAA,IAAA,KAAA,IAAmB,KAAM,OAAA,CAAQ;QAEnD,IAAI,CAAC,QAAQ,GAAA,CAAI,SAAS,CACxB,CAAA,QAAQ,GAAA,CAAI,UAAU,YAAY;QAGpC,IAAI,CAAC,QAAQ,GAAA,CAAI,gBAAgB,CAC/B,CAAA,QAAQ,GAAA,CAAI,iBAAiB,CAAA,OAAA,EAAU,aAAA,CAAc;QAGvD,OAAOA,QAAM,OAAA,eAAA,eAAA,CAAA,GAAY,OAAA,CAAA,GAAA;YAAM;QAAA,GAAU;;;;;ACtB7C,SAAgB,oBAAoB,GAAA,EAAqB;IACvD,OAAO,IAAI,QAAA,CAAS,IAAI,GAAG,MAAM,MAAM;;AAKzC,SAAgB,qBAMd,OAAA,EACA,QAAA,EAC6C;;IAC7C,MAAM,EACJ,IAAI,SAAA,EACJ,MAAM,WAAA,EACN,UAAU,eAAA,EACV,QAAQ,aAAA,EAAA,GACN;IACJ,MAAM,EACJ,IAAIC,oBAAAA,EACJ,MAAMC,sBAAAA,EACN,UAAUC,0BAAAA,EACV,QAAQC,wBAAAA,EAAAA,GACN;IAEJ,MAAMC,SAAsD;QAC1D,IAAA,eAAA,eAAA,CAAA,GACKJ,uBACA;QAEL,MAAA,eAAA,eAAA,CAAA,GACKC,yBACA;QAEL,UAAA,eAAA,eAAA,CAAA,GACKC,6BACA;QAEL,SAAS,CAAA,CAAE;QACX,QAAA,eAAA,eAAA,eAAA,CAAA,GACKC,2BACA,gBAAA,CAAA,GAAA;YACH,SAAA,eAAA,eAAA,CAAA,GAAA,CAAA,wBAAA,6BAAA,QAAA,6BAAA,KAAA,IAAA,KAAA,IACMA,yBAAwB,OAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAW,CAAA,CAAE,GAAA,CAAA,wBAAA,kBAAA,QAAA,kBAAA,KAAA,IAAA,KAAA,IACrC,cAAe,OAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAW,CAAA,CAAE;QAAA;QAGpC,aAAa,UAAY;KAC1B;IAED,IAAI,QAAQ,WAAA,CACV,CAAA,OAAO,WAAA,GAAc,QAAQ,WAAA;SAG7B,OAAQ,OAAe,WAAA;IAGzB,OAAO;;;;;;;;GAUT,SAAgB,oBAAoB,WAAA,EAA0B;IAC5D,MAAM,aAAA,gBAAA,QAAA,gBAAA,KAAA,IAAA,KAAA,IAAa,YAAa,IAAA,EAAM;IAEtC,IAAI,CAAC,WACH,CAAA,MAAM,IAAI,MAAM,2BAA2B;IAG7C,IAAI,CAAC,WAAW,KAAA,CAAM,gBAAgB,CACpC,CAAA,MAAM,IAAI,MAAM,0DAA0D;IAG5E,IAAI;QACF,OAAO,IAAI,IAAI,oBAAoB,WAAW,CAAC;sBACzC;QACN,MAAM,MAAM,kDAAkD;;;;;AC5FlE,IAAa,qBAAb,cAAwC,kOAAA,CAAW;IACjD,YAAY,OAAA,CAAoC;QAC9C,KAAA,CAAM,QAAQ;;;;;;;;;GC+BlB,IAAqB,iBAArB,MAgCE;;;;;;;;;;;;;;;;;;;;IA2CA,YACYE,WAAAA,EACAC,WAAAA,EACV,OAAA,CACA;;QAHU,IAAA,CAAA,WAAA,GAAA;QACA,IAAA,CAAA,WAAA,GAAA;QAGV,MAAM,UAAU,oBAAoB,YAAY;QAChD,IAAI,CAAC,YAAa,CAAA,MAAM,IAAI,MAAM,2BAA2B;QAE7D,IAAA,CAAK,WAAA,GAAc,IAAI,IAAI,eAAe,QAAQ;QAClD,IAAA,CAAK,WAAA,CAAY,QAAA,GAAW,IAAA,CAAK,WAAA,CAAY,QAAA,CAAS,OAAA,CAAQ,QAAQ,KAAK;QAC3E,IAAA,CAAK,OAAA,GAAU,IAAI,IAAI,WAAW,QAAQ;QAC1C,IAAA,CAAK,UAAA,GAAa,IAAI,IAAI,cAAc,QAAQ;QAChD,IAAA,CAAK,YAAA,GAAe,IAAI,IAAI,gBAAgB,QAAQ;QAGpD,MAAM,oBAAoB,CAAA,GAAA,EAAM,QAAQ,QAAA,CAAS,KAAA,CAAM,IAAI,CAAC,EAAA,CAAG,WAAA,CAAA;QAC/D,MAAM,WAAW;YACf,IAAI;YACJ,UAAU;YACV,MAAA,eAAA,eAAA,CAAA,GAAW,uBAAA,CAAA,GAAA;gBAAsB,YAAY;YAAA;YAC7C,QAAQ;SACT;QAED,MAAM,WAAW,qBAAqB,YAAA,QAAA,YAAA,KAAA,IAAA,UAAW,CAAA,CAAE,EAAE,SAAS;QAE9D,IAAA,CAAK,UAAA,GAAA,CAAA,wBAAa,SAAS,IAAA,CAAK,UAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAc;QAC9C,IAAA,CAAK,OAAA,GAAA,CAAA,wBAAU,SAAS,MAAA,CAAO,OAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAW,CAAA,CAAE;QAE5C,IAAI,CAAC,SAAS,WAAA,EAAa;;YACzB,IAAA,CAAK,IAAA,GAAO,IAAA,CAAK,uBAAA,CAAA,CAAA,iBACf,SAAS,IAAA,MAAA,QAAA,mBAAA,KAAA,IAAA,iBAAQ,CAAA,CAAE,EACnB,IAAA,CAAK,OAAA,EACL,SAAS,MAAA,CAAO,KAAA,CACjB;eACI;YACL,IAAA,CAAK,WAAA,GAAc,SAAS,WAAA;YAE5B,IAAA,CAAK,IAAA,GAAO,IAAI,MAA0B,CAAA,CAAE,EAAS;gBACnD,KAAA,CAAM,GAAG,SAAS;oBAChB,MAAM,IAAI,MACR,CAAA,0GAAA,EAA6G,OAC3G,KACD,CAAC,gBAAA,CAAA,CACH;;aAEJ,CAAC;;QAGJ,IAAA,CAAK,KAAA,GAAQ,cAAc,aAAa,IAAA,CAAK,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK,EAAE,SAAS,MAAA,CAAO,KAAA,CAAM;QAC/F,IAAA,CAAK,QAAA,GAAW,IAAA,CAAK,mBAAA,CAAA,eAAA;YACnB,SAAS,IAAA,CAAK,OAAA;YACd,aAAa,IAAA,CAAK,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK;WACzC,SAAS,QAAA,EACZ;QACF,IAAI,IAAA,CAAK,WAAA,CAEP,CAAA,IAAA,CAAK,WAAA,EAAa,CACf,IAAA,CAAA,CAAM,QAAU,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,MAAM,CAAC,CAC7C,KAAA,CAAA,CAAO,IAAM,QAAQ,IAAA,CAAK,8CAA8C,EAAE,CAAC;QAGhF,IAAA,CAAK,IAAA,GAAO,IAAI,qLAAA,CAAgB,IAAI,IAAI,WAAW,QAAQ,CAAC,IAAA,EAAM;YAChE,SAAS,IAAA,CAAK,OAAA;YACd,QAAQ,SAAS,EAAA,CAAG,MAAA;YACpB,OAAO,IAAA,CAAK,KAAA;SACb,CAAC;QAEF,IAAA,CAAK,OAAA,GAAU,IAAIC,iLAAAA,CACjB,IAAA,CAAK,UAAA,CAAW,IAAA,EAChB,IAAA,CAAK,OAAA,EACL,IAAA,CAAK,KAAA,EAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IACL,QAAS,OAAA,CACV;QAED,IAAI,CAAC,SAAS,WAAA,CACZ,CAAA,IAAA,CAAK,oBAAA,EAAsB;;;;IAO/B,IAAI,YAA6B;QAC/B,OAAO,IAAI,wMAAA,CAAgB,IAAA,CAAK,YAAA,CAAa,IAAA,EAAM;YACjD,SAAS,IAAA,CAAK,OAAA;YACd,aAAa,IAAA,CAAK,KAAA;SACnB,CAAC;;;;;;IAgBJ,KAAK,QAAA,EAAqE;QACxE,OAAO,IAAA,CAAK,IAAA,CAAK,IAAA,CAAK,SAAS;;;;;;;;IAWjC,OACE,MAAA,EAMA;QACA,OAAO,IAAA,CAAK,IAAA,CAAK,MAAA,CAAsB,OAAO;;;;;;;;;;;;;;;;;;;;;;;;IA2BhD,IASE,EAAA,EACA,OAAa,CAAA,CAAE,EACf,UAII;QACF,MAAM;QACN,KAAK;QACL,OAAO,KAAA;KACR,EASD;QACA,OAAO,IAAA,CAAK,IAAA,CAAK,GAAA,CAAI,IAAI,MAAM,QAAQ;;;;;;;;IAkBzC,QAAQ,IAAA,EAAc,OAA+B;QAAE,QAAQ,CAAA,CAAE;IAAA,CAAE,EAAmB;QACpF,OAAO,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,MAAM,KAAK;;;;IAM1C,cAAiC;QAC/B,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,EAAa;;;;;;;IASpC,cAAc,OAAA,EAAiE;QAC7E,OAAO,IAAA,CAAK,QAAA,CAAS,aAAA,CAAc,QAAQ;;;;IAM7C,oBAA+D;QAC7D,OAAO,IAAA,CAAK,QAAA,CAAS,iBAAA,EAAmB;;IAG1C,MAAc,kBAAkB;;;QAC9B,IAAIC,MAAK,WAAA,CACP,CAAA,OAAO,MAAMA,MAAK,WAAA,EAAa;QAGjC,MAAM,EAAE,IAAA,EAAA,GAAS,MAAMA,MAAK,IAAA,CAAK,UAAA,EAAY;QAE7C,OAAA,CAAA,wBAAA,CAAA,gBAAO,KAAK,OAAA,MAAA,QAAA,kBAAA,KAAA,IAAA,KAAA,IAAA,cAAS,YAAA,MAAA,QAAA,0BAAA,KAAA,IAAA,wBAAgBA,MAAK,WAAA;;IAGpC,wBACN,EACE,gBAAA,EACA,cAAA,EACA,kBAAA,EACA,OAAA,EACA,WAAA,EACA,UAAA,EACA,QAAA,EACA,IAAA,EACA,KAAA,EACA,YAAA,EAAA,EAEF,OAAA,EACA,OAAA,EACA;QACA,MAAM,cAAc;YAClB,eAAe,CAAA,OAAA,EAAU,IAAA,CAAK,WAAA,EAAA;YAC9B,QAAQ,GAAG,IAAA,CAAK,WAAA,EAAA;SACjB;QACD,OAAO,IAAI,mBAAmB;YAC5B,KAAK,IAAA,CAAK,OAAA,CAAQ,IAAA;YAClB,SAAA,eAAA,eAAA,CAAA,GAAc,cAAgB;YAClB;YACZ;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA,OAAA;YAGA,8BAA8B,OAAO,IAAA,CAAK,IAAA,CAAK,OAAA,CAAQ,CAAC,IAAA,CAAA,CACrD,MAAQ,IAAI,WAAA,EAAa,KAAK,gBAChC;SACF,CAAC;;IAGI,oBAAoB,OAAA,EAAgC;QAC1D,OAAO,IAAI,kPAAA,CAAe,IAAA,CAAK,WAAA,CAAY,IAAA,EAAA,eAAA,eAAA,CAAA,GACtC,UAAA,CAAA,GAAA;YACH,QAAA,eAAA,eAAA,CAAA,GAAa;gBAAE,QAAQ,IAAA,CAAK,WAAA;YAAA,CAAa,GAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAK,QAAS,MAAA;QAAA,GACvD;;IAGI,uBAAuB;QAI7B,OAHa,IAAA,CAAK,IAAA,CAAK,iBAAA,CAAA,CAAmB,OAAO,YAAY;YAC3D,IAAA,CAAK,mBAAA,CAAoB,OAAO,UAAA,YAAA,QAAA,YAAA,KAAA,IAAA,KAAA,IAAU,QAAS,YAAA,CAAa;UAChE;;IAII,oBACN,KAAA,EACA,MAAA,EACA,KAAA,EACA;QACA,IAAA,CACG,UAAU,qBAAqB,UAAU,WAAA,KAC1C,IAAA,CAAK,kBAAA,KAAuB,OAC5B;YACA,IAAA,CAAK,kBAAA,GAAqB;YAC1B,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,MAAM;mBACnB,UAAU,cAAc;YACjC,IAAA,CAAK,QAAA,CAAS,OAAA,EAAS;YACvB,IAAI,UAAU,UAAW,CAAA,IAAA,CAAK,IAAA,CAAK,OAAA,EAAS;YAC5C,IAAA,CAAK,kBAAA,GAAqB,KAAA;;;;;;;;;;;;;;;;GCvXhC,MAAa,eAAA,CAeX,aACA,aACA,YACoE;IACpE,OAAO,IAAI,eACT,aACA,aACA,QACD;;AAIH,SAAS,+BAAwC;IAE/C,IAAI,OAAO,WAAW,YACpB,CAAA,OAAO;IAIT,IAAI,kLAAO,KAAY,YACrB,CAAA,OAAO;IAIT,MAAM,iBAAkB,2KAAA,CAAgB,UAAA;IACxC,IAAI,mBAAmB,KAAA,KAAa,mBAAmB,KACrD,CAAA,OAAO;IAGT,MAAM,eAAe,eAAe,KAAA,CAAM,YAAY;IACtD,IAAI,CAAC,aACH,CAAA,OAAO;IAIT,OADqB,SAAS,YAAA,CAAa,EAAA,EAAI,GAAG,IAC3B;;AAGzB,IAAI,8BAA8B,CAChC,CAAA,QAAQ,IAAA,CACN,8OAGD"}}]
}